INFO:root:Backdoor type: single-character-attack
INFO:root: noDefense: False
INFO:root:Initialising training data for single character backdoor
INFO:root:Backdoor Train Size: 200 Backdoor Test Size: 120
INFO:root:size of test data 340
INFO:root:attack from epoch 101
INFO:root:Test Accuracy of loaded global Model is: 55.588235294117645
INFO:root:================FL round 1 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 1 Workers Selected : [65, 43, 96, 21, 84, 86, 67, 45, 13, 3]
INFO:root:FL Epoch: 1 Fraction of points on each worker in this round: [0.01111111 0.01111111 0.01111111 0.56666667 0.13333333 0.05555556
 0.13333333 0.02222222 0.04444444 0.01111111]
INFO:root:FL Epoch: 1 Num points on workers: [ 1  1  1 51 12  5 12  2  4  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 1 Training on worker :65
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 1 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 1 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :43
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 1 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 1 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :96
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 1 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 1 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :21
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.699185
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.618861
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 1 Norm Difference for worker 21 is 0.32881
INFO:root:FL Epoch: 1 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :84
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 1 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 1 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :86
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 1 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 1 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :67
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 1 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 1 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :45
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 1 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 1 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :13
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 1 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 1 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :3
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 1 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 1 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 65
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 1 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 1 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 1 Ends   ===================
INFO:root:Epoch:1 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:1 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 2 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 2 Workers Selected : [61, 56, 93, 89, 55, 60, 40, 18, 62, 26]
INFO:root:FL Epoch: 2 Fraction of points on each worker in this round: [0.05 0.15 0.1  0.05 0.05 0.15 0.05 0.2  0.15 0.05]
INFO:root:FL Epoch: 2 Num points on workers: [1 3 2 1 1 3 1 4 3 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 2 Training on worker :61
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 2 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :56
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 2 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 2 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :93
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 2 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 2 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :89
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 2 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :55
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 2 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :60
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 2 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 2 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :40
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 2 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :18
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 2 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 2 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :62
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 2 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 2 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :26
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 2 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 61
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 2 Ends   ===================
INFO:root:Epoch:2 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:2 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 3 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 3 Workers Selected : [36, 12, 47, 15, 23, 29, 60, 53, 64, 45]
INFO:root:FL Epoch: 3 Fraction of points on each worker in this round: [0.07407407 0.03703704 0.11111111 0.03703704 0.25925926 0.03703704
 0.11111111 0.14814815 0.11111111 0.07407407]
INFO:root:FL Epoch: 3 Num points on workers: [2 1 3 1 7 1 3 4 3 2]
INFO:root:--------------------------
INFO:root:FL Epoch: 3 Training on worker :36
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 3 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 3 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :12
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 3 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 3 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :47
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 3 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 3 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :15
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 3 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 3 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :23
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 3 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 3 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :29
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 3 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 3 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :60
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 3 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 3 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :53
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 3 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 3 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :64
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 3 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 3 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :45
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 3 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 3 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 36
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 3 Ends   ===================
INFO:root:Epoch:3 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:3 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 4 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 4 Workers Selected : [7, 14, 49, 58, 60, 42, 16, 54, 89, 97]
INFO:root:FL Epoch: 4 Fraction of points on each worker in this round: [0.02173913 0.13043478 0.02173913 0.39130435 0.06521739 0.06521739
 0.04347826 0.02173913 0.02173913 0.2173913 ]
INFO:root:FL Epoch: 4 Num points on workers: [ 1  6  1 18  3  3  2  1  1 10]
INFO:root:--------------------------
INFO:root:FL Epoch: 4 Training on worker :7
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 4 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 4 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :14
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 4 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 4 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :49
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 4 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 4 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :58
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 4 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 4 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :60
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 4 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 4 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :42
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 4 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 4 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :16
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 4 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 4 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :54
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 4 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 4 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :89
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 4 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 4 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :97
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 4 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 4 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 7
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 4 Ends   ===================
INFO:root:Epoch:4 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:4 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 5 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 5 Workers Selected : [26, 63, 20, 71, 40, 82, 29, 89, 13, 4]
INFO:root:FL Epoch: 5 Fraction of points on each worker in this round: [0.07142857 0.14285714 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857 0.28571429 0.07142857]
INFO:root:FL Epoch: 5 Num points on workers: [1 2 1 1 1 1 1 1 4 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 5 Training on worker :26
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 5 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :63
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 5 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 5 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :20
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 5 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :71
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 5 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :40
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 5 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :82
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 5 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :29
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 5 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :89
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 5 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :13
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 5 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 5 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :4
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 5 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 26
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 5 Ends   ===================
INFO:root:Epoch:5 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:5 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 6 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 6 Workers Selected : [33, 70, 8, 68, 17, 3, 44, 16, 58, 7]
INFO:root:FL Epoch: 6 Fraction of points on each worker in this round: [0.49180328 0.03278689 0.01639344 0.03278689 0.03278689 0.01639344
 0.03278689 0.03278689 0.29508197 0.01639344]
INFO:root:FL Epoch: 6 Num points on workers: [30  2  1  2  2  1  2  2 18  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 6 Training on worker :33
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.685100
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.665281
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 6 Norm Difference for worker 33 is 0.099004
INFO:root:FL Epoch: 6 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :70
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 6 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 6 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :8
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 6 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :68
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 6 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 6 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :17
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 6 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 6 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :3
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 6 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :44
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 6 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 6 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :16
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 6 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 6 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :58
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 6 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 6 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :7
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 6 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 6 Ends   ===================
INFO:root:Epoch:6 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:6 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 7 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 7 Workers Selected : [66, 98, 34, 82, 49, 63, 72, 36, 58, 87]
INFO:root:FL Epoch: 7 Fraction of points on each worker in this round: [0.025 0.025 0.075 0.025 0.025 0.05  0.15  0.05  0.45  0.125]
INFO:root:FL Epoch: 7 Num points on workers: [ 1  1  3  1  1  2  6  2 18  5]
INFO:root:--------------------------
INFO:root:FL Epoch: 7 Training on worker :66
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 7 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :98
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 7 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :34
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 7 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 7 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :82
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 7 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :49
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 7 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :63
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 7 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 7 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :72
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 7 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 7 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :36
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 7 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 7 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :58
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 7 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 7 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :87
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 7 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 7 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 66
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 7 Ends   ===================
INFO:root:Epoch:7 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:7 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 8 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 8 Workers Selected : [53, 99, 96, 54, 59, 97, 9, 89, 4, 91]
INFO:root:FL Epoch: 8 Fraction of points on each worker in this round: [0.08510638 0.06382979 0.0212766  0.0212766  0.0212766  0.21276596
 0.44680851 0.0212766  0.0212766  0.08510638]
INFO:root:FL Epoch: 8 Num points on workers: [ 4  3  1  1  1 10 21  1  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 8 Training on worker :53
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 8 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 8 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :99
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 8 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 8 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :96
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 8 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :54
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 8 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :59
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 8 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :97
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 8 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 8 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :9
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.683136
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.664188
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 9 is 0.095769
INFO:root:FL Epoch: 8 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :89
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 8 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :4
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 8 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :91
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 8 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 8 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 53
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 8 Ends   ===================
INFO:root:Epoch:8 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:8 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 9 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 9 Workers Selected : [17, 43, 76, 30, 38, 73, 95, 9, 85, 41]
INFO:root:FL Epoch: 9 Fraction of points on each worker in this round: [0.05128205 0.02564103 0.1025641  0.05128205 0.02564103 0.02564103
 0.02564103 0.53846154 0.05128205 0.1025641 ]
INFO:root:FL Epoch: 9 Num points on workers: [ 2  1  4  2  1  1  1 21  2  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 9 Training on worker :17
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 9 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 9 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :43
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 9 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :76
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 9 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 9 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :30
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 9 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 9 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :38
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 9 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :73
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 9 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :95
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 9 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :9
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.681755
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.662934
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 9 is 0.096338
INFO:root:FL Epoch: 9 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :85
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 9 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 9 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :41
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 9 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 9 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 17
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 9 Ends   ===================
INFO:root:Epoch:9 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:9 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 10 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 10 Workers Selected : [69, 78, 68, 84, 14, 65, 82, 31, 29, 67]
INFO:root:FL Epoch: 10 Fraction of points on each worker in this round: [0.31481481 0.01851852 0.03703704 0.22222222 0.11111111 0.01851852
 0.01851852 0.01851852 0.01851852 0.22222222]
INFO:root:FL Epoch: 10 Num points on workers: [17  1  2 12  6  1  1  1  1 12]
INFO:root:--------------------------
INFO:root:FL Epoch: 10 Training on worker :69
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 10 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 10 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :78
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 10 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :68
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 10 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 10 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :84
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 10 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 10 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :14
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 10 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 10 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :65
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 10 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :82
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 10 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :31
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 10 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :29
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 10 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :67
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 10 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 10 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 69
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 10 Ends   ===================
INFO:root:Epoch:10 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:10 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 11 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 11 Workers Selected : [41, 56, 44, 34, 93, 83, 58, 64, 71, 18]
INFO:root:FL Epoch: 11 Fraction of points on each worker in this round: [0.0952381  0.07142857 0.04761905 0.07142857 0.04761905 0.04761905
 0.42857143 0.07142857 0.02380952 0.0952381 ]
INFO:root:FL Epoch: 11 Num points on workers: [ 4  3  2  3  2  2 18  3  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 11 Training on worker :41
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 11 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 11 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :56
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 11 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 11 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :44
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 11 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 11 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :34
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 11 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 11 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :93
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 11 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 11 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :83
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 11 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 11 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :58
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 11 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 11 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :64
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 11 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 11 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :71
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 11 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 11 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :18
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 11 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 11 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 41
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 11 Ends   ===================
INFO:root:Epoch:11 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:11 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 12 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 12 Workers Selected : [63, 41, 72, 39, 18, 5, 37, 52, 34, 23]
INFO:root:FL Epoch: 12 Fraction of points on each worker in this round: [0.04 0.08 0.12 0.26 0.08 0.18 0.02 0.02 0.06 0.14]
INFO:root:FL Epoch: 12 Num points on workers: [ 2  4  6 13  4  9  1  1  3  7]
INFO:root:--------------------------
INFO:root:FL Epoch: 12 Training on worker :63
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 12 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 12 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :41
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 12 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 12 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :72
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 12 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 12 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :39
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 12 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 12 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :18
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 12 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 12 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :5
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 12 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 12 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :37
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 12 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 12 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :52
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 12 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 12 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :34
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 12 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 12 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :23
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 12 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 12 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 63
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 12 Ends   ===================
INFO:root:Epoch:12 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:12 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 13 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 13 Workers Selected : [82, 74, 48, 29, 23, 7, 63, 13, 14, 17]
INFO:root:FL Epoch: 13 Fraction of points on each worker in this round: [0.02380952 0.4047619  0.02380952 0.02380952 0.16666667 0.02380952
 0.04761905 0.0952381  0.14285714 0.04761905]
INFO:root:FL Epoch: 13 Num points on workers: [ 1 17  1  1  7  1  2  4  6  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 13 Training on worker :82
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 13 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :74
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 13 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 13 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :48
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 13 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :29
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 13 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :23
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 13 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 13 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :7
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 13 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :63
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 13 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 13 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :13
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 13 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 13 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :14
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 13 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 13 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :17
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 13 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 13 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 82
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 13 Ends   ===================
INFO:root:Epoch:13 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:13 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 14 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 14 Workers Selected : [17, 97, 72, 84, 66, 5, 30, 44, 82, 47]
INFO:root:FL Epoch: 14 Fraction of points on each worker in this round: [0.04166667 0.20833333 0.125      0.25       0.02083333 0.1875
 0.04166667 0.04166667 0.02083333 0.0625    ]
INFO:root:FL Epoch: 14 Num points on workers: [ 2 10  6 12  1  9  2  2  1  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 14 Training on worker :17
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 14 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 14 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :97
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 14 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 14 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :72
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 14 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 14 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :84
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 14 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 14 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :66
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 14 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 14 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :5
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 14 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 14 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :30
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 14 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 14 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :44
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 14 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 14 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :82
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 14 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 14 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :47
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 14 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 14 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 17
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 14 Ends   ===================
INFO:root:Epoch:14 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:14 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 15 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 15 Workers Selected : [6, 15, 34, 60, 20, 33, 85, 93, 50, 9]
INFO:root:FL Epoch: 15 Fraction of points on each worker in this round: [0.01538462 0.01538462 0.04615385 0.04615385 0.01538462 0.46153846
 0.03076923 0.03076923 0.01538462 0.32307692]
INFO:root:FL Epoch: 15 Num points on workers: [ 1  1  3  3  1 30  2  2  1 21]
INFO:root:--------------------------
INFO:root:FL Epoch: 15 Training on worker :6
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 15 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :15
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 15 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :34
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 15 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 15 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :60
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 15 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 15 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :20
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 15 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :33
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.683740
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.657270
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 15 Norm Difference for worker 33 is 0.096437
INFO:root:FL Epoch: 15 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :85
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 15 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 15 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :93
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 15 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 15 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :50
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 15 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :9
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.687615
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.663363
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 9 is 0.094607
INFO:root:FL Epoch: 15 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 6
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 15 Ends   ===================
INFO:root:Epoch:15 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:15 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 16 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 16 Workers Selected : [70, 24, 67, 87, 56, 40, 85, 25, 73, 29]
INFO:root:FL Epoch: 16 Fraction of points on each worker in this round: [0.03703704 0.05555556 0.22222222 0.09259259 0.05555556 0.01851852
 0.03703704 0.44444444 0.01851852 0.01851852]
INFO:root:FL Epoch: 16 Num points on workers: [ 2  3 12  5  3  1  2 24  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 16 Training on worker :70
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 16 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 16 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :24
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 16 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 16 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :67
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 16 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 16 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :87
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 16 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 16 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :56
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 16 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 16 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :40
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 16 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :85
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 16 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 16 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :25
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.683991
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.671919
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 16 Norm Difference for worker 25 is 0.100283
INFO:root:FL Epoch: 16 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :73
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 16 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :29
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 16 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 16 Ends   ===================
INFO:root:Epoch:16 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:16 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 17 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 17 Workers Selected : [73, 67, 14, 32, 96, 4, 77, 83, 53, 45]
INFO:root:FL Epoch: 17 Fraction of points on each worker in this round: [0.02941176 0.35294118 0.17647059 0.11764706 0.02941176 0.02941176
 0.02941176 0.05882353 0.11764706 0.05882353]
INFO:root:FL Epoch: 17 Num points on workers: [ 1 12  6  4  1  1  1  2  4  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 17 Training on worker :73
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 17 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :67
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 17 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 17 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :14
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 17 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 17 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :32
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 17 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 17 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :96
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 17 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :4
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 17 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :77
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 17 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :83
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 17 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 17 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :53
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 17 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 17 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :45
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 17 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 17 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 73
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 17 Ends   ===================
INFO:root:Epoch:17 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:17 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 18 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 18 Workers Selected : [10, 40, 86, 20, 57, 94, 43, 11, 82, 27]
INFO:root:FL Epoch: 18 Fraction of points on each worker in this round: [0.01408451 0.01408451 0.07042254 0.01408451 0.18309859 0.56338028
 0.01408451 0.04225352 0.01408451 0.07042254]
INFO:root:FL Epoch: 18 Num points on workers: [ 1  1  5  1 13 40  1  3  1  5]
INFO:root:--------------------------
INFO:root:FL Epoch: 18 Training on worker :10
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 18 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 18 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :40
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 18 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 18 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :86
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 18 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 18 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :20
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 18 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 18 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :57
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 18 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 18 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :94
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.693376
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.629514
INFO:root:FL Epoch: 18 Norm Difference for worker 94 is 0.295316
INFO:root:FL Epoch: 18 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :43
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 18 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 18 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :11
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 18 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 18 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :82
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 18 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 18 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :27
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 18 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 18 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 10
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 18 Ends   ===================
INFO:root:Epoch:18 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:18 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 19 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 19 Workers Selected : [45, 53, 57, 44, 7, 92, 38, 6, 39, 63]
INFO:root:FL Epoch: 19 Fraction of points on each worker in this round: [0.04651163 0.09302326 0.30232558 0.04651163 0.02325581 0.09302326
 0.02325581 0.02325581 0.30232558 0.04651163]
INFO:root:FL Epoch: 19 Num points on workers: [ 2  4 13  2  1  4  1  1 13  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 19 Training on worker :45
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 19 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 19 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :53
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 19 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 19 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :57
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 19 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 19 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :44
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 19 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 19 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :7
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 19 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :92
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 19 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 19 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :38
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 19 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :6
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 19 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :39
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 19 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 19 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :63
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 19 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 19 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 45
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 19 Ends   ===================
INFO:root:Epoch:19 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:19 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 20 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 20 Workers Selected : [29, 91, 61, 73, 13, 3, 68, 7, 67, 45]
INFO:root:FL Epoch: 20 Fraction of points on each worker in this round: [0.03448276 0.13793103 0.03448276 0.03448276 0.13793103 0.03448276
 0.06896552 0.03448276 0.4137931  0.06896552]
INFO:root:FL Epoch: 20 Num points on workers: [ 1  4  1  1  4  1  2  1 12  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 20 Training on worker :29
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 20 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 20 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :91
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 20 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 20 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :61
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 20 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 20 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :73
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 20 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 20 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :13
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 20 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 20 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :3
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 20 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 20 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :68
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 20 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 20 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :7
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 20 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 20 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :67
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 20 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 20 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :45
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 20 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 20 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 29
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 20 Ends   ===================
INFO:root:Epoch:20 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:20 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 21 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 21 Workers Selected : [27, 85, 76, 24, 81, 34, 65, 6, 75, 53]
INFO:root:FL Epoch: 21 Fraction of points on each worker in this round: [0.17857143 0.07142857 0.14285714 0.10714286 0.10714286 0.10714286
 0.03571429 0.03571429 0.07142857 0.14285714]
INFO:root:FL Epoch: 21 Num points on workers: [5 2 4 3 3 3 1 1 2 4]
INFO:root:--------------------------
INFO:root:FL Epoch: 21 Training on worker :27
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 21 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 21 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :85
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 21 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 21 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :76
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 21 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 21 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :24
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 21 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 21 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :81
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 21 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 21 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :34
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 21 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 21 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :65
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 21 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :6
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 21 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :75
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 21 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 21 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :53
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 21 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 21 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 27
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 21 Ends   ===================
INFO:root:Epoch:21 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:21 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 22 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 22 Workers Selected : [42, 29, 63, 41, 81, 54, 30, 37, 94, 18]
INFO:root:FL Epoch: 22 Fraction of points on each worker in this round: [0.04918033 0.01639344 0.03278689 0.06557377 0.04918033 0.01639344
 0.03278689 0.01639344 0.6557377  0.06557377]
INFO:root:FL Epoch: 22 Num points on workers: [ 3  1  2  4  3  1  2  1 40  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 22 Training on worker :42
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 22 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 22 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :29
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 22 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :63
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 22 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 22 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :41
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 22 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 22 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :81
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 22 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 22 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :54
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 22 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :30
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 22 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 22 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :37
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 22 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :94
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.690572
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.624603
INFO:root:FL Epoch: 22 Norm Difference for worker 94 is 0.294553
INFO:root:FL Epoch: 22 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :18
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 22 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 22 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 22 Ends   ===================
INFO:root:Epoch:22 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:22 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 23 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 23 Workers Selected : [16, 8, 56, 90, 71, 88, 43, 52, 64, 40]
INFO:root:FL Epoch: 23 Fraction of points on each worker in this round: [0.125  0.0625 0.1875 0.125  0.0625 0.0625 0.0625 0.0625 0.1875 0.0625]
INFO:root:FL Epoch: 23 Num points on workers: [2 1 3 2 1 1 1 1 3 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 23 Training on worker :16
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 23 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 23 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :8
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 23 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 23 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :56
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 23 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 23 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :90
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 23 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 23 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :71
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 23 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 23 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :88
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 23 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 23 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :43
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 23 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 23 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :52
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 23 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 23 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :64
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 23 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 23 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :40
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 23 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 23 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 16
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 23 Ends   ===================
INFO:root:Epoch:23 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:23 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 24 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 24 Workers Selected : [31, 58, 82, 86, 16, 84, 65, 45, 90, 87]
INFO:root:FL Epoch: 24 Fraction of points on each worker in this round: [0.02040816 0.36734694 0.02040816 0.10204082 0.04081633 0.24489796
 0.02040816 0.04081633 0.04081633 0.10204082]
INFO:root:FL Epoch: 24 Num points on workers: [ 1 18  1  5  2 12  1  2  2  5]
INFO:root:--------------------------
INFO:root:FL Epoch: 24 Training on worker :31
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 24 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :58
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 24 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 24 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :82
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 24 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :86
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 24 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 24 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :16
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 24 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 24 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :84
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 24 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 24 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :65
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 24 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :45
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 24 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 24 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :90
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 24 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 24 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :87
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 24 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 24 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 31
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 24 Ends   ===================
INFO:root:Epoch:24 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:24 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 25 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 25 Workers Selected : [53, 92, 73, 43, 33, 13, 76, 30, 63, 91]
INFO:root:FL Epoch: 25 Fraction of points on each worker in this round: [0.07142857 0.07142857 0.01785714 0.01785714 0.53571429 0.07142857
 0.07142857 0.03571429 0.03571429 0.07142857]
INFO:root:FL Epoch: 25 Num points on workers: [ 4  4  1  1 30  4  4  2  2  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 25 Training on worker :53
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 25 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 25 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :92
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 25 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 25 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :73
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 25 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :43
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 25 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :33
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.686049
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.666665
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 25 Norm Difference for worker 33 is 0.094831
INFO:root:FL Epoch: 25 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :13
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 25 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 25 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :76
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 25 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 25 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :30
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 25 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 25 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :63
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 25 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 25 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :91
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 25 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 25 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 53
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 25 Ends   ===================
INFO:root:Epoch:25 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:25 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 26 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 26 Workers Selected : [60, 27, 35, 48, 49, 55, 93, 26, 78, 76]
INFO:root:FL Epoch: 26 Fraction of points on each worker in this round: [0.15 0.25 0.05 0.05 0.05 0.05 0.1  0.05 0.05 0.2 ]
INFO:root:FL Epoch: 26 Num points on workers: [3 5 1 1 1 1 2 1 1 4]
INFO:root:--------------------------
INFO:root:FL Epoch: 26 Training on worker :60
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 26 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 26 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :27
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 26 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 26 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :35
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 26 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :48
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 26 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :49
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 26 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :55
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 26 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :93
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 26 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 26 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :26
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 26 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :78
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 26 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :76
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 26 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 26 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 60
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 26 Ends   ===================
INFO:root:Epoch:26 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:26 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 27 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 27 Workers Selected : [29, 69, 44, 64, 18, 58, 35, 73, 70, 24]
INFO:root:FL Epoch: 27 Fraction of points on each worker in this round: [0.01923077 0.32692308 0.03846154 0.05769231 0.07692308 0.34615385
 0.01923077 0.01923077 0.03846154 0.05769231]
INFO:root:FL Epoch: 27 Num points on workers: [ 1 17  2  3  4 18  1  1  2  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 27 Training on worker :29
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 27 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :69
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 27 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 27 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :44
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 27 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 27 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :64
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 27 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 27 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :18
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 27 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 27 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :58
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 27 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 27 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :35
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 27 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :73
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 27 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :70
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 27 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 27 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :24
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 27 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 27 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 29
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 27 Ends   ===================
INFO:root:Epoch:27 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:27 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 28 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 28 Workers Selected : [57, 85, 55, 40, 13, 8, 51, 70, 68, 33]
INFO:root:FL Epoch: 28 Fraction of points on each worker in this round: [0.21666667 0.03333333 0.01666667 0.01666667 0.06666667 0.01666667
 0.06666667 0.03333333 0.03333333 0.5       ]
INFO:root:FL Epoch: 28 Num points on workers: [13  2  1  1  4  1  4  2  2 30]
INFO:root:--------------------------
INFO:root:FL Epoch: 28 Training on worker :57
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 28 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 28 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :85
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 28 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 28 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :55
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 28 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 28 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :40
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 28 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 28 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :13
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 28 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 28 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :8
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 28 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 28 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :51
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 28 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 28 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :70
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 28 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 28 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :68
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 28 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 28 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :33
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.681314
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.663054
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 28 Norm Difference for worker 33 is 0.09532
INFO:root:FL Epoch: 28 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 57
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 28 Ends   ===================
INFO:root:Epoch:28 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:28 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 29 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 29 Workers Selected : [92, 4, 61, 3, 41, 34, 10, 52, 31, 85]
INFO:root:FL Epoch: 29 Fraction of points on each worker in this round: [0.21052632 0.05263158 0.05263158 0.05263158 0.21052632 0.15789474
 0.05263158 0.05263158 0.05263158 0.10526316]
INFO:root:FL Epoch: 29 Num points on workers: [4 1 1 1 4 3 1 1 1 2]
INFO:root:--------------------------
INFO:root:FL Epoch: 29 Training on worker :92
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 29 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 29 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :4
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 29 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 29 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :61
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 29 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 29 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :3
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 29 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 29 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :41
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 29 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 29 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :34
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 29 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 29 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :10
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 29 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 29 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :52
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 29 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 29 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :31
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 29 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 29 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :85
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 29 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 29 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 92
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 29 Ends   ===================
INFO:root:Epoch:29 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:29 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 30 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 30 Workers Selected : [68, 75, 49, 51, 70, 50, 71, 54, 24, 82]
INFO:root:FL Epoch: 30 Fraction of points on each worker in this round: [0.11111111 0.11111111 0.05555556 0.22222222 0.11111111 0.05555556
 0.05555556 0.05555556 0.16666667 0.05555556]
INFO:root:FL Epoch: 30 Num points on workers: [2 2 1 4 2 1 1 1 3 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 30 Training on worker :68
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 30 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 30 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :75
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 30 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 30 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :49
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 30 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :51
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 30 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 30 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :70
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 30 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 30 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :50
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 30 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :71
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 30 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :54
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 30 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :24
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 30 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 30 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :82
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 30 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 68
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 30 Ends   ===================
INFO:root:Epoch:30 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:30 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 31 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 31 Workers Selected : [69, 57, 92, 19, 36, 48, 6, 52, 47, 94]
INFO:root:FL Epoch: 31 Fraction of points on each worker in this round: [0.20481928 0.15662651 0.04819277 0.01204819 0.02409639 0.01204819
 0.01204819 0.01204819 0.03614458 0.48192771]
INFO:root:FL Epoch: 31 Num points on workers: [17 13  4  1  2  1  1  1  3 40]
INFO:root:--------------------------
INFO:root:FL Epoch: 31 Training on worker :69
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 31 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 31 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :57
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 31 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 31 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :92
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 31 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 31 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :19
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 31 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 31 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :36
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 31 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 31 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :48
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 31 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 31 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :6
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 31 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 31 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :52
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 31 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 31 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :47
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 31 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 31 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :94
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.690318
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.626693
INFO:root:FL Epoch: 31 Norm Difference for worker 94 is 0.286738
INFO:root:FL Epoch: 31 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 69
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 31 Ends   ===================
INFO:root:Epoch:31 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:31 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 32 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 32 Workers Selected : [91, 73, 99, 44, 40, 82, 88, 41, 56, 16]
INFO:root:FL Epoch: 32 Fraction of points on each worker in this round: [0.18181818 0.04545455 0.13636364 0.09090909 0.04545455 0.04545455
 0.04545455 0.18181818 0.13636364 0.09090909]
INFO:root:FL Epoch: 32 Num points on workers: [4 1 3 2 1 1 1 4 3 2]
INFO:root:--------------------------
INFO:root:FL Epoch: 32 Training on worker :91
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 32 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 32 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :73
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 32 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :99
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 32 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 32 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :44
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 32 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 32 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :40
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 32 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :82
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 32 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :88
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 32 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :41
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 32 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 32 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :56
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 32 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 32 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :16
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 32 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 32 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 91
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 32 Ends   ===================
INFO:root:Epoch:32 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:32 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 33 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 33 Workers Selected : [12, 36, 17, 87, 29, 45, 20, 69, 94, 95]
INFO:root:FL Epoch: 33 Fraction of points on each worker in this round: [0.01388889 0.02777778 0.02777778 0.06944444 0.01388889 0.02777778
 0.01388889 0.23611111 0.55555556 0.01388889]
INFO:root:FL Epoch: 33 Num points on workers: [ 1  2  2  5  1  2  1 17 40  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 33 Training on worker :12
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 33 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 33 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :36
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 33 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 33 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :17
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 33 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 33 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :87
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 33 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 33 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :29
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 33 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 33 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :45
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 33 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 33 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :20
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 33 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 33 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :69
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 33 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 33 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :94
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.692484
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.626026
INFO:root:FL Epoch: 33 Norm Difference for worker 94 is 0.287294
INFO:root:FL Epoch: 33 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :95
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 33 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 33 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 12
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 33 Ends   ===================
INFO:root:Epoch:33 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:33 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 34 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 34 Workers Selected : [17, 32, 20, 5, 70, 75, 86, 66, 12, 4]
INFO:root:FL Epoch: 34 Fraction of points on each worker in this round: [0.07142857 0.14285714 0.03571429 0.32142857 0.07142857 0.07142857
 0.17857143 0.03571429 0.03571429 0.03571429]
INFO:root:FL Epoch: 34 Num points on workers: [2 4 1 9 2 2 5 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 34 Training on worker :17
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 34 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 34 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :32
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 34 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 34 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :20
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 34 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 34 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :5
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 34 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 34 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :70
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 34 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 34 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :75
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 34 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 34 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :86
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 34 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 34 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :66
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 34 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 34 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :12
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 34 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 34 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :4
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 34 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 34 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 17
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 34 Ends   ===================
INFO:root:Epoch:34 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:34 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 35 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 35 Workers Selected : [67, 10, 50, 84, 35, 99, 8, 49, 19, 82]
INFO:root:FL Epoch: 35 Fraction of points on each worker in this round: [0.35294118 0.02941176 0.02941176 0.35294118 0.02941176 0.08823529
 0.02941176 0.02941176 0.02941176 0.02941176]
INFO:root:FL Epoch: 35 Num points on workers: [12  1  1 12  1  3  1  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 35 Training on worker :67
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 35 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 35 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :10
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 35 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :50
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 35 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :84
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 35 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 35 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :35
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 35 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :99
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 35 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 35 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :8
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 35 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :49
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 35 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :19
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 35 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :82
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 35 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 67
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 35 Ends   ===================
INFO:root:Epoch:35 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:35 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 36 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 36 Workers Selected : [56, 14, 99, 42, 87, 80, 11, 38, 12, 18]
INFO:root:FL Epoch: 36 Fraction of points on each worker in this round: [0.1        0.2        0.1        0.1        0.16666667 0.03333333
 0.1        0.03333333 0.03333333 0.13333333]
INFO:root:FL Epoch: 36 Num points on workers: [3 6 3 3 5 1 3 1 1 4]
INFO:root:--------------------------
INFO:root:FL Epoch: 36 Training on worker :56
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 36 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 36 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :14
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 36 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 36 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :99
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 36 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 36 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :42
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 36 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 36 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :87
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 36 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 36 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :80
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 36 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 36 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :11
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 36 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 36 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :38
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 36 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 36 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :12
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 36 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 36 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :18
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 36 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 36 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 56
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 36 Ends   ===================
INFO:root:Epoch:36 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:36 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 37 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 37 Workers Selected : [63, 13, 89, 68, 59, 90, 16, 94, 8, 20]
INFO:root:FL Epoch: 37 Fraction of points on each worker in this round: [0.03571429 0.07142857 0.01785714 0.03571429 0.01785714 0.03571429
 0.03571429 0.71428571 0.01785714 0.01785714]
INFO:root:FL Epoch: 37 Num points on workers: [ 2  4  1  2  1  2  2 40  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 37 Training on worker :63
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 37 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 37 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :13
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 37 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 37 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :89
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 37 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :68
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 37 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 37 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :59
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 37 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :90
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 37 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 37 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :16
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 37 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 37 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :94
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.696250
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.627666
INFO:root:FL Epoch: 37 Norm Difference for worker 94 is 0.284907
INFO:root:FL Epoch: 37 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :8
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 37 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :20
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 37 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 63
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 37 Ends   ===================
INFO:root:Epoch:37 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:37 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 38 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 38 Workers Selected : [28, 90, 44, 56, 9, 61, 75, 5, 3, 43]
INFO:root:FL Epoch: 38 Fraction of points on each worker in this round: [0.125      0.04166667 0.04166667 0.0625     0.4375     0.02083333
 0.04166667 0.1875     0.02083333 0.02083333]
INFO:root:FL Epoch: 38 Num points on workers: [ 6  2  2  3 21  1  2  9  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 38 Training on worker :28
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 38 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 38 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :90
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 38 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 38 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :44
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 38 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 38 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :56
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 38 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 38 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :9
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.686547
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.666313
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 9 is 0.091698
INFO:root:FL Epoch: 38 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :61
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 38 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :75
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 38 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 38 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :5
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 38 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 38 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :3
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 38 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :43
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 38 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 28
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 38 Ends   ===================
INFO:root:Epoch:38 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:38 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 39 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 39 Workers Selected : [97, 88, 48, 22, 17, 96, 47, 68, 73, 21]
INFO:root:FL Epoch: 39 Fraction of points on each worker in this round: [0.1369863  0.01369863 0.01369863 0.01369863 0.02739726 0.01369863
 0.04109589 0.02739726 0.01369863 0.69863014]
INFO:root:FL Epoch: 39 Num points on workers: [10  1  1  1  2  1  3  2  1 51]
INFO:root:--------------------------
INFO:root:FL Epoch: 39 Training on worker :97
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 39 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 39 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :88
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 39 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 39 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :48
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 39 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 39 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :22
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 39 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 39 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :17
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 39 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 39 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :96
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 39 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 39 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :47
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 39 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 39 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :68
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 39 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 39 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :73
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 39 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 39 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :21
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.696750
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.630130
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 39 Norm Difference for worker 21 is 0.307166
INFO:root:FL Epoch: 39 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 97
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 39 Ends   ===================
INFO:root:Epoch:39 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:39 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 40 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 40 Workers Selected : [46, 80, 77, 73, 48, 81, 41, 4, 23, 96]
INFO:root:FL Epoch: 40 Fraction of points on each worker in this round: [0.04761905 0.04761905 0.04761905 0.04761905 0.04761905 0.14285714
 0.19047619 0.04761905 0.33333333 0.04761905]
INFO:root:FL Epoch: 40 Num points on workers: [1 1 1 1 1 3 4 1 7 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 40 Training on worker :46
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 40 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 40 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :80
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 40 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 40 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :77
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 40 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 40 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :73
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 40 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 40 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :48
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 40 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 40 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :81
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 40 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 40 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :41
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 40 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 40 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :4
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 40 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 40 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :23
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 40 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 40 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :96
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 40 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 40 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 46
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 40 Ends   ===================
INFO:root:Epoch:40 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:40 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 41 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 41 Workers Selected : [36, 82, 99, 58, 75, 11, 65, 87, 3, 26]
INFO:root:FL Epoch: 41 Fraction of points on each worker in this round: [0.05405405 0.02702703 0.08108108 0.48648649 0.05405405 0.08108108
 0.02702703 0.13513514 0.02702703 0.02702703]
INFO:root:FL Epoch: 41 Num points on workers: [ 2  1  3 18  2  3  1  5  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 41 Training on worker :36
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 41 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 41 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :82
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 41 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 41 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :99
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 41 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 41 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :58
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 41 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 41 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :75
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 41 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 41 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :11
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 41 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 41 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :65
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 41 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 41 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :87
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 41 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 41 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :3
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 41 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 41 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :26
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 41 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 41 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 36
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 41 Ends   ===================
INFO:root:Epoch:41 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:41 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 42 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 42 Workers Selected : [4, 48, 60, 33, 8, 99, 97, 35, 18, 53]
INFO:root:FL Epoch: 42 Fraction of points on each worker in this round: [0.01724138 0.01724138 0.05172414 0.51724138 0.01724138 0.05172414
 0.17241379 0.01724138 0.06896552 0.06896552]
INFO:root:FL Epoch: 42 Num points on workers: [ 1  1  3 30  1  3 10  1  4  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 42 Training on worker :4
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 42 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :48
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 42 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :60
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 42 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 42 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :33
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.680853
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.661428
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 42 Norm Difference for worker 33 is 0.091821
INFO:root:FL Epoch: 42 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :8
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 42 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :99
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 42 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 42 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :97
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 42 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 42 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :35
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 42 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :18
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 42 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 42 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :53
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 42 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 42 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 4
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 42 Ends   ===================
INFO:root:Epoch:42 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:42 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 43 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 43 Workers Selected : [30, 73, 20, 91, 96, 86, 65, 14, 28, 85]
INFO:root:FL Epoch: 43 Fraction of points on each worker in this round: [0.06896552 0.03448276 0.03448276 0.13793103 0.03448276 0.17241379
 0.03448276 0.20689655 0.20689655 0.06896552]
INFO:root:FL Epoch: 43 Num points on workers: [2 1 1 4 1 5 1 6 6 2]
INFO:root:--------------------------
INFO:root:FL Epoch: 43 Training on worker :30
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 43 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 43 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :73
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 43 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :20
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 43 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :91
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 43 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 43 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :96
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 43 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :86
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 43 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 43 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :65
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 43 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :14
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 43 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 43 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :28
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 43 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 43 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :85
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 43 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 43 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 30
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 43 Ends   ===================
INFO:root:Epoch:43 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:43 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 44 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 44 Workers Selected : [23, 71, 39, 80, 32, 46, 92, 41, 11, 38]
INFO:root:FL Epoch: 44 Fraction of points on each worker in this round: [0.17948718 0.02564103 0.33333333 0.02564103 0.1025641  0.02564103
 0.1025641  0.1025641  0.07692308 0.02564103]
INFO:root:FL Epoch: 44 Num points on workers: [ 7  1 13  1  4  1  4  4  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 44 Training on worker :23
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 44 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 44 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :71
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 44 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 44 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :39
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 44 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 44 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :80
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 44 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 44 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :32
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 44 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 44 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :46
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 44 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 44 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :92
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 44 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 44 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :41
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 44 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 44 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :11
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 44 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 44 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :38
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 44 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 44 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 23
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 44 Ends   ===================
INFO:root:Epoch:44 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:44 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 45 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 45 Workers Selected : [63, 90, 62, 25, 91, 44, 20, 23, 39, 74]
INFO:root:FL Epoch: 45 Fraction of points on each worker in this round: [0.02666667 0.02666667 0.04       0.32       0.05333333 0.02666667
 0.01333333 0.09333333 0.17333333 0.22666667]
INFO:root:FL Epoch: 45 Num points on workers: [ 2  2  3 24  4  2  1  7 13 17]
INFO:root:--------------------------
INFO:root:FL Epoch: 45 Training on worker :63
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 45 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 45 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :90
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 45 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 45 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :62
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 45 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 45 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :25
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.687753
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.664761
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 45 Norm Difference for worker 25 is 0.09606
INFO:root:FL Epoch: 45 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :91
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 45 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 45 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :44
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 45 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 45 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :20
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 45 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :23
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 45 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 45 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :39
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 45 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 45 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :74
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 45 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 45 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 63
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 45 Ends   ===================
INFO:root:Epoch:45 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:45 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 46 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 46 Workers Selected : [73, 31, 81, 77, 39, 61, 74, 59, 71, 4]
INFO:root:FL Epoch: 46 Fraction of points on each worker in this round: [0.025 0.025 0.075 0.025 0.325 0.025 0.425 0.025 0.025 0.025]
INFO:root:FL Epoch: 46 Num points on workers: [ 1  1  3  1 13  1 17  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 46 Training on worker :73
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 46 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 46 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :31
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 46 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 46 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :81
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 46 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 46 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :77
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 46 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 46 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :39
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 46 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 46 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :61
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 46 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 46 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :74
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 46 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 46 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :59
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 46 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 46 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :71
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 46 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 46 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :4
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 46 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 46 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 73
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 46 Ends   ===================
INFO:root:Epoch:46 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:46 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 47 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 47 Workers Selected : [36, 86, 33, 12, 21, 50, 68, 92, 90, 93]
INFO:root:FL Epoch: 47 Fraction of points on each worker in this round: [0.02 0.05 0.3  0.01 0.51 0.01 0.02 0.04 0.02 0.02]
INFO:root:FL Epoch: 47 Num points on workers: [ 2  5 30  1 51  1  2  4  2  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 47 Training on worker :36
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 47 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 47 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :86
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 47 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 47 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :33
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.686310
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.665468
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 47 Norm Difference for worker 33 is 0.091643
INFO:root:FL Epoch: 47 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :12
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 47 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 47 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :21
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.702420
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.621630
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 47 Norm Difference for worker 21 is 0.30375
INFO:root:FL Epoch: 47 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :50
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 47 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 47 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :68
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 47 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 47 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :92
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 47 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 47 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :90
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 47 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 47 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :93
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 47 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 47 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 36
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 47 Ends   ===================
INFO:root:Epoch:47 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:47 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 48 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 48 Workers Selected : [48, 25, 78, 29, 6, 8, 97, 77, 32, 22]
INFO:root:FL Epoch: 48 Fraction of points on each worker in this round: [0.02222222 0.53333333 0.02222222 0.02222222 0.02222222 0.02222222
 0.22222222 0.02222222 0.08888889 0.02222222]
INFO:root:FL Epoch: 48 Num points on workers: [ 1 24  1  1  1  1 10  1  4  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 48 Training on worker :48
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 48 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :25
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.685113
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.668861
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 48 Norm Difference for worker 25 is 0.094
INFO:root:FL Epoch: 48 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :78
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 48 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :29
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 48 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :6
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 48 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :8
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 48 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :97
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 48 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 48 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :77
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 48 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :32
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 48 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 48 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :22
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 48 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 48
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 48 Ends   ===================
INFO:root:Epoch:48 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:48 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 49 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 49 Workers Selected : [7, 36, 76, 53, 96, 16, 44, 89, 48, 65]
INFO:root:FL Epoch: 49 Fraction of points on each worker in this round: [0.05263158 0.10526316 0.21052632 0.21052632 0.05263158 0.10526316
 0.10526316 0.05263158 0.05263158 0.05263158]
INFO:root:FL Epoch: 49 Num points on workers: [1 2 4 4 1 2 2 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 49 Training on worker :7
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 49 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :36
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 49 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 49 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :76
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 49 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 49 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :53
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 49 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 49 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :96
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 49 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :16
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 49 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 49 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :44
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 49 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 49 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :89
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 49 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :48
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 49 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :65
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 49 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 7
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 49 Ends   ===================
INFO:root:Epoch:49 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:49 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 50 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 50 Workers Selected : [64, 53, 36, 77, 45, 67, 51, 11, 70, 38]
INFO:root:FL Epoch: 50 Fraction of points on each worker in this round: [0.08823529 0.11764706 0.05882353 0.02941176 0.05882353 0.35294118
 0.11764706 0.08823529 0.05882353 0.02941176]
INFO:root:FL Epoch: 50 Num points on workers: [ 3  4  2  1  2 12  4  3  2  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 50 Training on worker :64
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 50 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 50 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :53
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 50 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 50 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :36
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 50 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 50 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :77
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 50 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 50 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :45
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 50 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 50 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :67
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 50 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 50 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :51
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 50 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 50 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :11
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 50 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 50 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :70
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 50 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 50 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :38
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 50 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 50 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 64
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 50 Ends   ===================
INFO:root:Epoch:50 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:50 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 51 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 51 Workers Selected : [49, 11, 90, 33, 67, 47, 36, 51, 80, 39]
INFO:root:FL Epoch: 51 Fraction of points on each worker in this round: [0.01408451 0.04225352 0.02816901 0.42253521 0.16901408 0.04225352
 0.02816901 0.05633803 0.01408451 0.18309859]
INFO:root:FL Epoch: 51 Num points on workers: [ 1  3  2 30 12  3  2  4  1 13]
INFO:root:--------------------------
INFO:root:FL Epoch: 51 Training on worker :49
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 51 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :11
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 51 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 51 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :90
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 51 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 51 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :33
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.688536
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.662868
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 51 Norm Difference for worker 33 is 0.091108
INFO:root:FL Epoch: 51 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :67
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 51 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 51 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :47
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 51 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 51 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :36
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 51 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 51 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :51
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 51 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 51 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :80
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 51 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :39
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 51 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 51 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 49
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 51 Ends   ===================
INFO:root:Epoch:51 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:51 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 52 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 52 Workers Selected : [35, 23, 93, 69, 72, 27, 18, 11, 65, 92]
INFO:root:FL Epoch: 52 Fraction of points on each worker in this round: [0.02 0.14 0.04 0.34 0.12 0.1  0.08 0.06 0.02 0.08]
INFO:root:FL Epoch: 52 Num points on workers: [ 1  7  2 17  6  5  4  3  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 52 Training on worker :35
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 52 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :23
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 52 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 52 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :93
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 52 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 52 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :69
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 52 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 52 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :72
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 52 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 52 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :27
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 52 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 52 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :18
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 52 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 52 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :11
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 52 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 52 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :65
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 52 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :92
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 52 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 52 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 35
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 52 Ends   ===================
INFO:root:Epoch:52 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:52 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 53 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 53 Workers Selected : [13, 38, 79, 37, 44, 23, 56, 71, 29, 3]
INFO:root:FL Epoch: 53 Fraction of points on each worker in this round: [0.17391304 0.04347826 0.08695652 0.04347826 0.08695652 0.30434783
 0.13043478 0.04347826 0.04347826 0.04347826]
INFO:root:FL Epoch: 53 Num points on workers: [4 1 2 1 2 7 3 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 53 Training on worker :13
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 53 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 53 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :38
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 53 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 53 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :79
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 53 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 53 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :37
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 53 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 53 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :44
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 53 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 53 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :23
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 53 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 53 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :56
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 53 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 53 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :71
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 53 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 53 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :29
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 53 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 53 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :3
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 53 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 53 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 13
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 53 Ends   ===================
INFO:root:Epoch:53 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:53 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 54 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 54 Workers Selected : [28, 50, 88, 44, 22, 66, 12, 6, 9, 69]
INFO:root:FL Epoch: 54 Fraction of points on each worker in this round: [0.11538462 0.01923077 0.01923077 0.03846154 0.01923077 0.01923077
 0.01923077 0.01923077 0.40384615 0.32692308]
INFO:root:FL Epoch: 54 Num points on workers: [ 6  1  1  2  1  1  1  1 21 17]
INFO:root:--------------------------
INFO:root:FL Epoch: 54 Training on worker :28
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 54 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 54 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :50
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 54 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :88
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 54 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :44
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 54 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 54 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :22
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 54 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :66
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 54 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :12
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 54 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :6
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 54 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :9
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.692052
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.656006
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 9 is 0.087187
INFO:root:FL Epoch: 54 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :69
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 54 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 54 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 28
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 54 Ends   ===================
INFO:root:Epoch:54 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:54 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 55 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 55 Workers Selected : [32, 9, 89, 93, 53, 20, 13, 55, 94, 10]
INFO:root:FL Epoch: 55 Fraction of points on each worker in this round: [0.05063291 0.26582278 0.01265823 0.02531646 0.05063291 0.01265823
 0.05063291 0.01265823 0.50632911 0.01265823]
INFO:root:FL Epoch: 55 Num points on workers: [ 4 21  1  2  4  1  4  1 40  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 55 Training on worker :32
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 55 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 55 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :9
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.682682
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.658605
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 9 is 0.087832
INFO:root:FL Epoch: 55 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :89
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 55 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :93
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 55 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 55 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :53
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 55 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 55 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :20
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 55 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :13
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 55 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 55 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :55
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 55 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :94
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.692573
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.634041
INFO:root:FL Epoch: 55 Norm Difference for worker 94 is 0.275198
INFO:root:FL Epoch: 55 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :10
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 55 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 32
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 55 Ends   ===================
INFO:root:Epoch:55 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:55 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 56 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 56 Workers Selected : [9, 89, 59, 51, 87, 22, 86, 6, 34, 97]
INFO:root:FL Epoch: 56 Fraction of points on each worker in this round: [0.40384615 0.01923077 0.01923077 0.07692308 0.09615385 0.01923077
 0.09615385 0.01923077 0.05769231 0.19230769]
INFO:root:FL Epoch: 56 Num points on workers: [21  1  1  4  5  1  5  1  3 10]
INFO:root:--------------------------
INFO:root:FL Epoch: 56 Training on worker :9
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.683844
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.664232
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 9 is 0.08922
INFO:root:FL Epoch: 56 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :89
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 56 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :59
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 56 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :51
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 56 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 56 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :87
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 56 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 56 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :22
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 56 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :86
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 56 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 56 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :6
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 56 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :34
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 56 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 56 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :97
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 56 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 56 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 89
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 56 Ends   ===================
INFO:root:Epoch:56 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:56 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 57 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 57 Workers Selected : [90, 79, 69, 25, 68, 48, 58, 32, 55, 35]
INFO:root:FL Epoch: 57 Fraction of points on each worker in this round: [0.02777778 0.02777778 0.23611111 0.33333333 0.02777778 0.01388889
 0.25       0.05555556 0.01388889 0.01388889]
INFO:root:FL Epoch: 57 Num points on workers: [ 2  2 17 24  2  1 18  4  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 57 Training on worker :90
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 57 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 57 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :79
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 57 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 57 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :69
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 57 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 57 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :25
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.690708
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.662777
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 57 Norm Difference for worker 25 is 0.094056
INFO:root:FL Epoch: 57 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :68
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 57 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 57 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :48
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 57 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 57 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :58
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 57 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 57 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :32
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 57 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 57 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :55
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 57 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 57 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :35
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 57 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 57 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 90
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 57 Ends   ===================
INFO:root:Epoch:57 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:57 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 58 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 58 Workers Selected : [31, 42, 3, 84, 52, 33, 99, 22, 10, 55]
INFO:root:FL Epoch: 58 Fraction of points on each worker in this round: [0.01851852 0.05555556 0.01851852 0.22222222 0.01851852 0.55555556
 0.05555556 0.01851852 0.01851852 0.01851852]
INFO:root:FL Epoch: 58 Num points on workers: [ 1  3  1 12  1 30  3  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 58 Training on worker :31
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 58 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 58 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :42
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 58 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 58 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :3
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 58 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 58 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :84
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 58 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 58 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :52
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 58 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 58 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :33
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.684345
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.659311
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 58 Norm Difference for worker 33 is 0.089961
INFO:root:FL Epoch: 58 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :99
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 58 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 58 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :22
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 58 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 58 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :10
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 58 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 58 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :55
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 58 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 58 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 31
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 58 Ends   ===================
INFO:root:Epoch:58 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:58 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 59 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 59 Workers Selected : [77, 3, 92, 96, 93, 28, 67, 26, 63, 53]
INFO:root:FL Epoch: 59 Fraction of points on each worker in this round: [0.02941176 0.02941176 0.11764706 0.02941176 0.05882353 0.17647059
 0.35294118 0.02941176 0.05882353 0.11764706]
INFO:root:FL Epoch: 59 Num points on workers: [ 1  1  4  1  2  6 12  1  2  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 59 Training on worker :77
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 59 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 59 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :3
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 59 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 59 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :92
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 59 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 59 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :96
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 59 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 59 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :93
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 59 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 59 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :28
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 59 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 59 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :67
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 59 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 59 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :26
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 59 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 59 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :63
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 59 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 59 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :53
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 59 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 59 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 77
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 59 Ends   ===================
INFO:root:Epoch:59 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:59 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 60 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 60 Workers Selected : [25, 5, 63, 8, 75, 79, 87, 46, 47, 20]
INFO:root:FL Epoch: 60 Fraction of points on each worker in this round: [0.48 0.18 0.04 0.02 0.04 0.04 0.1  0.02 0.06 0.02]
INFO:root:FL Epoch: 60 Num points on workers: [24  9  2  1  2  2  5  1  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 60 Training on worker :25
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.697478
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.661708
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 60 Norm Difference for worker 25 is 0.092356
INFO:root:FL Epoch: 60 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :5
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 60 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 60 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :63
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 60 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 60 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :8
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 60 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :75
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 60 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 60 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :79
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 60 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 60 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :87
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 60 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 60 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :46
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 60 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :47
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 60 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 60 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :20
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 60 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 5
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 60 Ends   ===================
INFO:root:Epoch:60 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:60 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 61 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 61 Workers Selected : [75, 88, 39, 83, 99, 28, 53, 51, 57, 26]
INFO:root:FL Epoch: 61 Fraction of points on each worker in this round: [0.04081633 0.02040816 0.26530612 0.04081633 0.06122449 0.12244898
 0.08163265 0.08163265 0.26530612 0.02040816]
INFO:root:FL Epoch: 61 Num points on workers: [ 2  1 13  2  3  6  4  4 13  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 61 Training on worker :75
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 61 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 61 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :88
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 61 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :39
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 61 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 61 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :83
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 61 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 61 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :99
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 61 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 61 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :28
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 61 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 61 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :53
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 61 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 61 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :51
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 61 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 61 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :57
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 61 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 61 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :26
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 61 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 75
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 61 Ends   ===================
INFO:root:Epoch:61 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:61 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 62 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 62 Workers Selected : [24, 72, 97, 64, 46, 96, 26, 4, 61, 20]
INFO:root:FL Epoch: 62 Fraction of points on each worker in this round: [0.10714286 0.21428571 0.35714286 0.10714286 0.03571429 0.03571429
 0.03571429 0.03571429 0.03571429 0.03571429]
INFO:root:FL Epoch: 62 Num points on workers: [ 3  6 10  3  1  1  1  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 62 Training on worker :24
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 62 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 62 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :72
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 62 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 62 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :97
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 62 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 62 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :64
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 62 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 62 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :46
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 62 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :96
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 62 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :26
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 62 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :4
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 62 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :61
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 62 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :20
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 62 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 24
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 62 Ends   ===================
INFO:root:Epoch:62 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:62 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 63 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 63 Workers Selected : [17, 42, 77, 25, 46, 41, 88, 27, 90, 91]
INFO:root:FL Epoch: 63 Fraction of points on each worker in this round: [0.04255319 0.06382979 0.0212766  0.5106383  0.0212766  0.08510638
 0.0212766  0.10638298 0.04255319 0.08510638]
INFO:root:FL Epoch: 63 Num points on workers: [ 2  3  1 24  1  4  1  5  2  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 63 Training on worker :17
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 63 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 63 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :42
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 63 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 63 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :77
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 63 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 63 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :25
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.689317
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.665310
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 63 Norm Difference for worker 25 is 0.092321
INFO:root:FL Epoch: 63 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :46
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 63 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 63 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :41
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 63 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 63 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :88
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 63 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 63 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :27
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 63 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 63 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :90
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 63 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 63 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :91
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 63 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 63 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 17
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 63 Ends   ===================
INFO:root:Epoch:63 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:63 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 64 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 64 Workers Selected : [89, 79, 26, 67, 42, 3, 93, 38, 43, 58]
INFO:root:FL Epoch: 64 Fraction of points on each worker in this round: [0.02380952 0.04761905 0.02380952 0.28571429 0.07142857 0.02380952
 0.04761905 0.02380952 0.02380952 0.42857143]
INFO:root:FL Epoch: 64 Num points on workers: [ 1  2  1 12  3  1  2  1  1 18]
INFO:root:--------------------------
INFO:root:FL Epoch: 64 Training on worker :89
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 64 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 64 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :79
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 64 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 64 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :26
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 64 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 64 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :67
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 64 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 64 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :42
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 64 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 64 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :3
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 64 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 64 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :93
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 64 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 64 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :38
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 64 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 64 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :43
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 64 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 64 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :58
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 64 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 64 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 89
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 64 Ends   ===================
INFO:root:Epoch:64 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:64 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 65 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 65 Workers Selected : [51, 86, 39, 40, 70, 44, 95, 77, 92, 63]
INFO:root:FL Epoch: 65 Fraction of points on each worker in this round: [0.11428571 0.14285714 0.37142857 0.02857143 0.05714286 0.05714286
 0.02857143 0.02857143 0.11428571 0.05714286]
INFO:root:FL Epoch: 65 Num points on workers: [ 4  5 13  1  2  2  1  1  4  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 65 Training on worker :51
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 65 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 65 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :86
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 65 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 65 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :39
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 65 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 65 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :40
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 65 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 65 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :70
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 65 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 65 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :44
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 65 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 65 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :95
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 65 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 65 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :77
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 65 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 65 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :92
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 65 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 65 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :63
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 65 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 65 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 51
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 65 Ends   ===================
INFO:root:Epoch:65 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:65 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 66 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 66 Workers Selected : [7, 12, 98, 38, 34, 92, 76, 65, 93, 17]
INFO:root:FL Epoch: 66 Fraction of points on each worker in this round: [0.05 0.05 0.05 0.05 0.15 0.2  0.2  0.05 0.1  0.1 ]
INFO:root:FL Epoch: 66 Num points on workers: [1 1 1 1 3 4 4 1 2 2]
INFO:root:--------------------------
INFO:root:FL Epoch: 66 Training on worker :7
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 66 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :12
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 66 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :98
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 66 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :38
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 66 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :34
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 66 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 66 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :92
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 66 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 66 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :76
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 66 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 66 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :65
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 66 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :93
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 66 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 66 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :17
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 66 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 66 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 7
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 66 Ends   ===================
INFO:root:Epoch:66 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:66 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 67 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 67 Workers Selected : [3, 70, 89, 40, 34, 29, 30, 56, 97, 71]
INFO:root:FL Epoch: 67 Fraction of points on each worker in this round: [0.04 0.08 0.04 0.04 0.12 0.04 0.08 0.12 0.4  0.04]
INFO:root:FL Epoch: 67 Num points on workers: [ 1  2  1  1  3  1  2  3 10  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 67 Training on worker :3
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 67 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :70
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 67 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 67 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :89
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 67 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :40
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 67 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :34
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 67 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 67 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :29
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 67 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :30
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 67 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 67 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :56
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 67 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 67 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :97
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 67 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 67 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :71
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 67 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 3
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 67 Ends   ===================
INFO:root:Epoch:67 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:67 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 68 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 68 Workers Selected : [4, 84, 72, 39, 77, 50, 55, 43, 95, 21]
INFO:root:FL Epoch: 68 Fraction of points on each worker in this round: [0.01136364 0.13636364 0.06818182 0.14772727 0.01136364 0.01136364
 0.01136364 0.01136364 0.01136364 0.57954545]
INFO:root:FL Epoch: 68 Num points on workers: [ 1 12  6 13  1  1  1  1  1 51]
INFO:root:--------------------------
INFO:root:FL Epoch: 68 Training on worker :4
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 68 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :84
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 68 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 68 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :72
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 68 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 68 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :39
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 68 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 68 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :77
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 68 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :50
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 68 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :55
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 68 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :43
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 68 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :95
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 68 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :21
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.695393
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.631349
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 68 Norm Difference for worker 21 is 0.287863
INFO:root:FL Epoch: 68 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 4
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 68 Ends   ===================
INFO:root:Epoch:68 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:68 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 69 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 69 Workers Selected : [98, 90, 14, 68, 95, 85, 35, 91, 28, 50]
INFO:root:FL Epoch: 69 Fraction of points on each worker in this round: [0.03846154 0.07692308 0.23076923 0.07692308 0.03846154 0.07692308
 0.03846154 0.15384615 0.23076923 0.03846154]
INFO:root:FL Epoch: 69 Num points on workers: [1 2 6 2 1 2 1 4 6 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 69 Training on worker :98
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 69 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 69 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :90
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 69 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 69 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :14
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 69 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 69 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :68
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 69 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 69 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :95
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 69 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 69 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :85
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 69 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 69 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :35
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 69 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 69 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :91
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 69 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 69 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :28
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 69 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 69 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :50
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 69 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 69 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 98
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 69 Ends   ===================
INFO:root:Epoch:69 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:69 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 70 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 70 Workers Selected : [76, 50, 43, 12, 46, 59, 34, 83, 39, 27]
INFO:root:FL Epoch: 70 Fraction of points on each worker in this round: [0.125   0.03125 0.03125 0.03125 0.03125 0.03125 0.09375 0.0625  0.40625
 0.15625]
INFO:root:FL Epoch: 70 Num points on workers: [ 4  1  1  1  1  1  3  2 13  5]
INFO:root:--------------------------
INFO:root:FL Epoch: 70 Training on worker :76
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 70 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 70 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :50
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 70 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :43
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 70 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :12
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 70 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :46
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 70 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :59
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 70 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :34
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 70 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 70 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :83
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 70 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 70 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :39
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 70 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 70 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :27
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 70 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 70 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 76
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 70 Ends   ===================
INFO:root:Epoch:70 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:70 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 71 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 71 Workers Selected : [71, 57, 10, 89, 37, 26, 72, 22, 65, 54]
INFO:root:FL Epoch: 71 Fraction of points on each worker in this round: [0.03703704 0.48148148 0.03703704 0.03703704 0.03703704 0.03703704
 0.22222222 0.03703704 0.03703704 0.03703704]
INFO:root:FL Epoch: 71 Num points on workers: [ 1 13  1  1  1  1  6  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 71 Training on worker :71
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 71 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 71 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :57
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 71 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 71 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :10
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 71 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 71 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :89
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 71 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 71 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :37
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 71 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 71 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :26
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 71 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 71 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :72
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 71 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 71 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :22
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 71 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 71 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :65
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 71 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 71 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :54
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 71 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 71 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 71
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 71 Ends   ===================
INFO:root:Epoch:71 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:71 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 72 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 72 Workers Selected : [78, 34, 37, 54, 8, 95, 84, 35, 9, 51]
INFO:root:FL Epoch: 72 Fraction of points on each worker in this round: [0.02173913 0.06521739 0.02173913 0.02173913 0.02173913 0.02173913
 0.26086957 0.02173913 0.45652174 0.08695652]
INFO:root:FL Epoch: 72 Num points on workers: [ 1  3  1  1  1  1 12  1 21  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 72 Training on worker :78
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 72 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :34
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 72 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 72 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :37
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 72 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :54
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 72 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :8
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 72 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :95
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 72 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :84
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 72 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 72 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :35
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 72 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :9
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.680864
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.662580
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 9 is 0.084579
INFO:root:FL Epoch: 72 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :51
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 72 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 72 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 72 Ends   ===================
INFO:root:Epoch:72 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:72 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 73 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 73 Workers Selected : [49, 55, 92, 29, 90, 53, 89, 85, 41, 93]
INFO:root:FL Epoch: 73 Fraction of points on each worker in this round: [0.04545455 0.04545455 0.18181818 0.04545455 0.09090909 0.18181818
 0.04545455 0.09090909 0.18181818 0.09090909]
INFO:root:FL Epoch: 73 Num points on workers: [1 1 4 1 2 4 1 2 4 2]
INFO:root:--------------------------
INFO:root:FL Epoch: 73 Training on worker :49
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 73 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 73 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :55
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 73 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 73 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :92
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 73 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 73 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :29
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 73 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 73 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :90
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 73 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 73 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :53
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 73 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 73 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :89
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 73 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 73 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :85
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 73 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 73 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :41
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 73 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 73 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :93
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 73 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 73 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 49
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 73 Ends   ===================
INFO:root:Epoch:73 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:73 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 74 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 74 Workers Selected : [41, 67, 52, 96, 33, 85, 78, 50, 73, 34]
INFO:root:FL Epoch: 74 Fraction of points on each worker in this round: [0.07142857 0.21428571 0.01785714 0.01785714 0.53571429 0.03571429
 0.01785714 0.01785714 0.01785714 0.05357143]
INFO:root:FL Epoch: 74 Num points on workers: [ 4 12  1  1 30  2  1  1  1  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 74 Training on worker :41
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 74 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 74 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :67
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 74 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 74 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :52
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 74 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :96
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 74 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :33
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.688926
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.669985
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 74 Norm Difference for worker 33 is 0.087997
INFO:root:FL Epoch: 74 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :85
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 74 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 74 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :78
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 74 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :50
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 74 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :73
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 74 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :34
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 74 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 74 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 41
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 74 Ends   ===================
INFO:root:Epoch:74 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:74 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 75 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 75 Workers Selected : [24, 8, 47, 56, 75, 61, 57, 17, 64, 11]
INFO:root:FL Epoch: 75 Fraction of points on each worker in this round: [0.08823529 0.02941176 0.08823529 0.08823529 0.05882353 0.02941176
 0.38235294 0.05882353 0.08823529 0.08823529]
INFO:root:FL Epoch: 75 Num points on workers: [ 3  1  3  3  2  1 13  2  3  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 75 Training on worker :24
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 75 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 75 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :8
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 75 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 75 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :47
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 75 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 75 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :56
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 75 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 75 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :75
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 75 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 75 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :61
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 75 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 75 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :57
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 75 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 75 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :17
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 75 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 75 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :64
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 75 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 75 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :11
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 75 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 75 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 24
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 75 Ends   ===================
INFO:root:Epoch:75 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:75 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 76 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 76 Workers Selected : [86, 32, 8, 22, 3, 49, 73, 29, 82, 38]
INFO:root:FL Epoch: 76 Fraction of points on each worker in this round: [0.29411765 0.23529412 0.05882353 0.05882353 0.05882353 0.05882353
 0.05882353 0.05882353 0.05882353 0.05882353]
INFO:root:FL Epoch: 76 Num points on workers: [5 4 1 1 1 1 1 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 76 Training on worker :86
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 76 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 76 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :32
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 76 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 76 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :8
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 76 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :22
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 76 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :3
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 76 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :49
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 76 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :73
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 76 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :29
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 76 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :82
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 76 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :38
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 76 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 86
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 76 Ends   ===================
INFO:root:Epoch:76 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:76 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 77 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 77 Workers Selected : [13, 97, 63, 28, 76, 26, 3, 10, 43, 69]
INFO:root:FL Epoch: 77 Fraction of points on each worker in this round: [0.08510638 0.21276596 0.04255319 0.12765957 0.08510638 0.0212766
 0.0212766  0.0212766  0.0212766  0.36170213]
INFO:root:FL Epoch: 77 Num points on workers: [ 4 10  2  6  4  1  1  1  1 17]
INFO:root:--------------------------
INFO:root:FL Epoch: 77 Training on worker :13
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 77 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 77 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :97
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 77 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 77 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :63
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 77 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 77 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :28
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 77 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 77 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :76
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 77 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 77 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :26
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 77 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :3
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 77 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :10
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 77 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :43
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 77 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :69
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 77 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 77 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 13
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 77 Ends   ===================
INFO:root:Epoch:77 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:77 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 78 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 78 Workers Selected : [39, 90, 85, 99, 28, 10, 16, 46, 14, 55]
INFO:root:FL Epoch: 78 Fraction of points on each worker in this round: [0.35135135 0.05405405 0.05405405 0.08108108 0.16216216 0.02702703
 0.05405405 0.02702703 0.16216216 0.02702703]
INFO:root:FL Epoch: 78 Num points on workers: [13  2  2  3  6  1  2  1  6  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 78 Training on worker :39
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 78 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 78 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :90
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 78 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 78 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :85
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 78 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 78 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :99
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 78 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 78 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :28
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 78 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 78 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :10
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 78 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 78 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :16
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 78 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 78 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :46
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 78 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 78 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :14
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 78 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 78 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :55
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 78 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 78 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 39
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 78 Ends   ===================
INFO:root:Epoch:78 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:78 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 79 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 79 Workers Selected : [81, 96, 23, 5, 15, 89, 21, 28, 56, 66]
INFO:root:FL Epoch: 79 Fraction of points on each worker in this round: [0.03614458 0.01204819 0.08433735 0.10843373 0.01204819 0.01204819
 0.61445783 0.07228916 0.03614458 0.01204819]
INFO:root:FL Epoch: 79 Num points on workers: [ 3  1  7  9  1  1 51  6  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 79 Training on worker :81
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 79 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 79 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :96
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 79 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :23
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 79 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 79 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :5
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 79 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 79 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :15
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 79 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :89
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 79 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :21
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.694050
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.634841
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 79 Norm Difference for worker 21 is 0.282246
INFO:root:FL Epoch: 79 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :28
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 79 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 79 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :56
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 79 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 79 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :66
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 79 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 81
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 79 Ends   ===================
INFO:root:Epoch:79 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:79 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 80 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 80 Workers Selected : [41, 38, 98, 18, 28, 57, 85, 25, 3, 61]
INFO:root:FL Epoch: 80 Fraction of points on each worker in this round: [0.07017544 0.01754386 0.01754386 0.07017544 0.10526316 0.22807018
 0.03508772 0.42105263 0.01754386 0.01754386]
INFO:root:FL Epoch: 80 Num points on workers: [ 4  1  1  4  6 13  2 24  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 80 Training on worker :41
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 80 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 80 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :38
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 80 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :98
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 80 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :18
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 80 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 80 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :28
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 80 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 80 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :57
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 80 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 80 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :85
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 80 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 80 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :25
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.685582
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.669102
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 80 Norm Difference for worker 25 is 0.088276
INFO:root:FL Epoch: 80 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :3
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 80 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :61
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 80 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 41
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 80 Ends   ===================
INFO:root:Epoch:80 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:80 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 81 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 81 Workers Selected : [48, 3, 81, 10, 21, 75, 80, 6, 63, 16]
INFO:root:FL Epoch: 81 Fraction of points on each worker in this round: [0.01538462 0.01538462 0.04615385 0.01538462 0.78461538 0.03076923
 0.01538462 0.01538462 0.03076923 0.03076923]
INFO:root:FL Epoch: 81 Num points on workers: [ 1  1  3  1 51  2  1  1  2  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 81 Training on worker :48
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 81 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 81 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :3
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 81 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 81 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :81
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 81 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 81 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :10
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 81 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 81 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :21
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.694045
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.626723
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 81 Norm Difference for worker 21 is 0.277887
INFO:root:FL Epoch: 81 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :75
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 81 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 81 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :80
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 81 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 81 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :6
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 81 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 81 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :63
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 81 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 81 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :16
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 81 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 81 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 48
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 81 Ends   ===================
INFO:root:Epoch:81 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:81 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 82 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 82 Workers Selected : [95, 14, 24, 61, 79, 22, 6, 19, 21, 32]
INFO:root:FL Epoch: 82 Fraction of points on each worker in this round: [0.01408451 0.08450704 0.04225352 0.01408451 0.02816901 0.01408451
 0.01408451 0.01408451 0.71830986 0.05633803]
INFO:root:FL Epoch: 82 Num points on workers: [ 1  6  3  1  2  1  1  1 51  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 82 Training on worker :95
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 82 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :14
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 82 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 82 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :24
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 82 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 82 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :61
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 82 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :79
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 82 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 82 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :22
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 82 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :6
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 82 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :19
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 82 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :21
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.699958
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.630036
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 82 Norm Difference for worker 21 is 0.283959
INFO:root:FL Epoch: 82 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :32
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 82 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 82 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 95
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 82 Ends   ===================
INFO:root:Epoch:82 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:82 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 83 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 83 Workers Selected : [62, 49, 61, 83, 80, 11, 58, 90, 37, 96]
INFO:root:FL Epoch: 83 Fraction of points on each worker in this round: [0.09090909 0.03030303 0.03030303 0.06060606 0.03030303 0.09090909
 0.54545455 0.06060606 0.03030303 0.03030303]
INFO:root:FL Epoch: 83 Num points on workers: [ 3  1  1  2  1  3 18  2  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 83 Training on worker :62
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 83 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 83 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :49
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 83 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :61
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 83 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :83
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 83 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 83 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :80
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 83 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :11
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 83 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 83 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :58
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 83 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 83 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :90
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 83 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 83 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :37
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 83 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :96
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 83 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 62
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 83 Ends   ===================
INFO:root:Epoch:83 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:83 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 84 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 84 Workers Selected : [88, 49, 10, 12, 8, 13, 79, 27, 80, 66]
INFO:root:FL Epoch: 84 Fraction of points on each worker in this round: [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.22222222
 0.11111111 0.27777778 0.05555556 0.05555556]
INFO:root:FL Epoch: 84 Num points on workers: [1 1 1 1 1 4 2 5 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 84 Training on worker :88
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 84 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :49
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 84 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :10
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 84 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :12
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 84 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :8
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 84 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :13
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 84 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 84 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :79
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 84 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 84 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :27
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 84 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 84 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :80
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 84 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :66
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 84 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 88
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 84 Ends   ===================
INFO:root:Epoch:84 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:84 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 85 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 85 Workers Selected : [24, 29, 55, 26, 21, 18, 42, 23, 3, 50]
INFO:root:FL Epoch: 85 Fraction of points on each worker in this round: [0.04109589 0.01369863 0.01369863 0.01369863 0.69863014 0.05479452
 0.04109589 0.09589041 0.01369863 0.01369863]
INFO:root:FL Epoch: 85 Num points on workers: [ 3  1  1  1 51  4  3  7  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 85 Training on worker :24
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 85 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 85 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :29
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 85 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :55
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 85 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :26
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 85 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :21
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.705523
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.630192
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 85 Norm Difference for worker 21 is 0.27794
INFO:root:FL Epoch: 85 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :18
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 85 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 85 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :42
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 85 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 85 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :23
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 85 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 85 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :3
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 85 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :50
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 85 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 24
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 85 Ends   ===================
INFO:root:Epoch:85 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:85 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 86 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 86 Workers Selected : [76, 6, 71, 57, 49, 37, 13, 53, 38, 36]
INFO:root:FL Epoch: 86 Fraction of points on each worker in this round: [0.125   0.03125 0.03125 0.40625 0.03125 0.03125 0.125   0.125   0.03125
 0.0625 ]
INFO:root:FL Epoch: 86 Num points on workers: [ 4  1  1 13  1  1  4  4  1  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 86 Training on worker :76
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 86 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 86 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :6
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 86 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :71
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 86 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :57
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 86 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 86 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :49
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 86 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :37
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 86 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :13
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 86 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 86 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :53
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 86 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 86 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :38
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 86 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :36
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 86 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 86 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 76
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 86 Ends   ===================
INFO:root:Epoch:86 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:86 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 87 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 87 Workers Selected : [52, 56, 22, 46, 80, 32, 29, 63, 93, 9]
INFO:root:FL Epoch: 87 Fraction of points on each worker in this round: [0.02702703 0.08108108 0.02702703 0.02702703 0.02702703 0.10810811
 0.02702703 0.05405405 0.05405405 0.56756757]
INFO:root:FL Epoch: 87 Num points on workers: [ 1  3  1  1  1  4  1  2  2 21]
INFO:root:--------------------------
INFO:root:FL Epoch: 87 Training on worker :52
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 87 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 87 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :56
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 87 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 87 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :22
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 87 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 87 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :46
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 87 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 87 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :80
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 87 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 87 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :32
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 87 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 87 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :29
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 87 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 87 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :63
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 87 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 87 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :93
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 87 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 87 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :9
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.684387
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.658776
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 87 Norm Difference for worker 9 is 0.082471
INFO:root:FL Epoch: 87 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 52
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 87 Ends   ===================
INFO:root:Epoch:87 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:87 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 88 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 88 Workers Selected : [81, 8, 44, 83, 57, 78, 88, 72, 65, 84]
INFO:root:FL Epoch: 88 Fraction of points on each worker in this round: [0.07142857 0.02380952 0.04761905 0.04761905 0.30952381 0.02380952
 0.02380952 0.14285714 0.02380952 0.28571429]
INFO:root:FL Epoch: 88 Num points on workers: [ 3  1  2  2 13  1  1  6  1 12]
INFO:root:--------------------------
INFO:root:FL Epoch: 88 Training on worker :81
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 88 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 88 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :8
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 88 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 88 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :44
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 88 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 88 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :83
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 88 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 88 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :57
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 88 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 88 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :78
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 88 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 88 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :88
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 88 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 88 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :72
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 88 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 88 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :65
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 88 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 88 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :84
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 88 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 88 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 81
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 88 Ends   ===================
INFO:root:Epoch:88 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:88 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 89 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 89 Workers Selected : [50, 78, 33, 52, 80, 53, 84, 44, 73, 40]
INFO:root:FL Epoch: 89 Fraction of points on each worker in this round: [0.01851852 0.01851852 0.55555556 0.01851852 0.01851852 0.07407407
 0.22222222 0.03703704 0.01851852 0.01851852]
INFO:root:FL Epoch: 89 Num points on workers: [ 1  1 30  1  1  4 12  2  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 89 Training on worker :50
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 89 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :78
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 89 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :33
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.680905
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.666109
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 89 Norm Difference for worker 33 is 0.085041
INFO:root:FL Epoch: 89 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :52
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 89 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :80
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 89 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :53
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 89 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 89 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :84
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 89 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 89 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :44
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 89 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 89 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :73
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 89 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :40
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 89 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 50
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 89 Ends   ===================
INFO:root:Epoch:89 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:89 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 90 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 90 Workers Selected : [44, 93, 38, 26, 99, 79, 42, 9, 83, 70]
INFO:root:FL Epoch: 90 Fraction of points on each worker in this round: [0.05128205 0.05128205 0.02564103 0.02564103 0.07692308 0.05128205
 0.07692308 0.53846154 0.05128205 0.05128205]
INFO:root:FL Epoch: 90 Num points on workers: [ 2  2  1  1  3  2  3 21  2  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 90 Training on worker :44
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 90 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 90 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :93
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 90 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 90 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :38
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 90 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :26
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 90 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :99
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 90 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 90 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :79
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 90 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 90 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :42
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 90 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 90 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :9
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.682395
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.671211
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 9 is 0.0815
INFO:root:FL Epoch: 90 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :83
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 90 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 90 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :70
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 90 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 90 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 44
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 90 Ends   ===================
INFO:root:Epoch:90 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:90 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 91 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 91 Workers Selected : [74, 94, 71, 54, 3, 24, 91, 65, 95, 15]
INFO:root:FL Epoch: 91 Fraction of points on each worker in this round: [0.24285714 0.57142857 0.01428571 0.01428571 0.01428571 0.04285714
 0.05714286 0.01428571 0.01428571 0.01428571]
INFO:root:FL Epoch: 91 Num points on workers: [17 40  1  1  1  3  4  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 91 Training on worker :74
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 91 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 91 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :94
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.688327
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.635916
INFO:root:FL Epoch: 91 Norm Difference for worker 94 is 0.257537
INFO:root:FL Epoch: 91 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :71
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 91 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 91 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :54
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 91 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 91 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :3
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 91 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 91 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :24
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 91 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 91 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :91
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 91 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 91 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :65
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 91 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 91 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :95
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 91 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 91 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :15
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 91 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 91 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 74
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 91 Ends   ===================
INFO:root:Epoch:91 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:91 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 92 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 92 Workers Selected : [94, 20, 60, 95, 23, 53, 33, 74, 47, 38]
INFO:root:FL Epoch: 92 Fraction of points on each worker in this round: [0.37383178 0.00934579 0.02803738 0.00934579 0.06542056 0.03738318
 0.28037383 0.1588785  0.02803738 0.00934579]
INFO:root:FL Epoch: 92 Num points on workers: [40  1  3  1  7  4 30 17  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 92 Training on worker :94
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.696311
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.641396
INFO:root:FL Epoch: 92 Norm Difference for worker 94 is 0.257206
INFO:root:FL Epoch: 92 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :20
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 92 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 92 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :60
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 92 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 92 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :95
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 92 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 92 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :23
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 92 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 92 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :53
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 92 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 92 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :33
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.685608
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.665238
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 92 Norm Difference for worker 33 is 0.0839
INFO:root:FL Epoch: 92 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :74
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 92 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 92 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :47
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 92 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 92 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :38
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 92 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 92 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 20
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 92 Ends   ===================
INFO:root:Epoch:92 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:92 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 93 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 93 Workers Selected : [90, 65, 47, 61, 40, 62, 99, 20, 85, 87]
INFO:root:FL Epoch: 93 Fraction of points on each worker in this round: [0.09090909 0.04545455 0.13636364 0.04545455 0.04545455 0.13636364
 0.13636364 0.04545455 0.09090909 0.22727273]
INFO:root:FL Epoch: 93 Num points on workers: [2 1 3 1 1 3 3 1 2 5]
INFO:root:--------------------------
INFO:root:FL Epoch: 93 Training on worker :90
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 93 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 93 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :65
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 93 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :47
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 93 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 93 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :61
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 93 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :40
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 93 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :62
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 93 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 93 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :99
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 93 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 93 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :20
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 93 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :85
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 93 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 93 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :87
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 93 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 93 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 90
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 93 Ends   ===================
INFO:root:Epoch:93 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:93 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 94 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 94 Workers Selected : [52, 53, 38, 51, 77, 3, 57, 23, 54, 61]
INFO:root:FL Epoch: 94 Fraction of points on each worker in this round: [0.02941176 0.11764706 0.02941176 0.11764706 0.02941176 0.02941176
 0.38235294 0.20588235 0.02941176 0.02941176]
INFO:root:FL Epoch: 94 Num points on workers: [ 1  4  1  4  1  1 13  7  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 94 Training on worker :52
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 94 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :53
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 94 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 94 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :38
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 94 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :51
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 94 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 94 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :77
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 94 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :3
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 94 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :57
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 94 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 94 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :23
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 94 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 94 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :54
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 94 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :61
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 94 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 52
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 94 Ends   ===================
INFO:root:Epoch:94 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:94 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 95 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 95 Workers Selected : [47, 16, 69, 62, 75, 63, 32, 30, 28, 81]
INFO:root:FL Epoch: 95 Fraction of points on each worker in this round: [0.06818182 0.04545455 0.38636364 0.06818182 0.04545455 0.04545455
 0.09090909 0.04545455 0.13636364 0.06818182]
INFO:root:FL Epoch: 95 Num points on workers: [ 3  2 17  3  2  2  4  2  6  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 95 Training on worker :47
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 95 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 95 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :16
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 95 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 95 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :69
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 95 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 95 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :62
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 95 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 95 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :75
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 95 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 95 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :63
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 95 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 95 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :32
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 95 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 95 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :30
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 95 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 95 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :28
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 95 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 95 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :81
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 95 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 95 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 47
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 95 Ends   ===================
INFO:root:Epoch:95 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:95 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 96 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 96 Workers Selected : [32, 37, 51, 39, 3, 56, 36, 11, 9, 70]
INFO:root:FL Epoch: 96 Fraction of points on each worker in this round: [0.07407407 0.01851852 0.07407407 0.24074074 0.01851852 0.05555556
 0.03703704 0.05555556 0.38888889 0.03703704]
INFO:root:FL Epoch: 96 Num points on workers: [ 4  1  4 13  1  3  2  3 21  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 96 Training on worker :32
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 96 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 96 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :37
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 96 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :51
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 96 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 96 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :39
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 96 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 96 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :3
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 96 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :56
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 96 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 96 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :36
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 96 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 96 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :11
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 96 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 96 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :9
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.681661
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.664601
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 9 is 0.081941
INFO:root:FL Epoch: 96 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :70
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 96 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 96 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 32
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 96 Ends   ===================
INFO:root:Epoch:96 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:96 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 97 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 97 Workers Selected : [82, 97, 94, 64, 29, 95, 34, 71, 91, 70]
INFO:root:FL Epoch: 97 Fraction of points on each worker in this round: [0.01515152 0.15151515 0.60606061 0.04545455 0.01515152 0.01515152
 0.04545455 0.01515152 0.06060606 0.03030303]
INFO:root:FL Epoch: 97 Num points on workers: [ 1 10 40  3  1  1  3  1  4  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 97 Training on worker :82
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 97 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :97
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 97 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 97 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :94
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.698099
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.643690
INFO:root:FL Epoch: 97 Norm Difference for worker 94 is 0.255405
INFO:root:FL Epoch: 97 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :64
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 97 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 97 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :29
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 97 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :95
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 97 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :34
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 97 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 97 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :71
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 97 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :91
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 97 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 97 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :70
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 97 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 97 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 82
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 97 Ends   ===================
INFO:root:Epoch:97 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:97 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 98 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 98 Workers Selected : [90, 79, 27, 64, 35, 59, 96, 81, 84, 74]
INFO:root:FL Epoch: 98 Fraction of points on each worker in this round: [0.04255319 0.04255319 0.10638298 0.06382979 0.0212766  0.0212766
 0.0212766  0.06382979 0.25531915 0.36170213]
INFO:root:FL Epoch: 98 Num points on workers: [ 2  2  5  3  1  1  1  3 12 17]
INFO:root:--------------------------
INFO:root:FL Epoch: 98 Training on worker :90
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 98 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 98 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :79
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 98 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 98 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :27
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 98 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 98 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :64
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 98 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 98 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :35
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 98 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 98 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :59
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 98 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 98 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :96
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 98 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 98 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :81
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 98 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 98 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :84
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 98 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 98 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :74
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 98 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 98 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 90
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 98 Ends   ===================
INFO:root:Epoch:98 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:98 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 99 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 99 Workers Selected : [54, 84, 97, 99, 37, 70, 81, 74, 88, 5]
INFO:root:FL Epoch: 99 Fraction of points on each worker in this round: [0.01694915 0.20338983 0.16949153 0.05084746 0.01694915 0.03389831
 0.05084746 0.28813559 0.01694915 0.15254237]
INFO:root:FL Epoch: 99 Num points on workers: [ 1 12 10  3  1  2  3 17  1  9]
INFO:root:--------------------------
INFO:root:FL Epoch: 99 Training on worker :54
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 99 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :84
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 99 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 99 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :97
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 99 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 99 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :99
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 99 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 99 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :37
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 99 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :70
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 99 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 99 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :81
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 99 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 99 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :74
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 99 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 99 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :88
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 99 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :5
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 99 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 99 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 54
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 99 Ends   ===================
INFO:root:Epoch:99 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:99 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 100 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 100 Workers Selected : [29, 90, 53, 35, 30, 95, 41, 87, 59, 62]
INFO:root:FL Epoch: 100 Fraction of points on each worker in this round: [0.04166667 0.08333333 0.16666667 0.04166667 0.08333333 0.04166667
 0.16666667 0.20833333 0.04166667 0.125     ]
INFO:root:FL Epoch: 100 Num points on workers: [1 2 4 1 2 1 4 5 1 3]
INFO:root:--------------------------
INFO:root:FL Epoch: 100 Training on worker :29
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 100 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 100 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :90
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 100 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 100 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :53
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 100 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 100 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :35
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 100 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 100 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :30
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 100 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 100 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :95
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 100 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 100 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :41
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 100 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 100 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :87
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 100 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 100 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :59
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 100 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 100 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :62
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 100 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 100 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 29
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 100 Saving Checkpoint at this epoch.
INFO:root:FL Epoch: 100 Saved Checkpoint at this epoch.
INFO:root:================FL round 100 Ends   ===================
INFO:root:Epoch:100 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:100 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 101 Begins ===================
INFO:root:FL Epoch: 101 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 101 Workers Selected : [0, 1, 2, 52, 64, 41, 58, 81, 25, 54]
INFO:root:FL Epoch: 101 Fraction of points on each worker in this round: [0.3058104  0.3058104  0.3058104  0.00152905 0.00458716 0.00611621
 0.02752294 0.00458716 0.03669725 0.00152905]
INFO:root:FL Epoch: 101 Num points on workers: [200 200 200   1   3   4  18   3  24   1]
INFO:root:--------------------------
INFO:root:FL Epoch: 101 Training on worker :0
INFO:root:FL Epoch: 101 Using Learning rate : 0.008185668046884278 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696382
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688970
INFO:root:FL Epoch: 101 Worker: 0 Backdoor Test Loss: 0.7411357561747233 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 101 Worker: 0 Backdoor Train Loss: 0.6846343755722046 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 101 Norm Difference for worker 0 is 0.109578
INFO:root:FL Epoch: 101 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1
INFO:root:FL Epoch: 101 Using Learning rate : 0.008185668046884278 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697702
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696191
INFO:root:FL Epoch: 101 Worker: 1 Backdoor Test Loss: 0.7343939344088236 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 101 Worker: 1 Backdoor Train Loss: 0.6854736626148223 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 101 Norm Difference for worker 1 is 0.100474
INFO:root:FL Epoch: 101 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :2
INFO:root:FL Epoch: 101 Using Learning rate : 0.008185668046884278 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692795
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700114
INFO:root:FL Epoch: 101 Worker: 2 Backdoor Test Loss: 0.7321087221304575 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 101 Worker: 2 Backdoor Train Loss: 0.6854381024837494 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 101 Norm Difference for worker 2 is 0.099987
INFO:root:FL Epoch: 101 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :52
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 101 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 101 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :64
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 101 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 101 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :41
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 101 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 101 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :58
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 101 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 101 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :81
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 101 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 101 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :25
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.684533
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.669629
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 101 Norm Difference for worker 25 is 0.085231
INFO:root:FL Epoch: 101 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :54
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 101 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 101 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 52
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 101 Ends   ===================
INFO:root:Epoch:101 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:101 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 102 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 102 Workers Selected : [90, 74, 96, 30, 8, 42, 55, 77, 70, 38]
INFO:root:FL Epoch: 102 Fraction of points on each worker in this round: [0.06451613 0.5483871  0.03225806 0.06451613 0.03225806 0.09677419
 0.03225806 0.03225806 0.06451613 0.03225806]
INFO:root:FL Epoch: 102 Num points on workers: [ 2 17  1  2  1  3  1  1  2  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 102 Training on worker :90
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 102 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 102 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :74
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 102 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 102 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :96
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 102 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :30
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 102 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 102 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :8
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 102 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :42
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 102 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 102 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :55
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 102 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :77
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 102 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :70
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 102 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 102 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :38
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 102 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 90
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 102 Ends   ===================
INFO:root:Epoch:102 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:102 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 103 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 103 Workers Selected : [80, 78, 94, 73, 8, 71, 95, 31, 90, 39]
INFO:root:FL Epoch: 103 Fraction of points on each worker in this round: [0.01612903 0.01612903 0.64516129 0.01612903 0.01612903 0.01612903
 0.01612903 0.01612903 0.03225806 0.20967742]
INFO:root:FL Epoch: 103 Num points on workers: [ 1  1 40  1  1  1  1  1  2 13]
INFO:root:--------------------------
INFO:root:FL Epoch: 103 Training on worker :80
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 103 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :78
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 103 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :94
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.694259
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.638795
INFO:root:FL Epoch: 103 Norm Difference for worker 94 is 0.250288
INFO:root:FL Epoch: 103 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :73
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 103 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :8
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 103 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :71
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 103 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :95
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 103 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :31
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 103 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :90
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 103 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 103 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :39
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 103 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 103 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 80
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 103 Ends   ===================
INFO:root:Epoch:103 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:103 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 104 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 104 Workers Selected : [47, 99, 79, 53, 16, 94, 96, 51, 31, 37]
INFO:root:FL Epoch: 104 Fraction of points on each worker in this round: [0.04918033 0.04918033 0.03278689 0.06557377 0.03278689 0.6557377
 0.01639344 0.06557377 0.01639344 0.01639344]
INFO:root:FL Epoch: 104 Num points on workers: [ 3  3  2  4  2 40  1  4  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 104 Training on worker :47
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 104 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 104 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :99
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 104 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 104 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :79
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 104 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 104 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :53
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 104 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 104 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :16
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 104 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 104 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :94
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.690528
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.633588
INFO:root:FL Epoch: 104 Norm Difference for worker 94 is 0.251139
INFO:root:FL Epoch: 104 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :96
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 104 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :51
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 104 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 104 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :31
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 104 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :37
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 104 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 47
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 104 Ends   ===================
INFO:root:Epoch:104 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:104 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 105 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 105 Workers Selected : [76, 14, 73, 36, 35, 42, 24, 57, 44, 96]
INFO:root:FL Epoch: 105 Fraction of points on each worker in this round: [0.11111111 0.16666667 0.02777778 0.05555556 0.02777778 0.08333333
 0.08333333 0.36111111 0.05555556 0.02777778]
INFO:root:FL Epoch: 105 Num points on workers: [ 4  6  1  2  1  3  3 13  2  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 105 Training on worker :76
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 105 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 105 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :14
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 105 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 105 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :73
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 105 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 105 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :36
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 105 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 105 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :35
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 105 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 105 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :42
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 105 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 105 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :24
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 105 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 105 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :57
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 105 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 105 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :44
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 105 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 105 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :96
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 105 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 105 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 76
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 105 Ends   ===================
INFO:root:Epoch:105 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:105 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 106 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 106 Workers Selected : [70, 32, 21, 81, 10, 63, 36, 72, 37, 97]
INFO:root:FL Epoch: 106 Fraction of points on each worker in this round: [0.02439024 0.04878049 0.62195122 0.03658537 0.01219512 0.02439024
 0.02439024 0.07317073 0.01219512 0.12195122]
INFO:root:FL Epoch: 106 Num points on workers: [ 2  4 51  3  1  2  2  6  1 10]
INFO:root:--------------------------
INFO:root:FL Epoch: 106 Training on worker :70
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 106 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 106 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :32
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 106 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 106 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :21
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.698200
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.635886
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 106 Norm Difference for worker 21 is 0.269258
INFO:root:FL Epoch: 106 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :81
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 106 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 106 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :10
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 106 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :63
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 106 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 106 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :36
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 106 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 106 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :72
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 106 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 106 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :37
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 106 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :97
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 106 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 106 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 106 Ends   ===================
INFO:root:Epoch:106 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:106 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 107 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 107 Workers Selected : [47, 85, 87, 28, 10, 37, 7, 77, 66, 54]
INFO:root:FL Epoch: 107 Fraction of points on each worker in this round: [0.13636364 0.09090909 0.22727273 0.27272727 0.04545455 0.04545455
 0.04545455 0.04545455 0.04545455 0.04545455]
INFO:root:FL Epoch: 107 Num points on workers: [3 2 5 6 1 1 1 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 107 Training on worker :47
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 107 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 107 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :85
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 107 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 107 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :87
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 107 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 107 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :28
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 107 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 107 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :10
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 107 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :37
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 107 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :7
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 107 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :77
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 107 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :66
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 107 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :54
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 107 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 47
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 107 Ends   ===================
INFO:root:Epoch:107 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:107 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 108 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 108 Workers Selected : [10, 23, 99, 38, 58, 12, 31, 71, 17, 41]
INFO:root:FL Epoch: 108 Fraction of points on each worker in this round: [0.02564103 0.17948718 0.07692308 0.02564103 0.46153846 0.02564103
 0.02564103 0.02564103 0.05128205 0.1025641 ]
INFO:root:FL Epoch: 108 Num points on workers: [ 1  7  3  1 18  1  1  1  2  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 108 Training on worker :10
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 108 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :23
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 108 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 108 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :99
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 108 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 108 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :38
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 108 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :58
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 108 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 108 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :12
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 108 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :31
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 108 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :71
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 108 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :17
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 108 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 108 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :41
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 108 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 108 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 10
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 108 Ends   ===================
INFO:root:Epoch:108 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:108 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 109 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 109 Workers Selected : [67, 95, 38, 98, 83, 47, 17, 36, 10, 88]
INFO:root:FL Epoch: 109 Fraction of points on each worker in this round: [0.46153846 0.03846154 0.03846154 0.03846154 0.07692308 0.11538462
 0.07692308 0.07692308 0.03846154 0.03846154]
INFO:root:FL Epoch: 109 Num points on workers: [12  1  1  1  2  3  2  2  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 109 Training on worker :67
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 109 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 109 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :95
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 109 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :38
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 109 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :98
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 109 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :83
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 109 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 109 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :47
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 109 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 109 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :17
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 109 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 109 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :36
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 109 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 109 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :10
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 109 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :88
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 109 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 67
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 109 Ends   ===================
INFO:root:Epoch:109 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:109 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 110 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 110 Workers Selected : [98, 82, 37, 66, 95, 68, 29, 17, 39, 60]
INFO:root:FL Epoch: 110 Fraction of points on each worker in this round: [0.03846154 0.03846154 0.03846154 0.03846154 0.03846154 0.07692308
 0.03846154 0.07692308 0.5        0.11538462]
INFO:root:FL Epoch: 110 Num points on workers: [ 1  1  1  1  1  2  1  2 13  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 110 Training on worker :98
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 110 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :82
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 110 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :37
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 110 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :66
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 110 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :95
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 110 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :68
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 110 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 110 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :29
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 110 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :17
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 110 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 110 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :39
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 110 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 110 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :60
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 110 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 110 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 98
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 110 Ends   ===================
INFO:root:Epoch:110 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:110 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 111 Begins ===================
INFO:root:FL Epoch: 111 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 111 Workers Selected : [0, 1, 2, 78, 31, 98, 4, 26, 60, 86]
INFO:root:FL Epoch: 111 Fraction of points on each worker in this round: [0.32626427 0.32626427 0.32626427 0.00163132 0.00163132 0.00163132
 0.00163132 0.00163132 0.00489396 0.00815661]
INFO:root:FL Epoch: 111 Num points on workers: [200 200 200   1   1   1   1   1   3   5]
INFO:root:--------------------------
INFO:root:FL Epoch: 111 Training on worker :0
INFO:root:FL Epoch: 111 Using Learning rate : 0.00802342027539165 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690479
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707588
INFO:root:FL Epoch: 111 Worker: 0 Backdoor Test Loss: 0.7379226982593536 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 111 Worker: 0 Backdoor Train Loss: 0.6850967764854431 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 111 Norm Difference for worker 0 is 0.103698
INFO:root:FL Epoch: 111 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1
INFO:root:FL Epoch: 111 Using Learning rate : 0.00802342027539165 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698527
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698144
INFO:root:FL Epoch: 111 Worker: 1 Backdoor Test Loss: 0.738013486067454 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 111 Worker: 1 Backdoor Train Loss: 0.6852431833744049 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 111 Norm Difference for worker 1 is 0.102667
INFO:root:FL Epoch: 111 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :2
INFO:root:FL Epoch: 111 Using Learning rate : 0.00802342027539165 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691076
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699456
INFO:root:FL Epoch: 111 Worker: 2 Backdoor Test Loss: 0.7394043306509653 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 111 Worker: 2 Backdoor Train Loss: 0.6851693332195282 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 111 Norm Difference for worker 2 is 0.103962
INFO:root:FL Epoch: 111 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :78
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 111 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :31
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 111 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :98
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 111 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :4
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 111 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :26
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 111 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :60
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 111 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 111 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :86
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 111 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 111 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 111 Ends   ===================
INFO:root:Epoch:111 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:111 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 112 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 112 Workers Selected : [88, 73, 49, 94, 44, 53, 35, 37, 74, 82]
INFO:root:FL Epoch: 112 Fraction of points on each worker in this round: [0.01449275 0.01449275 0.01449275 0.57971014 0.02898551 0.05797101
 0.01449275 0.01449275 0.24637681 0.01449275]
INFO:root:FL Epoch: 112 Num points on workers: [ 1  1  1 40  2  4  1  1 17  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 112 Training on worker :88
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 112 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :73
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 112 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :49
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 112 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :94
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.694520
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.634997
INFO:root:FL Epoch: 112 Norm Difference for worker 94 is 0.246335
INFO:root:FL Epoch: 112 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :44
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 112 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 112 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :53
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 112 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 112 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :35
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 112 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :37
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 112 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :74
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 112 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 112 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :82
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 112 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 88
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 112 Ends   ===================
INFO:root:Epoch:112 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:112 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 113 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 113 Workers Selected : [37, 9, 98, 15, 95, 51, 32, 91, 83, 27]
INFO:root:FL Epoch: 113 Fraction of points on each worker in this round: [0.02272727 0.47727273 0.02272727 0.02272727 0.02272727 0.09090909
 0.09090909 0.09090909 0.04545455 0.11363636]
INFO:root:FL Epoch: 113 Num points on workers: [ 1 21  1  1  1  4  4  4  2  5]
INFO:root:--------------------------
INFO:root:FL Epoch: 113 Training on worker :37
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 113 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :9
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.680946
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.664407
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 9 is 0.077996
INFO:root:FL Epoch: 113 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :98
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 113 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :15
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 113 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :95
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 113 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :51
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 113 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 113 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :32
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 113 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 113 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :91
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 113 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 113 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :83
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 113 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 113 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :27
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 113 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 113 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 37
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 113 Ends   ===================
INFO:root:Epoch:113 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:113 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 114 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 114 Workers Selected : [17, 92, 10, 28, 58, 51, 70, 11, 41, 85]
INFO:root:FL Epoch: 114 Fraction of points on each worker in this round: [0.04347826 0.08695652 0.02173913 0.13043478 0.39130435 0.08695652
 0.04347826 0.06521739 0.08695652 0.04347826]
INFO:root:FL Epoch: 114 Num points on workers: [ 2  4  1  6 18  4  2  3  4  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 114 Training on worker :17
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 114 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 114 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :92
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 114 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 114 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :10
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 114 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 114 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :28
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 114 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 114 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :58
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 114 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 114 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :51
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 114 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 114 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :70
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 114 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 114 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :11
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 114 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 114 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :41
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 114 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 114 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :85
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 114 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 114 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 17
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 114 Ends   ===================
INFO:root:Epoch:114 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:114 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 115 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 115 Workers Selected : [59, 31, 29, 52, 77, 14, 26, 88, 36, 57]
INFO:root:FL Epoch: 115 Fraction of points on each worker in this round: [0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.21428571
 0.03571429 0.03571429 0.07142857 0.46428571]
INFO:root:FL Epoch: 115 Num points on workers: [ 1  1  1  1  1  6  1  1  2 13]
INFO:root:--------------------------
INFO:root:FL Epoch: 115 Training on worker :59
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 115 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 115 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :31
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 115 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 115 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :29
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 115 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 115 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :52
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 115 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 115 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :77
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 115 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 115 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :14
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 115 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 115 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :26
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 115 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 115 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :88
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 115 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 115 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :36
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 115 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 115 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :57
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 115 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 115 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 59
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 115 Ends   ===================
INFO:root:Epoch:115 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:115 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 116 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 116 Workers Selected : [96, 90, 63, 24, 56, 99, 87, 70, 95, 92]
INFO:root:FL Epoch: 116 Fraction of points on each worker in this round: [0.03846154 0.07692308 0.07692308 0.11538462 0.11538462 0.11538462
 0.19230769 0.07692308 0.03846154 0.15384615]
INFO:root:FL Epoch: 116 Num points on workers: [1 2 2 3 3 3 5 2 1 4]
INFO:root:--------------------------
INFO:root:FL Epoch: 116 Training on worker :96
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 116 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :90
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 116 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 116 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :63
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 116 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 116 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :24
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 116 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 116 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :56
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 116 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 116 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :99
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 116 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 116 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :87
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 116 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 116 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :70
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 116 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 116 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :95
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 116 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :92
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 116 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 116 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 96
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 116 Ends   ===================
INFO:root:Epoch:116 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:116 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 117 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 117 Workers Selected : [3, 41, 35, 88, 60, 94, 46, 7, 50, 38]
INFO:root:FL Epoch: 117 Fraction of points on each worker in this round: [0.01851852 0.07407407 0.01851852 0.01851852 0.05555556 0.74074074
 0.01851852 0.01851852 0.01851852 0.01851852]
INFO:root:FL Epoch: 117 Num points on workers: [ 1  4  1  1  3 40  1  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 117 Training on worker :3
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 117 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :41
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 117 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 117 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :35
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 117 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :88
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 117 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :60
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 117 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 117 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :94
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.693736
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.634215
INFO:root:FL Epoch: 117 Norm Difference for worker 94 is 0.247233
INFO:root:FL Epoch: 117 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :46
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 117 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :7
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 117 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :50
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 117 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :38
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 117 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 3
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 117 Ends   ===================
INFO:root:Epoch:117 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:117 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 118 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 118 Workers Selected : [51, 45, 33, 32, 61, 71, 93, 70, 77, 48]
INFO:root:FL Epoch: 118 Fraction of points on each worker in this round: [0.08333333 0.04166667 0.625      0.08333333 0.02083333 0.02083333
 0.04166667 0.04166667 0.02083333 0.02083333]
INFO:root:FL Epoch: 118 Num points on workers: [ 4  2 30  4  1  1  2  2  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 118 Training on worker :51
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 118 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 118 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :45
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 118 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 118 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :33
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.682791
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.672139
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 118 Norm Difference for worker 33 is 0.079963
INFO:root:FL Epoch: 118 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :32
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 118 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 118 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :61
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 118 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :71
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 118 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :93
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 118 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 118 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :70
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 118 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 118 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :77
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 118 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :48
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 118 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 51
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 118 Ends   ===================
INFO:root:Epoch:118 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:118 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 119 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 119 Workers Selected : [98, 23, 79, 63, 69, 17, 94, 58, 72, 60]
INFO:root:FL Epoch: 119 Fraction of points on each worker in this round: [0.01020408 0.07142857 0.02040816 0.02040816 0.17346939 0.02040816
 0.40816327 0.18367347 0.06122449 0.03061224]
INFO:root:FL Epoch: 119 Num points on workers: [ 1  7  2  2 17  2 40 18  6  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 119 Training on worker :98
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 119 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 119 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :23
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 119 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 119 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :79
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 119 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 119 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :63
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 119 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 119 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :69
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 119 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 119 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :17
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 119 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 119 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :94
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.693648
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.638670
INFO:root:FL Epoch: 119 Norm Difference for worker 94 is 0.242449
INFO:root:FL Epoch: 119 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :58
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 119 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 119 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :72
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 119 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 119 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :60
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 119 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 119 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 98
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 119 Ends   ===================
INFO:root:Epoch:119 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:119 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 120 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 120 Workers Selected : [68, 88, 79, 40, 46, 25, 11, 44, 81, 26]
INFO:root:FL Epoch: 120 Fraction of points on each worker in this round: [0.05  0.025 0.05  0.025 0.025 0.6   0.075 0.05  0.075 0.025]
INFO:root:FL Epoch: 120 Num points on workers: [ 2  1  2  1  1 24  3  2  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 120 Training on worker :68
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 120 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 120 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :88
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 120 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 120 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :79
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 120 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 120 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :40
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 120 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 120 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :46
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 120 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 120 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :25
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.690159
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.669390
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 120 Norm Difference for worker 25 is 0.083298
INFO:root:FL Epoch: 120 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :11
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 120 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 120 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :44
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 120 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 120 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :81
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 120 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 120 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :26
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 120 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 120 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 68
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 120 Ends   ===================
INFO:root:Epoch:120 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:120 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 121 Begins ===================
INFO:root:FL Epoch: 121 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 121 Workers Selected : [0, 1, 2, 46, 68, 17, 45, 76, 84, 51]
INFO:root:FL Epoch: 121 Fraction of points on each worker in this round: [0.31897927 0.31897927 0.31897927 0.0015949  0.00318979 0.00318979
 0.00318979 0.00637959 0.01913876 0.00637959]
INFO:root:FL Epoch: 121 Num points on workers: [200 200 200   1   2   2   2   4  12   4]
INFO:root:--------------------------
INFO:root:FL Epoch: 121 Training on worker :0
INFO:root:FL Epoch: 121 Using Learning rate : 0.007864388409944021 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694851
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694937
INFO:root:FL Epoch: 121 Worker: 0 Backdoor Test Loss: 0.7323616147041321 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 121 Worker: 0 Backdoor Train Loss: 0.6854988515377045 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 121 Norm Difference for worker 0 is 0.099075
INFO:root:FL Epoch: 121 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1
INFO:root:FL Epoch: 121 Using Learning rate : 0.007864388409944021 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693386
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692925
INFO:root:FL Epoch: 121 Worker: 1 Backdoor Test Loss: 0.7341994742552439 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 121 Worker: 1 Backdoor Train Loss: 0.6855037152767182 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 121 Norm Difference for worker 1 is 0.098643
INFO:root:FL Epoch: 121 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :2
INFO:root:FL Epoch: 121 Using Learning rate : 0.007864388409944021 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689473
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686251
INFO:root:FL Epoch: 121 Worker: 2 Backdoor Test Loss: 0.7355939348538717 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 121 Worker: 2 Backdoor Train Loss: 0.6852877795696258 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 121 Norm Difference for worker 2 is 0.100995
INFO:root:FL Epoch: 121 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :46
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 121 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 121 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :68
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 121 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 121 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :17
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 121 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 121 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :45
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 121 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 121 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :76
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 121 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 121 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :84
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 121 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 121 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :51
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 121 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 121 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 46
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 121 Ends   ===================
INFO:root:Epoch:121 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:121 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 122 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 122 Workers Selected : [89, 80, 25, 98, 29, 66, 41, 7, 28, 57]
INFO:root:FL Epoch: 122 Fraction of points on each worker in this round: [0.01886792 0.01886792 0.45283019 0.01886792 0.01886792 0.01886792
 0.0754717  0.01886792 0.11320755 0.24528302]
INFO:root:FL Epoch: 122 Num points on workers: [ 1  1 24  1  1  1  4  1  6 13]
INFO:root:--------------------------
INFO:root:FL Epoch: 122 Training on worker :89
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 122 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :80
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 122 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :25
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.687754
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.669002
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 122 Norm Difference for worker 25 is 0.081004
INFO:root:FL Epoch: 122 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :98
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 122 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :29
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 122 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :66
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 122 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :41
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 122 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 122 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :7
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 122 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :28
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 122 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 122 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :57
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 122 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 122 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 89
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 122 Ends   ===================
INFO:root:Epoch:122 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:122 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 123 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 123 Workers Selected : [6, 14, 12, 4, 45, 93, 24, 83, 74, 23]
INFO:root:FL Epoch: 123 Fraction of points on each worker in this round: [0.02380952 0.14285714 0.02380952 0.02380952 0.04761905 0.04761905
 0.07142857 0.04761905 0.4047619  0.16666667]
INFO:root:FL Epoch: 123 Num points on workers: [ 1  6  1  1  2  2  3  2 17  7]
INFO:root:--------------------------
INFO:root:FL Epoch: 123 Training on worker :6
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 123 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :14
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 123 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 123 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :12
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 123 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :4
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 123 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :45
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 123 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 123 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :93
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 123 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 123 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :24
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 123 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 123 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :83
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 123 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 123 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :74
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 123 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 123 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :23
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 123 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 123 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 6
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 123 Ends   ===================
INFO:root:Epoch:123 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:123 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 124 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 124 Workers Selected : [72, 75, 52, 92, 40, 86, 45, 4, 78, 16]
INFO:root:FL Epoch: 124 Fraction of points on each worker in this round: [0.24 0.08 0.04 0.16 0.04 0.2  0.08 0.04 0.04 0.08]
INFO:root:FL Epoch: 124 Num points on workers: [6 2 1 4 1 5 2 1 1 2]
INFO:root:--------------------------
INFO:root:FL Epoch: 124 Training on worker :72
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 124 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 124 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :75
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 124 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 124 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :52
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 124 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 124 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :92
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 124 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 124 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :40
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 124 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 124 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :86
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 124 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 124 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :45
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 124 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 124 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :4
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 124 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 124 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :78
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 124 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 124 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :16
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 124 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 124 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 72
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 124 Ends   ===================
INFO:root:Epoch:124 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:124 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 125 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 125 Workers Selected : [99, 57, 61, 53, 84, 62, 39, 27, 10, 79]
INFO:root:FL Epoch: 125 Fraction of points on each worker in this round: [0.05263158 0.22807018 0.01754386 0.07017544 0.21052632 0.05263158
 0.22807018 0.0877193  0.01754386 0.03508772]
INFO:root:FL Epoch: 125 Num points on workers: [ 3 13  1  4 12  3 13  5  1  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 125 Training on worker :99
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 125 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 125 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :57
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 125 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 125 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :61
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 125 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 125 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :53
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 125 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 125 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :84
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 125 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 125 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :62
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 125 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 125 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :39
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 125 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 125 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :27
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 125 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 125 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :10
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 125 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 125 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :79
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 125 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 125 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 99
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 125 Ends   ===================
INFO:root:Epoch:125 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:125 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 126 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 126 Workers Selected : [7, 38, 47, 68, 51, 52, 57, 44, 67, 69]
INFO:root:FL Epoch: 126 Fraction of points on each worker in this round: [0.01785714 0.01785714 0.05357143 0.03571429 0.07142857 0.01785714
 0.23214286 0.03571429 0.21428571 0.30357143]
INFO:root:FL Epoch: 126 Num points on workers: [ 1  1  3  2  4  1 13  2 12 17]
INFO:root:--------------------------
INFO:root:FL Epoch: 126 Training on worker :7
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 126 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :38
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 126 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :47
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 126 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 126 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :68
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 126 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 126 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :51
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 126 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 126 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :52
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 126 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :57
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 126 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 126 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :44
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 126 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 126 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :67
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 126 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 126 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :69
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 126 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 126 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 7
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 126 Ends   ===================
INFO:root:Epoch:126 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:126 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 127 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 127 Workers Selected : [8, 18, 48, 28, 53, 75, 3, 65, 7, 20]
INFO:root:FL Epoch: 127 Fraction of points on each worker in this round: [0.04545455 0.18181818 0.04545455 0.27272727 0.18181818 0.09090909
 0.04545455 0.04545455 0.04545455 0.04545455]
INFO:root:FL Epoch: 127 Num points on workers: [1 4 1 6 4 2 1 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 127 Training on worker :8
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 127 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 127 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :18
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 127 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 127 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :48
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 127 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 127 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :28
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 127 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 127 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :53
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 127 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 127 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :75
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 127 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 127 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :3
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 127 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 127 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :65
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 127 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 127 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :7
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 127 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 127 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :20
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 127 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 127 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 8
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 127 Ends   ===================
INFO:root:Epoch:127 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:127 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 128 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 128 Workers Selected : [17, 87, 90, 5, 13, 81, 62, 6, 12, 78]
INFO:root:FL Epoch: 128 Fraction of points on each worker in this round: [0.06451613 0.16129032 0.06451613 0.29032258 0.12903226 0.09677419
 0.09677419 0.03225806 0.03225806 0.03225806]
INFO:root:FL Epoch: 128 Num points on workers: [2 5 2 9 4 3 3 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 128 Training on worker :17
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 128 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 128 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :87
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 128 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 128 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :90
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 128 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 128 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :5
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 128 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 128 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :13
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 128 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 128 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :81
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 128 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 128 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :62
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 128 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 128 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :6
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 128 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :12
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 128 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :78
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 128 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 17
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 128 Ends   ===================
INFO:root:Epoch:128 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:128 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 129 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 129 Workers Selected : [70, 83, 4, 65, 57, 6, 87, 8, 38, 84]
INFO:root:FL Epoch: 129 Fraction of points on each worker in this round: [0.05128205 0.05128205 0.02564103 0.02564103 0.33333333 0.02564103
 0.12820513 0.02564103 0.02564103 0.30769231]
INFO:root:FL Epoch: 129 Num points on workers: [ 2  2  1  1 13  1  5  1  1 12]
INFO:root:--------------------------
INFO:root:FL Epoch: 129 Training on worker :70
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 129 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 129 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :83
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 129 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 129 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :4
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 129 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 129 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :65
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 129 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 129 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :57
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 129 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 129 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :6
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 129 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 129 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :87
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 129 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 129 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :8
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 129 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 129 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :38
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 129 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 129 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :84
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 129 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 129 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 129 Ends   ===================
INFO:root:Epoch:129 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:129 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 130 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 130 Workers Selected : [95, 29, 79, 87, 61, 20, 13, 70, 37, 12]
INFO:root:FL Epoch: 130 Fraction of points on each worker in this round: [0.05263158 0.05263158 0.10526316 0.26315789 0.05263158 0.05263158
 0.21052632 0.10526316 0.05263158 0.05263158]
INFO:root:FL Epoch: 130 Num points on workers: [1 1 2 5 1 1 4 2 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 130 Training on worker :95
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 130 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :29
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 130 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :79
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 130 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 130 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :87
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 130 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 130 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :61
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 130 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :20
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 130 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :13
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 130 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 130 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :70
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 130 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 130 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :37
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 130 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :12
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 130 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 95
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 130 Ends   ===================
INFO:root:Epoch:130 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:130 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 131 Begins ===================
INFO:root:FL Epoch: 131 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 131 Workers Selected : [0, 1, 2, 48, 28, 26, 54, 60, 49, 96]
INFO:root:FL Epoch: 131 Fraction of points on each worker in this round: [0.3257329  0.3257329  0.3257329  0.00162866 0.00977199 0.00162866
 0.00162866 0.00488599 0.00162866 0.00162866]
INFO:root:FL Epoch: 131 Num points on workers: [200 200 200   1   6   1   1   3   1   1]
INFO:root:--------------------------
INFO:root:FL Epoch: 131 Training on worker :0
INFO:root:FL Epoch: 131 Using Learning rate : 0.00770850870820709 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697414
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682837
INFO:root:FL Epoch: 131 Worker: 0 Backdoor Test Loss: 0.7360690931479136 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 131 Worker: 0 Backdoor Train Loss: 0.685366404056549 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 131 Norm Difference for worker 0 is 0.10002
INFO:root:FL Epoch: 131 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1
INFO:root:FL Epoch: 131 Using Learning rate : 0.00770850870820709 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695334
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690112
INFO:root:FL Epoch: 131 Worker: 1 Backdoor Test Loss: 0.7308049400647482 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 131 Worker: 1 Backdoor Train Loss: 0.6859303712844849 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 131 Norm Difference for worker 1 is 0.094265
INFO:root:FL Epoch: 131 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :2
INFO:root:FL Epoch: 131 Using Learning rate : 0.00770850870820709 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693284
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694633
INFO:root:FL Epoch: 131 Worker: 2 Backdoor Test Loss: 0.7399977048238119 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 131 Worker: 2 Backdoor Train Loss: 0.6852259933948517 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 131 Norm Difference for worker 2 is 0.103086
INFO:root:FL Epoch: 131 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :48
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 131 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :28
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 131 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 131 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :26
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 131 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :54
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 131 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :60
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 131 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 131 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :49
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 131 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :96
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 131 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 48
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 131 Ends   ===================
INFO:root:Epoch:131 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:131 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 132 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 132 Workers Selected : [73, 34, 16, 77, 54, 13, 97, 38, 44, 40]
INFO:root:FL Epoch: 132 Fraction of points on each worker in this round: [0.03846154 0.11538462 0.07692308 0.03846154 0.03846154 0.15384615
 0.38461538 0.03846154 0.07692308 0.03846154]
INFO:root:FL Epoch: 132 Num points on workers: [ 1  3  2  1  1  4 10  1  2  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 132 Training on worker :73
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 132 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :34
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 132 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 132 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :16
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 132 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 132 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :77
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 132 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :54
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 132 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :13
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 132 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 132 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :97
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 132 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 132 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :38
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 132 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :44
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 132 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 132 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :40
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 132 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 73
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 132 Ends   ===================
INFO:root:Epoch:132 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:132 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 133 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 133 Workers Selected : [90, 18, 56, 85, 79, 88, 39, 27, 77, 38]
INFO:root:FL Epoch: 133 Fraction of points on each worker in this round: [0.05882353 0.11764706 0.08823529 0.05882353 0.05882353 0.02941176
 0.38235294 0.14705882 0.02941176 0.02941176]
INFO:root:FL Epoch: 133 Num points on workers: [ 2  4  3  2  2  1 13  5  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 133 Training on worker :90
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 133 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 133 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :18
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 133 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 133 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :56
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 133 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 133 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :85
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 133 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 133 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :79
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 133 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 133 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :88
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 133 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 133 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :39
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 133 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 133 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :27
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 133 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 133 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :77
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 133 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 133 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :38
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 133 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 133 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 90
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 133 Ends   ===================
INFO:root:Epoch:133 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:133 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 134 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 134 Workers Selected : [99, 86, 4, 47, 62, 77, 68, 45, 90, 20]
INFO:root:FL Epoch: 134 Fraction of points on each worker in this round: [0.13043478 0.2173913  0.04347826 0.13043478 0.13043478 0.04347826
 0.08695652 0.08695652 0.08695652 0.04347826]
INFO:root:FL Epoch: 134 Num points on workers: [3 5 1 3 3 1 2 2 2 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 134 Training on worker :99
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 134 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 134 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :86
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 134 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 134 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :4
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 134 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :47
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 134 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 134 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :62
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 134 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 134 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :77
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 134 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :68
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 134 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 134 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :45
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 134 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 134 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :90
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 134 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 134 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :20
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 134 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 99
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 134 Ends   ===================
INFO:root:Epoch:134 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:134 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 135 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 135 Workers Selected : [71, 36, 74, 89, 4, 11, 51, 59, 73, 70]
INFO:root:FL Epoch: 135 Fraction of points on each worker in this round: [0.03030303 0.06060606 0.51515152 0.03030303 0.03030303 0.09090909
 0.12121212 0.03030303 0.03030303 0.06060606]
INFO:root:FL Epoch: 135 Num points on workers: [ 1  2 17  1  1  3  4  1  1  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 135 Training on worker :71
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 135 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :36
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 135 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 135 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :74
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 135 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 135 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :89
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 135 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :4
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 135 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :11
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 135 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 135 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :51
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 135 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 135 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :59
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 135 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :73
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 135 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :70
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 135 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 135 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 71
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 135 Ends   ===================
INFO:root:Epoch:135 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:135 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 136 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 136 Workers Selected : [42, 71, 33, 81, 63, 22, 37, 56, 50, 25]
INFO:root:FL Epoch: 136 Fraction of points on each worker in this round: [0.04347826 0.01449275 0.43478261 0.04347826 0.02898551 0.01449275
 0.01449275 0.04347826 0.01449275 0.34782609]
INFO:root:FL Epoch: 136 Num points on workers: [ 3  1 30  3  2  1  1  3  1 24]
INFO:root:--------------------------
INFO:root:FL Epoch: 136 Training on worker :42
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 136 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 136 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :71
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 136 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :33
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.688149
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.669713
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 136 Norm Difference for worker 33 is 0.077325
INFO:root:FL Epoch: 136 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :81
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 136 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 136 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :63
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 136 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 136 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :22
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 136 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :37
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 136 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :56
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 136 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 136 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :50
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 136 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :25
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.692018
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.675220
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 136 Norm Difference for worker 25 is 0.079423
INFO:root:FL Epoch: 136 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 136 Ends   ===================
INFO:root:Epoch:136 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:136 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 137 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 137 Workers Selected : [39, 37, 3, 10, 58, 49, 42, 35, 21, 90]
INFO:root:FL Epoch: 137 Fraction of points on each worker in this round: [0.14130435 0.01086957 0.01086957 0.01086957 0.19565217 0.01086957
 0.0326087  0.01086957 0.55434783 0.02173913]
INFO:root:FL Epoch: 137 Num points on workers: [13  1  1  1 18  1  3  1 51  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 137 Training on worker :39
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 137 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 137 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :37
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 137 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :3
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 137 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :10
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 137 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :58
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 137 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 137 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :49
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 137 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :42
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 137 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 137 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :35
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 137 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :21
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.696499
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.634436
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 137 Norm Difference for worker 21 is 0.253822
INFO:root:FL Epoch: 137 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :90
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 137 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 137 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 39
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 137 Ends   ===================
INFO:root:Epoch:137 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:137 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 138 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 138 Workers Selected : [29, 92, 51, 77, 10, 98, 95, 28, 78, 34]
INFO:root:FL Epoch: 138 Fraction of points on each worker in this round: [0.04347826 0.17391304 0.17391304 0.04347826 0.04347826 0.04347826
 0.04347826 0.26086957 0.04347826 0.13043478]
INFO:root:FL Epoch: 138 Num points on workers: [1 4 4 1 1 1 1 6 1 3]
INFO:root:--------------------------
INFO:root:FL Epoch: 138 Training on worker :29
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 138 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :92
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 138 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 138 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :51
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 138 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 138 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :77
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 138 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :10
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 138 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :98
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 138 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :95
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 138 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :28
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 138 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 138 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :78
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 138 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :34
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 138 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 138 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 29
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 138 Ends   ===================
INFO:root:Epoch:138 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:138 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 139 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 139 Workers Selected : [97, 87, 9, 74, 27, 16, 66, 61, 6, 34]
INFO:root:FL Epoch: 139 Fraction of points on each worker in this round: [0.15151515 0.07575758 0.31818182 0.25757576 0.07575758 0.03030303
 0.01515152 0.01515152 0.01515152 0.04545455]
INFO:root:FL Epoch: 139 Num points on workers: [10  5 21 17  5  2  1  1  1  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 139 Training on worker :97
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 139 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 139 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :87
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 139 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 139 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :9
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.684607
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.670044
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 139 Norm Difference for worker 9 is 0.073712
INFO:root:FL Epoch: 139 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :74
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 139 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 139 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :27
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 139 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 139 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :16
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 139 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 139 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :66
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 139 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 139 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :61
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 139 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 139 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :6
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 139 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 139 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :34
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 139 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 139 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 97
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 139 Ends   ===================
INFO:root:Epoch:139 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:139 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 140 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 140 Workers Selected : [73, 90, 51, 33, 44, 75, 31, 68, 85, 18]
INFO:root:FL Epoch: 140 Fraction of points on each worker in this round: [0.02 0.04 0.08 0.6  0.04 0.04 0.02 0.04 0.04 0.08]
INFO:root:FL Epoch: 140 Num points on workers: [ 1  2  4 30  2  2  1  2  2  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 140 Training on worker :73
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 140 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :90
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 140 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 140 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :51
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 140 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 140 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :33
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.690197
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.665481
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 140 Norm Difference for worker 33 is 0.076549
INFO:root:FL Epoch: 140 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :44
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 140 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 140 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :75
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 140 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 140 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :31
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 140 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :68
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 140 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 140 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :85
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 140 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 140 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :18
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 140 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 140 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 73
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 140 Ends   ===================
INFO:root:Epoch:140 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:140 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 141 Begins ===================
INFO:root:FL Epoch: 141 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 141 Workers Selected : [0, 1, 2, 27, 45, 33, 70, 66, 84, 31]
INFO:root:FL Epoch: 141 Fraction of points on each worker in this round: [0.30627871 0.30627871 0.30627871 0.00765697 0.00306279 0.04594181
 0.00306279 0.00153139 0.01837672 0.00153139]
INFO:root:FL Epoch: 141 Num points on workers: [200 200 200   5   2  30   2   1  12   1]
INFO:root:--------------------------
INFO:root:FL Epoch: 141 Training on worker :0
INFO:root:FL Epoch: 141 Using Learning rate : 0.007555718691280597 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693471
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693356
INFO:root:FL Epoch: 141 Worker: 0 Backdoor Test Loss: 0.7335428992907206 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 141 Worker: 0 Backdoor Train Loss: 0.685854697227478 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 141 Norm Difference for worker 0 is 0.0946
INFO:root:FL Epoch: 141 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1
INFO:root:FL Epoch: 141 Using Learning rate : 0.007555718691280597 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693662
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693581
INFO:root:FL Epoch: 141 Worker: 1 Backdoor Test Loss: 0.7373271385828654 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 141 Worker: 1 Backdoor Train Loss: 0.6855174124240875 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 141 Norm Difference for worker 1 is 0.098684
INFO:root:FL Epoch: 141 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :2
INFO:root:FL Epoch: 141 Using Learning rate : 0.007555718691280597 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696181
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694198
INFO:root:FL Epoch: 141 Worker: 2 Backdoor Test Loss: 0.7370193401972452 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 141 Worker: 2 Backdoor Train Loss: 0.685608696937561 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 141 Norm Difference for worker 2 is 0.098104
INFO:root:FL Epoch: 141 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :27
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 141 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 141 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :45
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 141 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 141 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :33
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.688679
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.664894
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 141 Norm Difference for worker 33 is 0.076676
INFO:root:FL Epoch: 141 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :70
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 141 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 141 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :66
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 141 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 141 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :84
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 141 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 141 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :31
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 141 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 141 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 27
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 141 Ends   ===================
INFO:root:Epoch:141 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:141 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 142 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 142 Workers Selected : [61, 72, 27, 35, 67, 94, 48, 81, 26, 50]
INFO:root:FL Epoch: 142 Fraction of points on each worker in this round: [0.01408451 0.08450704 0.07042254 0.01408451 0.16901408 0.56338028
 0.01408451 0.04225352 0.01408451 0.01408451]
INFO:root:FL Epoch: 142 Num points on workers: [ 1  6  5  1 12 40  1  3  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 142 Training on worker :61
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 142 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :72
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 142 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 142 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :27
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 142 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 142 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :35
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 142 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :67
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 142 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 142 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :94
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.693509
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.640836
INFO:root:FL Epoch: 142 Norm Difference for worker 94 is 0.234399
INFO:root:FL Epoch: 142 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :48
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 142 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :81
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 142 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 142 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :26
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 142 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :50
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 142 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 61
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 142 Ends   ===================
INFO:root:Epoch:142 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:142 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 143 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 143 Workers Selected : [72, 66, 88, 84, 5, 35, 71, 25, 94, 13]
INFO:root:FL Epoch: 143 Fraction of points on each worker in this round: [0.06060606 0.01010101 0.01010101 0.12121212 0.09090909 0.01010101
 0.01010101 0.24242424 0.4040404  0.04040404]
INFO:root:FL Epoch: 143 Num points on workers: [ 6  1  1 12  9  1  1 24 40  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 143 Training on worker :72
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 143 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 143 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :66
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 143 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :88
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 143 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :84
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 143 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 143 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :5
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 143 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 143 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :35
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 143 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :71
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 143 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :25
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.692728
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.669977
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 143 Norm Difference for worker 25 is 0.07905
INFO:root:FL Epoch: 143 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :94
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.687870
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.638150
INFO:root:FL Epoch: 143 Norm Difference for worker 94 is 0.233142
INFO:root:FL Epoch: 143 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :13
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 143 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 143 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 72
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 143 Ends   ===================
INFO:root:Epoch:143 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:143 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 144 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 144 Workers Selected : [26, 8, 57, 7, 13, 91, 37, 12, 47, 9]
INFO:root:FL Epoch: 144 Fraction of points on each worker in this round: [0.02 0.02 0.26 0.02 0.08 0.08 0.02 0.02 0.06 0.42]
INFO:root:FL Epoch: 144 Num points on workers: [ 1  1 13  1  4  4  1  1  3 21]
INFO:root:--------------------------
INFO:root:FL Epoch: 144 Training on worker :26
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 144 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 144 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :8
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 144 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 144 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :57
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 144 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 144 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :7
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 144 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 144 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :13
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 144 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 144 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :91
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 144 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 144 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :37
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 144 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 144 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :12
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 144 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 144 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :47
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 144 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 144 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :9
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.684526
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.669051
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 144 Norm Difference for worker 9 is 0.073785
INFO:root:FL Epoch: 144 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 26
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 144 Ends   ===================
INFO:root:Epoch:144 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:144 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 145 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 145 Workers Selected : [78, 31, 75, 20, 38, 23, 57, 35, 85, 11]
INFO:root:FL Epoch: 145 Fraction of points on each worker in this round: [0.03125 0.03125 0.0625  0.03125 0.03125 0.21875 0.40625 0.03125 0.0625
 0.09375]
INFO:root:FL Epoch: 145 Num points on workers: [ 1  1  2  1  1  7 13  1  2  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 145 Training on worker :78
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 145 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 145 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :31
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 145 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 145 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :75
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 145 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 145 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :20
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 145 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 145 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :38
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 145 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 145 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :23
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 145 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 145 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :57
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 145 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 145 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :35
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 145 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 145 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :85
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 145 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 145 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :11
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 145 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 145 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 145 Ends   ===================
INFO:root:Epoch:145 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:145 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 146 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 146 Workers Selected : [95, 43, 26, 42, 78, 84, 99, 41, 8, 38]
INFO:root:FL Epoch: 146 Fraction of points on each worker in this round: [0.03571429 0.03571429 0.03571429 0.10714286 0.03571429 0.42857143
 0.10714286 0.14285714 0.03571429 0.03571429]
INFO:root:FL Epoch: 146 Num points on workers: [ 1  1  1  3  1 12  3  4  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 146 Training on worker :95
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 146 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :43
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 146 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :26
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 146 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :42
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 146 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 146 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :78
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 146 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :84
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 146 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 146 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :99
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 146 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 146 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :41
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 146 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 146 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :8
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 146 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :38
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 146 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 95
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 146 Ends   ===================
INFO:root:Epoch:146 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:146 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 147 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 147 Workers Selected : [45, 31, 61, 7, 73, 83, 93, 71, 72, 80]
INFO:root:FL Epoch: 147 Fraction of points on each worker in this round: [0.11111111 0.05555556 0.05555556 0.05555556 0.05555556 0.11111111
 0.11111111 0.05555556 0.33333333 0.05555556]
INFO:root:FL Epoch: 147 Num points on workers: [2 1 1 1 1 2 2 1 6 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 147 Training on worker :45
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 147 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 147 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :31
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 147 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :61
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 147 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :7
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 147 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :73
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 147 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :83
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 147 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 147 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :93
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 147 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 147 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :71
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 147 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :72
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 147 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 147 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :80
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 147 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 45
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 147 Ends   ===================
INFO:root:Epoch:147 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:147 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 148 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 148 Workers Selected : [88, 63, 45, 36, 25, 82, 95, 16, 97, 7]
INFO:root:FL Epoch: 148 Fraction of points on each worker in this round: [0.02173913 0.04347826 0.04347826 0.04347826 0.52173913 0.02173913
 0.02173913 0.04347826 0.2173913  0.02173913]
INFO:root:FL Epoch: 148 Num points on workers: [ 1  2  2  2 24  1  1  2 10  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 148 Training on worker :88
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 148 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :63
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 148 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 148 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :45
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 148 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 148 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :36
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 148 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 148 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :25
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.691243
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.672248
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 148 Norm Difference for worker 25 is 0.07779
INFO:root:FL Epoch: 148 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :82
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 148 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :95
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 148 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :16
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 148 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 148 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :97
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 148 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 148 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :7
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 148 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 88
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 148 Ends   ===================
INFO:root:Epoch:148 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:148 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 149 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 149 Workers Selected : [42, 41, 34, 19, 59, 24, 76, 72, 73, 32]
INFO:root:FL Epoch: 149 Fraction of points on each worker in this round: [0.1        0.13333333 0.1        0.03333333 0.03333333 0.1
 0.13333333 0.2        0.03333333 0.13333333]
INFO:root:FL Epoch: 149 Num points on workers: [3 4 3 1 1 3 4 6 1 4]
INFO:root:--------------------------
INFO:root:FL Epoch: 149 Training on worker :42
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 149 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 149 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :41
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 149 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 149 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :34
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 149 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 149 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :19
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 149 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :59
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 149 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :24
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 149 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 149 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :76
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 149 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 149 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :72
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 149 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 149 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :73
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 149 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :32
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 149 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 149 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 149 Ends   ===================
INFO:root:Epoch:149 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:149 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 150 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 150 Workers Selected : [88, 47, 21, 78, 89, 6, 36, 39, 99, 22]
INFO:root:FL Epoch: 150 Fraction of points on each worker in this round: [0.01298701 0.03896104 0.66233766 0.01298701 0.01298701 0.01298701
 0.02597403 0.16883117 0.03896104 0.01298701]
INFO:root:FL Epoch: 150 Num points on workers: [ 1  3 51  1  1  1  2 13  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 150 Training on worker :88
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 150 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :47
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 150 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 150 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :21
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.696388
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.637419
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 150 Norm Difference for worker 21 is 0.246995
INFO:root:FL Epoch: 150 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :78
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 150 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :89
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 150 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :6
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 150 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :36
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 150 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 150 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :39
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 150 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 150 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :99
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 150 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 150 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :22
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 150 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 88
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 150 Ends   ===================
INFO:root:Epoch:150 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:150 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 151 Begins ===================
INFO:root:FL Epoch: 151 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 151 Workers Selected : [0, 1, 2, 56, 3, 77, 44, 34, 99, 84]
INFO:root:FL Epoch: 151 Fraction of points on each worker in this round: [0.32   0.32   0.32   0.0048 0.0016 0.0016 0.0032 0.0048 0.0048 0.0192]
INFO:root:FL Epoch: 151 Num points on workers: [200 200 200   3   1   1   2   3   3  12]
INFO:root:--------------------------
INFO:root:FL Epoch: 151 Training on worker :0
INFO:root:FL Epoch: 151 Using Learning rate : 0.00740595711865586 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700450
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689260
INFO:root:FL Epoch: 151 Worker: 0 Backdoor Test Loss: 0.7360610465208689 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 151 Worker: 0 Backdoor Train Loss: 0.6857896327972413 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 151 Norm Difference for worker 0 is 0.095853
INFO:root:FL Epoch: 151 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1
INFO:root:FL Epoch: 151 Using Learning rate : 0.00740595711865586 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697134
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684698
INFO:root:FL Epoch: 151 Worker: 1 Backdoor Test Loss: 0.7381295164426168 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 151 Worker: 1 Backdoor Train Loss: 0.685465294122696 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 151 Norm Difference for worker 1 is 0.099418
INFO:root:FL Epoch: 151 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :2
INFO:root:FL Epoch: 151 Using Learning rate : 0.00740595711865586 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693312
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693982
INFO:root:FL Epoch: 151 Worker: 2 Backdoor Test Loss: 0.7351301908493042 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 151 Worker: 2 Backdoor Train Loss: 0.6856337130069733 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 151 Norm Difference for worker 2 is 0.097593
INFO:root:FL Epoch: 151 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :56
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 151 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 151 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :3
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 151 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :77
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 151 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :44
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 151 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 151 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :34
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 151 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 151 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :99
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 151 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 151 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :84
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 151 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 151 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 56
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 151 Ends   ===================
INFO:root:Epoch:151 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:151 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 152 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 152 Workers Selected : [53, 39, 5, 3, 51, 35, 95, 72, 96, 74]
INFO:root:FL Epoch: 152 Fraction of points on each worker in this round: [0.07017544 0.22807018 0.15789474 0.01754386 0.07017544 0.01754386
 0.01754386 0.10526316 0.01754386 0.29824561]
INFO:root:FL Epoch: 152 Num points on workers: [ 4 13  9  1  4  1  1  6  1 17]
INFO:root:--------------------------
INFO:root:FL Epoch: 152 Training on worker :53
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 152 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 152 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :39
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 152 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 152 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :5
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 152 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 152 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :3
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 152 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :51
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 152 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 152 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :35
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 152 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :95
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 152 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :72
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 152 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 152 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :96
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 152 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :74
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 152 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 152 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 53
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 152 Ends   ===================
INFO:root:Epoch:152 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:152 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 153 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 153 Workers Selected : [37, 61, 38, 12, 65, 89, 4, 76, 97, 19]
INFO:root:FL Epoch: 153 Fraction of points on each worker in this round: [0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455
 0.04545455 0.18181818 0.45454545 0.04545455]
INFO:root:FL Epoch: 153 Num points on workers: [ 1  1  1  1  1  1  1  4 10  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 153 Training on worker :37
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 153 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :61
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 153 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :38
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 153 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :12
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 153 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :65
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 153 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :89
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 153 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :4
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 153 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :76
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 153 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 153 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :97
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 153 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 153 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :19
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 153 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 37
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 153 Ends   ===================
INFO:root:Epoch:153 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:153 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 154 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 154 Workers Selected : [94, 97, 92, 53, 67, 31, 96, 78, 26, 13]
INFO:root:FL Epoch: 154 Fraction of points on each worker in this round: [0.51282051 0.12820513 0.05128205 0.05128205 0.15384615 0.01282051
 0.01282051 0.01282051 0.01282051 0.05128205]
INFO:root:FL Epoch: 154 Num points on workers: [40 10  4  4 12  1  1  1  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 154 Training on worker :94
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.693634
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.639931
INFO:root:FL Epoch: 154 Norm Difference for worker 94 is 0.227777
INFO:root:FL Epoch: 154 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :97
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 154 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 154 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :92
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 154 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 154 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :53
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 154 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 154 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :67
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 154 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 154 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :31
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 154 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 154 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :96
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 154 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 154 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :78
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 154 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 154 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :26
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 154 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 154 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :13
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 154 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 154 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 97
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 154 Ends   ===================
INFO:root:Epoch:154 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:154 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 155 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 155 Workers Selected : [95, 50, 51, 61, 35, 22, 63, 8, 53, 23]
INFO:root:FL Epoch: 155 Fraction of points on each worker in this round: [0.04347826 0.04347826 0.17391304 0.04347826 0.04347826 0.04347826
 0.08695652 0.04347826 0.17391304 0.30434783]
INFO:root:FL Epoch: 155 Num points on workers: [1 1 4 1 1 1 2 1 4 7]
INFO:root:--------------------------
INFO:root:FL Epoch: 155 Training on worker :95
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 155 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :50
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 155 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :51
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 155 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 155 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :61
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 155 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :35
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 155 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :22
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 155 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :63
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 155 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 155 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :8
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 155 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :53
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 155 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 155 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :23
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 155 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 155 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 95
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 155 Ends   ===================
INFO:root:Epoch:155 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:155 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 156 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 156 Workers Selected : [39, 54, 23, 33, 97, 32, 8, 78, 84, 75]
INFO:root:FL Epoch: 156 Fraction of points on each worker in this round: [0.16049383 0.01234568 0.08641975 0.37037037 0.12345679 0.04938272
 0.01234568 0.01234568 0.14814815 0.02469136]
INFO:root:FL Epoch: 156 Num points on workers: [13  1  7 30 10  4  1  1 12  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 156 Training on worker :39
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 156 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 156 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :54
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 156 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 156 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :23
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 156 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 156 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :33
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.685868
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.668052
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 156 Norm Difference for worker 33 is 0.073808
INFO:root:FL Epoch: 156 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :97
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 156 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 156 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :32
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 156 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 156 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :8
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 156 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 156 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :78
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 156 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 156 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :84
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 156 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 156 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :75
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 156 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 156 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 39
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 156 Ends   ===================
INFO:root:Epoch:156 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:156 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 157 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 157 Workers Selected : [58, 37, 81, 34, 62, 10, 16, 20, 79, 86]
INFO:root:FL Epoch: 157 Fraction of points on each worker in this round: [0.46153846 0.02564103 0.07692308 0.07692308 0.07692308 0.02564103
 0.05128205 0.02564103 0.05128205 0.12820513]
INFO:root:FL Epoch: 157 Num points on workers: [18  1  3  3  3  1  2  1  2  5]
INFO:root:--------------------------
INFO:root:FL Epoch: 157 Training on worker :58
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 157 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 157 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :37
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 157 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 157 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :81
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 157 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 157 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :34
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 157 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 157 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :62
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 157 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 157 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :10
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 157 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 157 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :16
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 157 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 157 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :20
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 157 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 157 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :79
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 157 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 157 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :86
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 157 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 157 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 58
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 157 Ends   ===================
INFO:root:Epoch:157 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:157 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 158 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 158 Workers Selected : [89, 69, 79, 55, 96, 72, 98, 77, 90, 76]
INFO:root:FL Epoch: 158 Fraction of points on each worker in this round: [0.02777778 0.47222222 0.05555556 0.02777778 0.02777778 0.16666667
 0.02777778 0.02777778 0.05555556 0.11111111]
INFO:root:FL Epoch: 158 Num points on workers: [ 1 17  2  1  1  6  1  1  2  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 158 Training on worker :89
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 158 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :69
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 158 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 158 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :79
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 158 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 158 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :55
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 158 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :96
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 158 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :72
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 158 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 158 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :98
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 158 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :77
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 158 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :90
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 158 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 158 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :76
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 158 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 158 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 89
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 158 Ends   ===================
INFO:root:Epoch:158 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:158 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 159 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 159 Workers Selected : [19, 47, 30, 45, 26, 14, 3, 28, 24, 29]
INFO:root:FL Epoch: 159 Fraction of points on each worker in this round: [0.03846154 0.11538462 0.07692308 0.07692308 0.03846154 0.23076923
 0.03846154 0.23076923 0.11538462 0.03846154]
INFO:root:FL Epoch: 159 Num points on workers: [1 3 2 2 1 6 1 6 3 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 159 Training on worker :19
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 159 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 159 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :47
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 159 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 159 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :30
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 159 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 159 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :45
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 159 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 159 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :26
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 159 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 159 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :14
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 159 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 159 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :3
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 159 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 159 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :28
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 159 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 159 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :24
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 159 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 159 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :29
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 159 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 159 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 19
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 159 Ends   ===================
INFO:root:Epoch:159 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:159 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 160 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 160 Workers Selected : [80, 84, 18, 15, 39, 67, 87, 50, 75, 46]
INFO:root:FL Epoch: 160 Fraction of points on each worker in this round: [0.01923077 0.23076923 0.07692308 0.01923077 0.25       0.23076923
 0.09615385 0.01923077 0.03846154 0.01923077]
INFO:root:FL Epoch: 160 Num points on workers: [ 1 12  4  1 13 12  5  1  2  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 160 Training on worker :80
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 160 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :84
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 160 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 160 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :18
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 160 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 160 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :15
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 160 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :39
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 160 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 160 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :67
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 160 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 160 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :87
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 160 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 160 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :50
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 160 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :75
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 160 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 160 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :46
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 160 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 80
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 160 Ends   ===================
INFO:root:Epoch:160 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:160 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 161 Begins ===================
INFO:root:FL Epoch: 161 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 161 Workers Selected : [0, 1, 2, 42, 96, 11, 53, 75, 22, 56]
INFO:root:FL Epoch: 161 Fraction of points on each worker in this round: [0.32414911 0.32414911 0.32414911 0.00486224 0.00162075 0.00486224
 0.00648298 0.00324149 0.00162075 0.00486224]
INFO:root:FL Epoch: 161 Num points on workers: [200 200 200   3   1   3   4   2   1   3]
INFO:root:--------------------------
INFO:root:FL Epoch: 161 Training on worker :0
INFO:root:FL Epoch: 161 Using Learning rate : 0.00725916396366966 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682518
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680736
INFO:root:FL Epoch: 161 Worker: 0 Backdoor Test Loss: 0.7373952666918436 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 161 Worker: 0 Backdoor Train Loss: 0.6856742560863495 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 161 Norm Difference for worker 0 is 0.096774
INFO:root:FL Epoch: 161 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1
INFO:root:FL Epoch: 161 Using Learning rate : 0.00725916396366966 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694646
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691511
INFO:root:FL Epoch: 161 Worker: 1 Backdoor Test Loss: 0.7332768142223358 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 161 Worker: 1 Backdoor Train Loss: 0.6862152457237244 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 161 Norm Difference for worker 1 is 0.090983
INFO:root:FL Epoch: 161 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :2
INFO:root:FL Epoch: 161 Using Learning rate : 0.00725916396366966 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693606
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687294
INFO:root:FL Epoch: 161 Worker: 2 Backdoor Test Loss: 0.7433324257532755 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 161 Worker: 2 Backdoor Train Loss: 0.6853143513202667 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 161 Norm Difference for worker 2 is 0.102193
INFO:root:FL Epoch: 161 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :42
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 161 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 161 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :96
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 161 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 161 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :11
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 161 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 161 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :53
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 161 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 161 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :75
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 161 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 161 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :22
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 161 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 161 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :56
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 161 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 161 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 161 Ends   ===================
INFO:root:Epoch:161 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:161 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 162 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 162 Workers Selected : [79, 20, 97, 74, 27, 19, 45, 6, 99, 90]
INFO:root:FL Epoch: 162 Fraction of points on each worker in this round: [0.04545455 0.02272727 0.22727273 0.38636364 0.11363636 0.02272727
 0.04545455 0.02272727 0.06818182 0.04545455]
INFO:root:FL Epoch: 162 Num points on workers: [ 2  1 10 17  5  1  2  1  3  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 162 Training on worker :79
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 162 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 162 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :20
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 162 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 162 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :97
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 162 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 162 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :74
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 162 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 162 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :27
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 162 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 162 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :19
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 162 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 162 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :45
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 162 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 162 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :6
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 162 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 162 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :99
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 162 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 162 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :90
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 162 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 162 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 79
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 162 Ends   ===================
INFO:root:Epoch:162 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:162 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 163 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 163 Workers Selected : [58, 28, 25, 92, 91, 82, 85, 34, 9, 75]
INFO:root:FL Epoch: 163 Fraction of points on each worker in this round: [0.21176471 0.07058824 0.28235294 0.04705882 0.04705882 0.01176471
 0.02352941 0.03529412 0.24705882 0.02352941]
INFO:root:FL Epoch: 163 Num points on workers: [18  6 24  4  4  1  2  3 21  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 163 Training on worker :58
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 163 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 163 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :28
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 163 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 163 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :25
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.691199
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.667744
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 163 Norm Difference for worker 25 is 0.075971
INFO:root:FL Epoch: 163 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :92
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 163 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 163 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :91
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 163 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 163 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :82
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 163 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 163 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :85
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 163 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 163 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :34
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 163 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 163 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :9
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.686188
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.667276
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 163 Norm Difference for worker 9 is 0.070249
INFO:root:FL Epoch: 163 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :75
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 163 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 163 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 58
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 163 Ends   ===================
INFO:root:Epoch:163 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:163 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 164 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 164 Workers Selected : [96, 5, 75, 98, 6, 43, 19, 33, 14, 24]
INFO:root:FL Epoch: 164 Fraction of points on each worker in this round: [0.01818182 0.16363636 0.03636364 0.01818182 0.01818182 0.01818182
 0.01818182 0.54545455 0.10909091 0.05454545]
INFO:root:FL Epoch: 164 Num points on workers: [ 1  9  2  1  1  1  1 30  6  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 164 Training on worker :96
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 164 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :5
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 164 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 164 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :75
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 164 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 164 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :98
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 164 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :6
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 164 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :43
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 164 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :19
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 164 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :33
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.683065
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.663952
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 164 Norm Difference for worker 33 is 0.071979
INFO:root:FL Epoch: 164 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :14
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 164 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 164 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :24
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 164 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 164 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 96
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 164 Ends   ===================
INFO:root:Epoch:164 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:164 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 165 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 165 Workers Selected : [43, 46, 96, 47, 27, 67, 98, 4, 76, 39]
INFO:root:FL Epoch: 165 Fraction of points on each worker in this round: [0.02380952 0.02380952 0.02380952 0.07142857 0.11904762 0.28571429
 0.02380952 0.02380952 0.0952381  0.30952381]
INFO:root:FL Epoch: 165 Num points on workers: [ 1  1  1  3  5 12  1  1  4 13]
INFO:root:--------------------------
INFO:root:FL Epoch: 165 Training on worker :43
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 165 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :46
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 165 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :96
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 165 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :47
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 165 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 165 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :27
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 165 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 165 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :67
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 165 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 165 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :98
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 165 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :4
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 165 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :76
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 165 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 165 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :39
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 165 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 165 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 43
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 165 Ends   ===================
INFO:root:Epoch:165 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:165 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 166 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 166 Workers Selected : [13, 36, 34, 18, 62, 93, 75, 73, 56, 27]
INFO:root:FL Epoch: 166 Fraction of points on each worker in this round: [0.13793103 0.06896552 0.10344828 0.13793103 0.10344828 0.06896552
 0.06896552 0.03448276 0.10344828 0.17241379]
INFO:root:FL Epoch: 166 Num points on workers: [4 2 3 4 3 2 2 1 3 5]
INFO:root:--------------------------
INFO:root:FL Epoch: 166 Training on worker :13
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 166 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 166 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :36
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 166 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 166 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :34
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 166 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 166 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :18
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 166 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 166 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :62
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 166 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 166 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :93
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 166 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 166 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :75
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 166 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 166 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :73
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 166 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 166 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :56
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 166 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 166 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :27
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 166 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 166 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 13
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 166 Ends   ===================
INFO:root:Epoch:166 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:166 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 167 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 167 Workers Selected : [92, 59, 67, 51, 71, 10, 4, 74, 39, 21]
INFO:root:FL Epoch: 167 Fraction of points on each worker in this round: [0.03809524 0.00952381 0.11428571 0.03809524 0.00952381 0.00952381
 0.00952381 0.16190476 0.12380952 0.48571429]
INFO:root:FL Epoch: 167 Num points on workers: [ 4  1 12  4  1  1  1 17 13 51]
INFO:root:--------------------------
INFO:root:FL Epoch: 167 Training on worker :92
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 167 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 167 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :59
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 167 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :67
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 167 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 167 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :51
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 167 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 167 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :71
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 167 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :10
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 167 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :4
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 167 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :74
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 167 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 167 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :39
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 167 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 167 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :21
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.697159
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.637167
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 167 Norm Difference for worker 21 is 0.239902
INFO:root:FL Epoch: 167 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 92
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 167 Ends   ===================
INFO:root:Epoch:167 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:167 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 168 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 168 Workers Selected : [91, 76, 60, 54, 15, 95, 84, 30, 61, 19]
INFO:root:FL Epoch: 168 Fraction of points on each worker in this round: [0.13333333 0.13333333 0.1        0.03333333 0.03333333 0.03333333
 0.4        0.06666667 0.03333333 0.03333333]
INFO:root:FL Epoch: 168 Num points on workers: [ 4  4  3  1  1  1 12  2  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 168 Training on worker :91
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 168 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 168 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :76
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 168 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 168 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :60
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 168 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 168 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :54
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 168 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :15
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 168 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :95
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 168 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :84
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 168 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 168 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :30
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 168 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 168 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :61
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 168 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :19
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 168 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 91
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 168 Ends   ===================
INFO:root:Epoch:168 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:168 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 169 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 169 Workers Selected : [61, 22, 67, 64, 4, 70, 21, 19, 77, 69]
INFO:root:FL Epoch: 169 Fraction of points on each worker in this round: [0.01111111 0.01111111 0.13333333 0.03333333 0.01111111 0.02222222
 0.56666667 0.01111111 0.01111111 0.18888889]
INFO:root:FL Epoch: 169 Num points on workers: [ 1  1 12  3  1  2 51  1  1 17]
INFO:root:--------------------------
INFO:root:FL Epoch: 169 Training on worker :61
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 169 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :22
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 169 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :67
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 169 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 169 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :64
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 169 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 169 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :4
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 169 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :70
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 169 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 169 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :21
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.692320
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.640935
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 169 Norm Difference for worker 21 is 0.236442
INFO:root:FL Epoch: 169 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :19
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 169 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :77
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 169 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :69
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 169 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 169 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 61
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 169 Ends   ===================
INFO:root:Epoch:169 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:169 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 170 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 170 Workers Selected : [7, 79, 39, 34, 8, 75, 63, 49, 10, 66]
INFO:root:FL Epoch: 170 Fraction of points on each worker in this round: [0.03703704 0.07407407 0.48148148 0.11111111 0.03703704 0.07407407
 0.07407407 0.03703704 0.03703704 0.03703704]
INFO:root:FL Epoch: 170 Num points on workers: [ 1  2 13  3  1  2  2  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 170 Training on worker :7
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 170 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :79
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 170 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 170 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :39
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 170 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 170 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :34
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 170 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 170 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :8
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 170 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :75
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 170 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 170 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :63
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 170 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 170 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :49
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 170 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :10
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 170 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :66
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 170 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 7
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 170 Ends   ===================
INFO:root:Epoch:170 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:170 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 171 Begins ===================
INFO:root:FL Epoch: 171 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 171 Workers Selected : [0, 1, 2, 52, 45, 26, 89, 88, 74, 98]
INFO:root:FL Epoch: 171 Fraction of points on each worker in this round: [0.32051282 0.32051282 0.32051282 0.00160256 0.00320513 0.00160256
 0.00160256 0.00160256 0.02724359 0.00160256]
INFO:root:FL Epoch: 171 Num points on workers: [200 200 200   1   2   1   1   1  17   1]
INFO:root:--------------------------
INFO:root:FL Epoch: 171 Training on worker :0
INFO:root:FL Epoch: 171 Using Learning rate : 0.0071152803894446726 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698791
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695942
INFO:root:FL Epoch: 171 Worker: 0 Backdoor Test Loss: 0.7371313869953156 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 171 Worker: 0 Backdoor Train Loss: 0.685862374305725 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 171 Norm Difference for worker 0 is 0.094651
INFO:root:FL Epoch: 171 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1
INFO:root:FL Epoch: 171 Using Learning rate : 0.0071152803894446726 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691862
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692995
INFO:root:FL Epoch: 171 Worker: 1 Backdoor Test Loss: 0.7375793755054474 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 171 Worker: 1 Backdoor Train Loss: 0.6857572436332703 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 171 Norm Difference for worker 1 is 0.096549
INFO:root:FL Epoch: 171 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :2
INFO:root:FL Epoch: 171 Using Learning rate : 0.0071152803894446726 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698791
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697519
INFO:root:FL Epoch: 171 Worker: 2 Backdoor Test Loss: 0.7277837991714478 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 171 Worker: 2 Backdoor Train Loss: 0.6866639673709869 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 171 Norm Difference for worker 2 is 0.085644
INFO:root:FL Epoch: 171 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :52
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 171 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :45
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 171 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 171 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :26
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 171 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :89
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 171 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :88
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 171 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :74
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 171 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 171 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :98
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 171 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 52
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 171 Ends   ===================
INFO:root:Epoch:171 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:171 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 172 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 172 Workers Selected : [92, 18, 87, 52, 36, 17, 14, 60, 76, 74]
INFO:root:FL Epoch: 172 Fraction of points on each worker in this round: [0.08333333 0.08333333 0.10416667 0.02083333 0.04166667 0.04166667
 0.125      0.0625     0.08333333 0.35416667]
INFO:root:FL Epoch: 172 Num points on workers: [ 4  4  5  1  2  2  6  3  4 17]
INFO:root:--------------------------
INFO:root:FL Epoch: 172 Training on worker :92
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 172 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 172 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :18
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 172 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 172 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :87
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 172 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 172 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :52
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 172 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :36
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 172 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 172 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :17
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 172 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 172 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :14
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 172 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 172 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :60
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 172 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 172 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :76
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 172 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 172 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :74
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 172 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 172 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 92
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 172 Ends   ===================
INFO:root:Epoch:172 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:172 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 173 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 173 Workers Selected : [45, 4, 96, 83, 20, 53, 39, 73, 10, 49]
INFO:root:FL Epoch: 173 Fraction of points on each worker in this round: [0.07407407 0.03703704 0.03703704 0.07407407 0.03703704 0.14814815
 0.48148148 0.03703704 0.03703704 0.03703704]
INFO:root:FL Epoch: 173 Num points on workers: [ 2  1  1  2  1  4 13  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 173 Training on worker :45
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 173 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 173 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :4
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 173 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :96
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 173 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :83
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 173 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 173 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :20
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 173 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :53
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 173 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 173 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :39
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 173 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 173 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :73
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 173 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :10
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 173 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :49
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 173 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 45
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 173 Ends   ===================
INFO:root:Epoch:173 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:173 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 174 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 174 Workers Selected : [97, 40, 77, 71, 95, 38, 59, 8, 94, 30]
INFO:root:FL Epoch: 174 Fraction of points on each worker in this round: [0.16949153 0.01694915 0.01694915 0.01694915 0.01694915 0.01694915
 0.01694915 0.01694915 0.6779661  0.03389831]
INFO:root:FL Epoch: 174 Num points on workers: [10  1  1  1  1  1  1  1 40  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 174 Training on worker :97
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 174 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 174 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :40
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 174 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :77
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 174 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :71
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 174 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :95
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 174 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :38
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 174 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :59
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 174 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :8
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 174 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :94
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.687654
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.644230
INFO:root:FL Epoch: 174 Norm Difference for worker 94 is 0.218431
INFO:root:FL Epoch: 174 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :30
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 174 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 174 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 97
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 174 Ends   ===================
INFO:root:Epoch:174 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:174 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 175 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 175 Workers Selected : [84, 83, 60, 12, 21, 99, 23, 90, 96, 70]
INFO:root:FL Epoch: 175 Fraction of points on each worker in this round: [0.14285714 0.02380952 0.03571429 0.01190476 0.60714286 0.03571429
 0.08333333 0.02380952 0.01190476 0.02380952]
INFO:root:FL Epoch: 175 Num points on workers: [12  2  3  1 51  3  7  2  1  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 175 Training on worker :84
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 175 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 175 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :83
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 175 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 175 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :60
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 175 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 175 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :12
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 175 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 175 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :21
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.689327
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.644223
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 175 Norm Difference for worker 21 is 0.23213
INFO:root:FL Epoch: 175 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :99
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 175 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 175 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :23
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 175 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 175 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :90
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 175 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 175 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :96
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 175 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 175 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :70
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 175 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 175 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 84
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 175 Ends   ===================
INFO:root:Epoch:175 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:175 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 176 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 176 Workers Selected : [55, 22, 58, 43, 32, 38, 86, 50, 18, 59]
INFO:root:FL Epoch: 176 Fraction of points on each worker in this round: [0.02702703 0.02702703 0.48648649 0.02702703 0.10810811 0.02702703
 0.13513514 0.02702703 0.10810811 0.02702703]
INFO:root:FL Epoch: 176 Num points on workers: [ 1  1 18  1  4  1  5  1  4  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 176 Training on worker :55
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 176 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 176 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :22
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 176 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 176 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :58
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 176 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 176 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :43
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 176 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 176 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :32
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 176 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 176 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :38
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 176 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 176 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :86
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 176 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 176 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :50
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 176 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 176 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :18
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 176 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 176 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :59
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 176 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 176 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 55
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 176 Ends   ===================
INFO:root:Epoch:176 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:176 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 177 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 177 Workers Selected : [13, 25, 53, 39, 22, 87, 32, 28, 95, 45]
INFO:root:FL Epoch: 177 Fraction of points on each worker in this round: [0.0625   0.375    0.0625   0.203125 0.015625 0.078125 0.0625   0.09375
 0.015625 0.03125 ]
INFO:root:FL Epoch: 177 Num points on workers: [ 4 24  4 13  1  5  4  6  1  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 177 Training on worker :13
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 177 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 177 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :25
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.690436
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.672548
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 177 Norm Difference for worker 25 is 0.073849
INFO:root:FL Epoch: 177 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :53
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 177 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 177 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :39
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 177 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 177 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :22
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 177 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :87
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 177 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 177 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :32
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 177 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 177 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :28
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 177 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 177 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :95
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 177 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :45
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 177 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 177 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 13
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 177 Ends   ===================
INFO:root:Epoch:177 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:177 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 178 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 178 Workers Selected : [22, 36, 95, 50, 41, 90, 18, 70, 68, 98]
INFO:root:FL Epoch: 178 Fraction of points on each worker in this round: [0.05 0.1  0.05 0.05 0.2  0.1  0.2  0.1  0.1  0.05]
INFO:root:FL Epoch: 178 Num points on workers: [1 2 1 1 4 2 4 2 2 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 178 Training on worker :22
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 178 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :36
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 178 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 178 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :95
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 178 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :50
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 178 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :41
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 178 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 178 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :90
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 178 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 178 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :18
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 178 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 178 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :70
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 178 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 178 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :68
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 178 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 178 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :98
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 178 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 22
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 178 Ends   ===================
INFO:root:Epoch:178 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:178 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 179 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 179 Workers Selected : [52, 70, 62, 73, 3, 60, 74, 39, 47, 61]
INFO:root:FL Epoch: 179 Fraction of points on each worker in this round: [0.02222222 0.04444444 0.06666667 0.02222222 0.02222222 0.06666667
 0.37777778 0.28888889 0.06666667 0.02222222]
INFO:root:FL Epoch: 179 Num points on workers: [ 1  2  3  1  1  3 17 13  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 179 Training on worker :52
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 179 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 179 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :70
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 179 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 179 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :62
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 179 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 179 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :73
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 179 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 179 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :3
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 179 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 179 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :60
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 179 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 179 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :74
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 179 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 179 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :39
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 179 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 179 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :47
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 179 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 179 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :61
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 179 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 179 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 52
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 179 Ends   ===================
INFO:root:Epoch:179 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:179 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 180 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 180 Workers Selected : [30, 15, 48, 80, 16, 64, 58, 98, 63, 25]
INFO:root:FL Epoch: 180 Fraction of points on each worker in this round: [0.03636364 0.01818182 0.01818182 0.01818182 0.03636364 0.05454545
 0.32727273 0.01818182 0.03636364 0.43636364]
INFO:root:FL Epoch: 180 Num points on workers: [ 2  1  1  1  2  3 18  1  2 24]
INFO:root:--------------------------
INFO:root:FL Epoch: 180 Training on worker :30
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 180 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 180 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :15
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 180 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :48
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 180 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :80
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 180 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :16
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 180 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 180 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :64
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 180 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 180 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :58
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 180 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 180 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :98
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 180 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :63
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 180 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 180 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :25
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.688623
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.672765
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 180 Norm Difference for worker 25 is 0.073828
INFO:root:FL Epoch: 180 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 30
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 180 Ends   ===================
INFO:root:Epoch:180 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:180 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 181 Begins ===================
INFO:root:FL Epoch: 181 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 181 Workers Selected : [0, 1, 2, 70, 93, 5, 42, 86, 10, 77]
INFO:root:FL Epoch: 181 Fraction of points on each worker in this round: [0.32102729 0.32102729 0.32102729 0.00321027 0.00321027 0.01444623
 0.00481541 0.00802568 0.00160514 0.00160514]
INFO:root:FL Epoch: 181 Num points on workers: [200 200 200   2   2   9   3   5   1   1]
INFO:root:--------------------------
INFO:root:FL Epoch: 181 Training on worker :0
INFO:root:FL Epoch: 181 Using Learning rate : 0.006974248725306764 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695785
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689146
INFO:root:FL Epoch: 181 Worker: 0 Backdoor Test Loss: 0.7338953415552775 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 181 Worker: 0 Backdoor Train Loss: 0.6861751854419709 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 181 Norm Difference for worker 0 is 0.091072
INFO:root:FL Epoch: 181 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1
INFO:root:FL Epoch: 181 Using Learning rate : 0.006974248725306764 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701682
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692556
INFO:root:FL Epoch: 181 Worker: 1 Backdoor Test Loss: 0.7360479235649109 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 181 Worker: 1 Backdoor Train Loss: 0.6861221015453338 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 181 Norm Difference for worker 1 is 0.091908
INFO:root:FL Epoch: 181 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :2
INFO:root:FL Epoch: 181 Using Learning rate : 0.006974248725306764 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698102
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694542
INFO:root:FL Epoch: 181 Worker: 2 Backdoor Test Loss: 0.7375392615795135 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 181 Worker: 2 Backdoor Train Loss: 0.6859986782073975 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 181 Norm Difference for worker 2 is 0.093954
INFO:root:FL Epoch: 181 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :70
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 181 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 181 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :93
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 181 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 181 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :5
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 181 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 181 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :42
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 181 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 181 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :86
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 181 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 181 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :10
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 181 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 181 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :77
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 181 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 181 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 181 Ends   ===================
INFO:root:Epoch:181 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:181 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 182 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 182 Workers Selected : [83, 10, 8, 12, 64, 59, 71, 77, 19, 82]
INFO:root:FL Epoch: 182 Fraction of points on each worker in this round: [0.15384615 0.07692308 0.07692308 0.07692308 0.23076923 0.07692308
 0.07692308 0.07692308 0.07692308 0.07692308]
INFO:root:FL Epoch: 182 Num points on workers: [2 1 1 1 3 1 1 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 182 Training on worker :83
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 182 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 182 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :10
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 182 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :8
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 182 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :12
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 182 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :64
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 182 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 182 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :59
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 182 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :71
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 182 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :77
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 182 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :19
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 182 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :82
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 182 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 83
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 182 Ends   ===================
INFO:root:Epoch:182 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:182 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 183 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 183 Workers Selected : [38, 45, 4, 68, 6, 53, 37, 35, 83, 65]
INFO:root:FL Epoch: 183 Fraction of points on each worker in this round: [0.0625 0.125  0.0625 0.125  0.0625 0.25   0.0625 0.0625 0.125  0.0625]
INFO:root:FL Epoch: 183 Num points on workers: [1 2 1 2 1 4 1 1 2 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 183 Training on worker :38
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 183 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :45
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 183 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 183 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :4
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 183 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :68
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 183 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 183 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :6
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 183 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :53
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 183 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 183 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :37
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 183 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :35
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 183 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :83
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 183 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 183 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :65
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 183 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 38
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 183 Ends   ===================
INFO:root:Epoch:183 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:183 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 184 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 184 Workers Selected : [84, 55, 74, 72, 25, 49, 30, 40, 92, 99]
INFO:root:FL Epoch: 184 Fraction of points on each worker in this round: [0.16901408 0.01408451 0.23943662 0.08450704 0.33802817 0.01408451
 0.02816901 0.01408451 0.05633803 0.04225352]
INFO:root:FL Epoch: 184 Num points on workers: [12  1 17  6 24  1  2  1  4  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 184 Training on worker :84
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 184 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 184 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :55
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 184 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 184 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :74
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 184 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 184 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :72
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 184 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 184 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :25
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.683672
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.672956
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 184 Norm Difference for worker 25 is 0.072148
INFO:root:FL Epoch: 184 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :49
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 184 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 184 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :30
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 184 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 184 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :40
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 184 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 184 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :92
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 184 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 184 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :99
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 184 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 184 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 84
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 184 Ends   ===================
INFO:root:Epoch:184 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:184 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 185 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 185 Workers Selected : [88, 66, 22, 65, 56, 38, 82, 39, 78, 72]
INFO:root:FL Epoch: 185 Fraction of points on each worker in this round: [0.03448276 0.03448276 0.03448276 0.03448276 0.10344828 0.03448276
 0.03448276 0.44827586 0.03448276 0.20689655]
INFO:root:FL Epoch: 185 Num points on workers: [ 1  1  1  1  3  1  1 13  1  6]
INFO:root:--------------------------
INFO:root:FL Epoch: 185 Training on worker :88
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 185 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :66
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 185 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :22
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 185 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :65
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 185 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :56
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 185 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 185 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :38
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 185 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :82
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 185 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :39
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 185 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 185 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :78
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 185 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :72
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 185 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 185 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 88
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 185 Ends   ===================
INFO:root:Epoch:185 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:185 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 186 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 186 Workers Selected : [46, 69, 30, 12, 80, 11, 33, 59, 18, 26]
INFO:root:FL Epoch: 186 Fraction of points on each worker in this round: [0.01639344 0.27868852 0.03278689 0.01639344 0.01639344 0.04918033
 0.49180328 0.01639344 0.06557377 0.01639344]
INFO:root:FL Epoch: 186 Num points on workers: [ 1 17  2  1  1  3 30  1  4  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 186 Training on worker :46
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 186 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 186 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :69
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 186 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 186 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :30
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 186 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 186 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :12
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 186 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 186 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :80
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 186 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 186 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :11
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 186 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 186 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :33
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.683306
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.670033
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 186 Norm Difference for worker 33 is 0.068849
INFO:root:FL Epoch: 186 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :59
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 186 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 186 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :18
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 186 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 186 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :26
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 186 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 186 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 46
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 186 Ends   ===================
INFO:root:Epoch:186 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:186 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 187 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 187 Workers Selected : [7, 38, 48, 89, 15, 44, 99, 22, 21, 47]
INFO:root:FL Epoch: 187 Fraction of points on each worker in this round: [0.01538462 0.01538462 0.01538462 0.01538462 0.01538462 0.03076923
 0.04615385 0.01538462 0.78461538 0.04615385]
INFO:root:FL Epoch: 187 Num points on workers: [ 1  1  1  1  1  2  3  1 51  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 187 Training on worker :7
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 187 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :38
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 187 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :48
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 187 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :89
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 187 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :15
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 187 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :44
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 187 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 187 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :99
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 187 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 187 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :22
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 187 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :21
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.688001
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.641542
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 187 Norm Difference for worker 21 is 0.229951
INFO:root:FL Epoch: 187 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :47
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 187 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 187 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 7
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 187 Ends   ===================
INFO:root:Epoch:187 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:187 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 188 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 188 Workers Selected : [95, 91, 32, 38, 44, 65, 13, 60, 68, 73]
INFO:root:FL Epoch: 188 Fraction of points on each worker in this round: [0.04347826 0.17391304 0.17391304 0.04347826 0.08695652 0.04347826
 0.17391304 0.13043478 0.08695652 0.04347826]
INFO:root:FL Epoch: 188 Num points on workers: [1 4 4 1 2 1 4 3 2 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 188 Training on worker :95
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 188 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :91
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 188 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 188 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :32
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 188 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 188 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :38
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 188 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :44
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 188 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 188 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :65
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 188 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :13
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 188 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 188 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :60
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 188 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 188 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :68
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 188 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 188 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :73
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 188 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 95
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 188 Ends   ===================
INFO:root:Epoch:188 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:188 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 189 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 189 Workers Selected : [39, 29, 43, 57, 76, 60, 53, 31, 63, 82]
INFO:root:FL Epoch: 189 Fraction of points on each worker in this round: [0.30232558 0.02325581 0.02325581 0.30232558 0.09302326 0.06976744
 0.09302326 0.02325581 0.04651163 0.02325581]
INFO:root:FL Epoch: 189 Num points on workers: [13  1  1 13  4  3  4  1  2  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 189 Training on worker :39
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 189 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 189 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :29
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 189 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 189 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :43
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 189 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 189 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :57
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 189 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 189 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :76
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 189 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 189 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :60
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 189 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 189 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :53
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 189 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 189 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :31
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 189 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 189 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :63
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 189 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 189 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :82
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 189 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 189 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 39
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 189 Ends   ===================
INFO:root:Epoch:189 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:189 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 190 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 190 Workers Selected : [80, 34, 12, 42, 82, 29, 47, 83, 87, 67]
INFO:root:FL Epoch: 190 Fraction of points on each worker in this round: [0.03125 0.09375 0.03125 0.09375 0.03125 0.03125 0.09375 0.0625  0.15625
 0.375  ]
INFO:root:FL Epoch: 190 Num points on workers: [ 1  3  1  3  1  1  3  2  5 12]
INFO:root:--------------------------
INFO:root:FL Epoch: 190 Training on worker :80
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 190 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :34
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 190 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 190 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :12
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 190 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :42
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 190 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 190 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :82
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 190 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :29
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 190 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :47
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 190 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 190 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :83
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 190 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 190 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :87
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 190 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 190 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :67
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 190 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 190 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 80
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 190 Ends   ===================
INFO:root:Epoch:190 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:190 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 191 Begins ===================
INFO:root:FL Epoch: 191 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 191 Workers Selected : [0, 1, 2, 43, 24, 76, 11, 39, 94, 89]
INFO:root:FL Epoch: 191 Fraction of points on each worker in this round: [0.30075188 0.30075188 0.30075188 0.00150376 0.00451128 0.00601504
 0.00451128 0.01954887 0.06015038 0.00150376]
INFO:root:FL Epoch: 191 Num points on workers: [200 200 200   1   3   4   3  13  40   1]
INFO:root:--------------------------
INFO:root:FL Epoch: 191 Training on worker :0
INFO:root:FL Epoch: 191 Using Learning rate : 0.006836012443669737 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691434
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693427
INFO:root:FL Epoch: 191 Worker: 0 Backdoor Test Loss: 0.7385194599628448 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 191 Worker: 0 Backdoor Train Loss: 0.6857824802398682 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 191 Norm Difference for worker 0 is 0.096163
INFO:root:FL Epoch: 191 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1
INFO:root:FL Epoch: 191 Using Learning rate : 0.006836012443669737 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693520
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692352
INFO:root:FL Epoch: 191 Worker: 1 Backdoor Test Loss: 0.7346455852190653 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 191 Worker: 1 Backdoor Train Loss: 0.6860733985900879 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 191 Norm Difference for worker 1 is 0.092268
INFO:root:FL Epoch: 191 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :2
INFO:root:FL Epoch: 191 Using Learning rate : 0.006836012443669737 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692005
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695066
INFO:root:FL Epoch: 191 Worker: 2 Backdoor Test Loss: 0.7362751960754395 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 191 Worker: 2 Backdoor Train Loss: 0.6859585642814636 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 191 Norm Difference for worker 2 is 0.093909
INFO:root:FL Epoch: 191 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :43
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 191 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 191 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :24
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 191 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 191 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :76
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 191 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 191 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :11
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 191 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 191 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :39
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 191 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 191 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :94
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.695407
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.645311
INFO:root:FL Epoch: 191 Norm Difference for worker 94 is 0.209786
INFO:root:FL Epoch: 191 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :89
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 191 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 191 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 43
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 191 Ends   ===================
INFO:root:Epoch:191 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:191 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 192 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 192 Workers Selected : [25, 62, 44, 48, 38, 63, 86, 6, 74, 23]
INFO:root:FL Epoch: 192 Fraction of points on each worker in this round: [0.38095238 0.04761905 0.03174603 0.01587302 0.01587302 0.03174603
 0.07936508 0.01587302 0.26984127 0.11111111]
INFO:root:FL Epoch: 192 Num points on workers: [24  3  2  1  1  2  5  1 17  7]
INFO:root:--------------------------
INFO:root:FL Epoch: 192 Training on worker :25
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.684776
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.667464
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 192 Norm Difference for worker 25 is 0.070467
INFO:root:FL Epoch: 192 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :62
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 192 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 192 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :44
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 192 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 192 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :48
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 192 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 192 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :38
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 192 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 192 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :63
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 192 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 192 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :86
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 192 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 192 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :6
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 192 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 192 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :74
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 192 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 192 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :23
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 192 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 192 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 62
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 192 Ends   ===================
INFO:root:Epoch:192 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:192 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 193 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 193 Workers Selected : [72, 67, 94, 77, 47, 35, 41, 76, 82, 57]
INFO:root:FL Epoch: 193 Fraction of points on each worker in this round: [0.07058824 0.14117647 0.47058824 0.01176471 0.03529412 0.01176471
 0.04705882 0.04705882 0.01176471 0.15294118]
INFO:root:FL Epoch: 193 Num points on workers: [ 6 12 40  1  3  1  4  4  1 13]
INFO:root:--------------------------
INFO:root:FL Epoch: 193 Training on worker :72
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 193 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 193 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :67
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 193 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 193 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :94
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.691950
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.646844
INFO:root:FL Epoch: 193 Norm Difference for worker 94 is 0.20991
INFO:root:FL Epoch: 193 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :77
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 193 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 193 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :47
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 193 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 193 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :35
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 193 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 193 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :41
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 193 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 193 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :76
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 193 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 193 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :82
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 193 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 193 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :57
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 193 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 193 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 72
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 193 Ends   ===================
INFO:root:Epoch:193 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:193 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 194 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 194 Workers Selected : [98, 41, 72, 62, 26, 29, 14, 38, 30, 28]
INFO:root:FL Epoch: 194 Fraction of points on each worker in this round: [0.03225806 0.12903226 0.19354839 0.09677419 0.03225806 0.03225806
 0.19354839 0.03225806 0.06451613 0.19354839]
INFO:root:FL Epoch: 194 Num points on workers: [1 4 6 3 1 1 6 1 2 6]
INFO:root:--------------------------
INFO:root:FL Epoch: 194 Training on worker :98
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 194 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :41
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 194 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 194 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :72
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 194 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 194 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :62
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 194 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 194 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :26
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 194 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :29
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 194 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :14
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 194 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 194 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :38
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 194 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :30
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 194 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 194 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :28
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 194 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 194 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 98
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 194 Ends   ===================
INFO:root:Epoch:194 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:194 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 195 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 195 Workers Selected : [93, 5, 9, 87, 89, 45, 59, 24, 50, 22]
INFO:root:FL Epoch: 195 Fraction of points on each worker in this round: [0.04347826 0.19565217 0.45652174 0.10869565 0.02173913 0.04347826
 0.02173913 0.06521739 0.02173913 0.02173913]
INFO:root:FL Epoch: 195 Num points on workers: [ 2  9 21  5  1  2  1  3  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 195 Training on worker :93
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 195 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 195 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :5
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 195 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 195 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :9
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.686623
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.674124
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 9 is 0.066794
INFO:root:FL Epoch: 195 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :87
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 195 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 195 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :89
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 195 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :45
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 195 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 195 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :59
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 195 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :24
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 195 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 195 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :50
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 195 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :22
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 195 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 93
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 195 Ends   ===================
INFO:root:Epoch:195 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:195 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 196 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 196 Workers Selected : [59, 43, 91, 78, 25, 67, 94, 95, 51, 76]
INFO:root:FL Epoch: 196 Fraction of points on each worker in this round: [0.01086957 0.01086957 0.04347826 0.01086957 0.26086957 0.13043478
 0.43478261 0.01086957 0.04347826 0.04347826]
INFO:root:FL Epoch: 196 Num points on workers: [ 1  1  4  1 24 12 40  1  4  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 196 Training on worker :59
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 196 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :43
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 196 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :91
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 196 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 196 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :78
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 196 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :25
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.685933
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.666237
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 196 Norm Difference for worker 25 is 0.070676
INFO:root:FL Epoch: 196 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :67
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 196 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 196 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :94
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.691087
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.651738
INFO:root:FL Epoch: 196 Norm Difference for worker 94 is 0.209214
INFO:root:FL Epoch: 196 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :95
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 196 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :51
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 196 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 196 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :76
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 196 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 196 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 59
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 196 Ends   ===================
INFO:root:Epoch:196 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:196 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 197 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 197 Workers Selected : [51, 93, 60, 76, 33, 26, 80, 71, 37, 95]
INFO:root:FL Epoch: 197 Fraction of points on each worker in this round: [0.08333333 0.04166667 0.0625     0.08333333 0.625      0.02083333
 0.02083333 0.02083333 0.02083333 0.02083333]
INFO:root:FL Epoch: 197 Num points on workers: [ 4  2  3  4 30  1  1  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 197 Training on worker :51
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 197 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 197 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :93
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 197 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 197 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :60
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 197 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 197 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :76
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 197 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 197 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :33
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.689504
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.668226
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 197 Norm Difference for worker 33 is 0.069121
INFO:root:FL Epoch: 197 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :26
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 197 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 197 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :80
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 197 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 197 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :71
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 197 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 197 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :37
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 197 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 197 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :95
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 197 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 197 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 51
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 197 Ends   ===================
INFO:root:Epoch:197 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:197 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 198 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 198 Workers Selected : [66, 56, 41, 16, 31, 85, 81, 68, 20, 71]
INFO:root:FL Epoch: 198 Fraction of points on each worker in this round: [0.05 0.15 0.2  0.1  0.05 0.1  0.15 0.1  0.05 0.05]
INFO:root:FL Epoch: 198 Num points on workers: [1 3 4 2 1 2 3 2 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 198 Training on worker :66
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 198 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 198 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :56
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 198 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 198 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :41
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 198 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 198 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :16
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 198 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 198 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :31
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 198 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 198 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :85
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 198 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 198 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :81
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 198 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 198 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :68
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 198 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 198 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :20
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 198 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 198 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :71
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 198 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 198 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 66
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 198 Ends   ===================
INFO:root:Epoch:198 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:198 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 199 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 199 Workers Selected : [12, 27, 35, 78, 85, 63, 67, 88, 14, 6]
INFO:root:FL Epoch: 199 Fraction of points on each worker in this round: [0.03125 0.15625 0.03125 0.03125 0.0625  0.0625  0.375   0.03125 0.1875
 0.03125]
INFO:root:FL Epoch: 199 Num points on workers: [ 1  5  1  1  2  2 12  1  6  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 199 Training on worker :12
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 199 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :27
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 199 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 199 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :35
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 199 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :78
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 199 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :85
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 199 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 199 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :63
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 199 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 199 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :67
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 199 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 199 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :88
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 199 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :14
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 199 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 199 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :6
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 199 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 12
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 199 Ends   ===================
INFO:root:Epoch:199 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:199 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 200 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 200 Workers Selected : [59, 11, 74, 28, 21, 42, 24, 23, 22, 29]
INFO:root:FL Epoch: 200 Fraction of points on each worker in this round: [0.01075269 0.03225806 0.1827957  0.06451613 0.5483871  0.03225806
 0.03225806 0.07526882 0.01075269 0.01075269]
INFO:root:FL Epoch: 200 Num points on workers: [ 1  3 17  6 51  3  3  7  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 200 Training on worker :59
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 200 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 200 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :11
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 200 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 200 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :74
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 200 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 200 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :28
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 200 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 200 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :21
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.699429
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.643067
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 200 Norm Difference for worker 21 is 0.222137
INFO:root:FL Epoch: 200 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :42
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 200 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 200 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :24
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 200 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 200 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :23
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 200 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 200 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :22
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 200 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 200 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :29
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 200 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 200 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 59
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 200 Ends   ===================
INFO:root:Epoch:200 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:200 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 201 Begins ===================
INFO:root:FL Epoch: 201 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 201 Workers Selected : [0, 1, 2, 58, 8, 90, 41, 80, 13, 42]
INFO:root:FL Epoch: 201 Fraction of points on each worker in this round: [0.31595577 0.31595577 0.31595577 0.02843602 0.00157978 0.00315956
 0.00631912 0.00157978 0.00631912 0.00473934]
INFO:root:FL Epoch: 201 Num points on workers: [200 200 200  18   1   2   4   1   4   3]
INFO:root:--------------------------
INFO:root:FL Epoch: 201 Training on worker :0
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695910
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689983
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Test Loss: 0.734505424896876 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Train Loss: 0.6864024341106415 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 201 Norm Difference for worker 0 is 0.088688
INFO:root:FL Epoch: 201 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689252
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686087
INFO:root:FL Epoch: 201 Worker: 1 Backdoor Test Loss: 0.7364017764727274 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 201 Worker: 1 Backdoor Train Loss: 0.686304897069931 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 201 Norm Difference for worker 1 is 0.090406
INFO:root:FL Epoch: 201 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :2
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688468
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693228
INFO:root:FL Epoch: 201 Worker: 2 Backdoor Test Loss: 0.7323187092940012 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 201 Worker: 2 Backdoor Train Loss: 0.6865427315235137 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 201 Norm Difference for worker 2 is 0.087008
INFO:root:FL Epoch: 201 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :58
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 201 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 201 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :8
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 201 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 201 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :90
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 201 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 201 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :41
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 201 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 201 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :80
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 201 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 201 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :13
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 201 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 201 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :42
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 201 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 201 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 58
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 201 Ends   ===================
INFO:root:Epoch:201 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:201 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 202 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 202 Workers Selected : [52, 91, 76, 24, 9, 75, 41, 39, 80, 89]
INFO:root:FL Epoch: 202 Fraction of points on each worker in this round: [0.01851852 0.07407407 0.07407407 0.05555556 0.38888889 0.03703704
 0.07407407 0.24074074 0.01851852 0.01851852]
INFO:root:FL Epoch: 202 Num points on workers: [ 1  4  4  3 21  2  4 13  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 202 Training on worker :52
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 202 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :91
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 202 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 202 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :76
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 202 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 202 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :24
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 202 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 202 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :9
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.688315
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.667998
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 9 is 0.065652
INFO:root:FL Epoch: 202 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :75
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 202 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 202 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :41
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 202 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 202 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :39
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 202 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 202 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :80
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 202 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :89
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 202 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 52
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 202 Ends   ===================
INFO:root:Epoch:202 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:202 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 203 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 203 Workers Selected : [49, 54, 69, 19, 37, 56, 85, 46, 97, 45]
INFO:root:FL Epoch: 203 Fraction of points on each worker in this round: [0.02564103 0.02564103 0.43589744 0.02564103 0.02564103 0.07692308
 0.05128205 0.02564103 0.25641026 0.05128205]
INFO:root:FL Epoch: 203 Num points on workers: [ 1  1 17  1  1  3  2  1 10  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 203 Training on worker :49
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 203 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 203 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :54
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 203 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 203 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :69
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 203 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 203 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :19
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 203 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 203 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :37
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 203 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 203 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :56
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 203 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 203 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :85
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 203 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 203 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :46
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 203 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 203 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :97
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 203 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 203 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :45
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 203 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 203 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 49
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 203 Ends   ===================
INFO:root:Epoch:203 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:203 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 204 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 204 Workers Selected : [85, 39, 90, 88, 93, 16, 77, 4, 26, 18]
INFO:root:FL Epoch: 204 Fraction of points on each worker in this round: [0.06896552 0.44827586 0.06896552 0.03448276 0.06896552 0.06896552
 0.03448276 0.03448276 0.03448276 0.13793103]
INFO:root:FL Epoch: 204 Num points on workers: [ 2 13  2  1  2  2  1  1  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 204 Training on worker :85
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 204 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 204 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :39
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 204 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 204 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :90
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 204 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 204 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :88
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 204 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :93
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 204 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 204 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :16
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 204 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 204 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :77
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 204 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :4
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 204 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :26
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 204 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :18
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 204 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 204 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 85
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 204 Ends   ===================
INFO:root:Epoch:204 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:204 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 205 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 205 Workers Selected : [37, 94, 40, 27, 64, 28, 78, 45, 79, 36]
INFO:root:FL Epoch: 205 Fraction of points on each worker in this round: [0.01587302 0.63492063 0.01587302 0.07936508 0.04761905 0.0952381
 0.01587302 0.03174603 0.03174603 0.03174603]
INFO:root:FL Epoch: 205 Num points on workers: [ 1 40  1  5  3  6  1  2  2  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 205 Training on worker :37
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 205 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :94
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.689907
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.642907
INFO:root:FL Epoch: 205 Norm Difference for worker 94 is 0.207997
INFO:root:FL Epoch: 205 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :40
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 205 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :27
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 205 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 205 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :64
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 205 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 205 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :28
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 205 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 205 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :78
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 205 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :45
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 205 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 205 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :79
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 205 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 205 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :36
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 205 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 205 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 37
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 205 Ends   ===================
INFO:root:Epoch:205 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:205 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 206 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 206 Workers Selected : [10, 25, 56, 34, 44, 24, 49, 87, 41, 63]
INFO:root:FL Epoch: 206 Fraction of points on each worker in this round: [0.02083333 0.5        0.0625     0.0625     0.04166667 0.0625
 0.02083333 0.10416667 0.08333333 0.04166667]
INFO:root:FL Epoch: 206 Num points on workers: [ 1 24  3  3  2  3  1  5  4  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 206 Training on worker :10
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 206 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :25
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.678925
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.675634
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 206 Norm Difference for worker 25 is 0.069453
INFO:root:FL Epoch: 206 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :56
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 206 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 206 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :34
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 206 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 206 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :44
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 206 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 206 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :24
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 206 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 206 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :49
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 206 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :87
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 206 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 206 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :41
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 206 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 206 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :63
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 206 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 206 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 10
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 206 Ends   ===================
INFO:root:Epoch:206 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:206 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 207 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 207 Workers Selected : [7, 28, 66, 73, 20, 86, 81, 74, 3, 67]
INFO:root:FL Epoch: 207 Fraction of points on each worker in this round: [0.02083333 0.125      0.02083333 0.02083333 0.02083333 0.10416667
 0.0625     0.35416667 0.02083333 0.25      ]
INFO:root:FL Epoch: 207 Num points on workers: [ 1  6  1  1  1  5  3 17  1 12]
INFO:root:--------------------------
INFO:root:FL Epoch: 207 Training on worker :7
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 207 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :28
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 207 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 207 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :66
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 207 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :73
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 207 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :20
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 207 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :86
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 207 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 207 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :81
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 207 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 207 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :74
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 207 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 207 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :3
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 207 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :67
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 207 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 207 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 7
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 207 Ends   ===================
INFO:root:Epoch:207 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:207 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 208 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 208 Workers Selected : [42, 68, 7, 79, 57, 44, 36, 89, 40, 27]
INFO:root:FL Epoch: 208 Fraction of points on each worker in this round: [0.09375 0.0625  0.03125 0.0625  0.40625 0.0625  0.0625  0.03125 0.03125
 0.15625]
INFO:root:FL Epoch: 208 Num points on workers: [ 3  2  1  2 13  2  2  1  1  5]
INFO:root:--------------------------
INFO:root:FL Epoch: 208 Training on worker :42
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 208 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 208 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :68
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 208 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 208 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :7
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 208 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 208 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :79
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 208 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 208 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :57
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 208 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 208 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :44
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 208 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 208 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :36
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 208 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 208 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :89
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 208 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 208 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :40
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 208 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 208 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :27
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 208 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 208 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 208 Ends   ===================
INFO:root:Epoch:208 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:208 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 209 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 209 Workers Selected : [61, 50, 25, 98, 89, 82, 19, 29, 46, 97]
INFO:root:FL Epoch: 209 Fraction of points on each worker in this round: [0.02380952 0.02380952 0.57142857 0.02380952 0.02380952 0.02380952
 0.02380952 0.02380952 0.02380952 0.23809524]
INFO:root:FL Epoch: 209 Num points on workers: [ 1  1 24  1  1  1  1  1  1 10]
INFO:root:--------------------------
INFO:root:FL Epoch: 209 Training on worker :61
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 209 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :50
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 209 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :25
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.683788
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.676637
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 209 Norm Difference for worker 25 is 0.068969
INFO:root:FL Epoch: 209 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :98
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 209 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :89
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 209 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :82
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 209 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :19
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 209 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :29
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 209 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :46
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 209 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :97
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 209 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 209 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 61
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 209 Ends   ===================
INFO:root:Epoch:209 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:209 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 210 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 210 Workers Selected : [61, 35, 49, 26, 36, 6, 37, 52, 78, 58]
INFO:root:FL Epoch: 210 Fraction of points on each worker in this round: [0.03571429 0.03571429 0.03571429 0.03571429 0.07142857 0.03571429
 0.03571429 0.03571429 0.03571429 0.64285714]
INFO:root:FL Epoch: 210 Num points on workers: [ 1  1  1  1  2  1  1  1  1 18]
INFO:root:--------------------------
INFO:root:FL Epoch: 210 Training on worker :61
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 210 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :35
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 210 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :49
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 210 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :26
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 210 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :36
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 210 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 210 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :6
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 210 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :37
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 210 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :52
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 210 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :78
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 210 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :58
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 210 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 210 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 61
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 210 Ends   ===================
INFO:root:Epoch:210 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:210 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 211 Begins ===================
INFO:root:FL Epoch: 211 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 211 Workers Selected : [0, 1, 2, 37, 26, 41, 65, 29, 12, 14]
INFO:root:FL Epoch: 211 Fraction of points on each worker in this round: [0.32520325 0.32520325 0.32520325 0.00162602 0.00162602 0.00650407
 0.00162602 0.00162602 0.00162602 0.0097561 ]
INFO:root:FL Epoch: 211 Num points on workers: [200 200 200   1   1   4   1   1   1   6]
INFO:root:--------------------------
INFO:root:FL Epoch: 211 Training on worker :0
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688149
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700626
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Test Loss: 0.7292344868183136 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Train Loss: 0.6868253290653229 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 211 Norm Difference for worker 0 is 0.083626
INFO:root:FL Epoch: 211 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692996
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689356
INFO:root:FL Epoch: 211 Worker: 1 Backdoor Test Loss: 0.7327101031939188 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 211 Worker: 1 Backdoor Train Loss: 0.6865557670593262 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 211 Norm Difference for worker 1 is 0.086886
INFO:root:FL Epoch: 211 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :2
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697820
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688400
INFO:root:FL Epoch: 211 Worker: 2 Backdoor Test Loss: 0.7312007546424866 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 211 Worker: 2 Backdoor Train Loss: 0.6865915656089783 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 211 Norm Difference for worker 2 is 0.086596
INFO:root:FL Epoch: 211 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :37
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 211 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :26
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 211 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :41
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 211 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 211 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :65
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 211 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :29
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 211 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :12
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 211 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :14
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 211 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 211 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 37
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 211 Ends   ===================
INFO:root:Epoch:211 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:211 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 212 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 212 Workers Selected : [75, 93, 39, 5, 61, 7, 97, 88, 57, 21]
INFO:root:FL Epoch: 212 Fraction of points on each worker in this round: [0.01941748 0.01941748 0.12621359 0.08737864 0.00970874 0.00970874
 0.09708738 0.00970874 0.12621359 0.49514563]
INFO:root:FL Epoch: 212 Num points on workers: [ 2  2 13  9  1  1 10  1 13 51]
INFO:root:--------------------------
INFO:root:FL Epoch: 212 Training on worker :75
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 212 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 212 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :93
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 212 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 212 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :39
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 212 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 212 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :5
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 212 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 212 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :61
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 212 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :7
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 212 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :97
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 212 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 212 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :88
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 212 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :57
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 212 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 212 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :21
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.701604
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.646302
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 212 Norm Difference for worker 21 is 0.218305
INFO:root:FL Epoch: 212 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 75
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 212 Ends   ===================
INFO:root:Epoch:212 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:212 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 213 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 213 Workers Selected : [55, 44, 14, 66, 94, 85, 5, 77, 87, 10]
INFO:root:FL Epoch: 213 Fraction of points on each worker in this round: [0.01470588 0.02941176 0.08823529 0.01470588 0.58823529 0.02941176
 0.13235294 0.01470588 0.07352941 0.01470588]
INFO:root:FL Epoch: 213 Num points on workers: [ 1  2  6  1 40  2  9  1  5  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 213 Training on worker :55
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 213 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 213 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :44
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 213 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 213 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :14
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 213 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 213 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :66
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 213 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 213 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :94
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.690262
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.646765
INFO:root:FL Epoch: 213 Norm Difference for worker 94 is 0.204017
INFO:root:FL Epoch: 213 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :85
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 213 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 213 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :5
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 213 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 213 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :77
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 213 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 213 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :87
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 213 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 213 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :10
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 213 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 213 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 55
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 213 Ends   ===================
INFO:root:Epoch:213 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:213 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 214 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 214 Workers Selected : [14, 72, 37, 3, 96, 40, 38, 54, 17, 77]
INFO:root:FL Epoch: 214 Fraction of points on each worker in this round: [0.28571429 0.28571429 0.04761905 0.04761905 0.04761905 0.04761905
 0.04761905 0.04761905 0.0952381  0.04761905]
INFO:root:FL Epoch: 214 Num points on workers: [6 6 1 1 1 1 1 1 2 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 214 Training on worker :14
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 214 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 214 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :72
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 214 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 214 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :37
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 214 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :3
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 214 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :96
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 214 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :40
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 214 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :38
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 214 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :54
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 214 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :17
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 214 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 214 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :77
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 214 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 14
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 214 Ends   ===================
INFO:root:Epoch:214 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:214 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 215 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 215 Workers Selected : [62, 52, 99, 40, 78, 96, 34, 31, 89, 55]
INFO:root:FL Epoch: 215 Fraction of points on each worker in this round: [0.1875 0.0625 0.1875 0.0625 0.0625 0.0625 0.1875 0.0625 0.0625 0.0625]
INFO:root:FL Epoch: 215 Num points on workers: [3 1 3 1 1 1 3 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 215 Training on worker :62
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 215 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 215 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :52
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 215 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :99
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 215 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 215 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :40
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 215 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :78
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 215 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :96
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 215 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :34
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 215 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 215 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :31
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 215 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :89
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 215 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :55
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 215 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 62
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 215 Ends   ===================
INFO:root:Epoch:215 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:215 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 216 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 216 Workers Selected : [87, 8, 15, 96, 13, 27, 26, 81, 36, 48]
INFO:root:FL Epoch: 216 Fraction of points on each worker in this round: [0.20833333 0.04166667 0.04166667 0.04166667 0.16666667 0.20833333
 0.04166667 0.125      0.08333333 0.04166667]
INFO:root:FL Epoch: 216 Num points on workers: [5 1 1 1 4 5 1 3 2 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 216 Training on worker :87
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 216 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 216 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :8
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 216 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 216 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :15
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 216 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 216 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :96
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 216 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 216 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :13
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 216 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 216 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :27
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 216 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 216 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :26
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 216 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 216 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :81
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 216 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 216 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :36
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 216 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 216 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :48
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 216 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 216 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 87
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 216 Ends   ===================
INFO:root:Epoch:216 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:216 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 217 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 217 Workers Selected : [54, 33, 77, 37, 8, 88, 43, 84, 98, 82]
INFO:root:FL Epoch: 217 Fraction of points on each worker in this round: [0.02 0.6  0.02 0.02 0.02 0.02 0.02 0.24 0.02 0.02]
INFO:root:FL Epoch: 217 Num points on workers: [ 1 30  1  1  1  1  1 12  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 217 Training on worker :54
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 217 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 217 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :33
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.686131
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.672527
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 217 Norm Difference for worker 33 is 0.064865
INFO:root:FL Epoch: 217 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :77
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 217 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 217 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :37
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 217 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 217 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :8
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 217 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 217 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :88
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 217 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 217 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :43
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 217 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 217 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :84
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 217 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 217 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :98
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 217 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 217 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :82
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 217 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 217 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 54
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 217 Ends   ===================
INFO:root:Epoch:217 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:217 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 218 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 218 Workers Selected : [22, 81, 93, 4, 92, 91, 61, 33, 44, 53]
INFO:root:FL Epoch: 218 Fraction of points on each worker in this round: [0.01923077 0.05769231 0.03846154 0.01923077 0.07692308 0.07692308
 0.01923077 0.57692308 0.03846154 0.07692308]
INFO:root:FL Epoch: 218 Num points on workers: [ 1  3  2  1  4  4  1 30  2  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 218 Training on worker :22
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 218 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :81
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 218 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 218 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :93
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 218 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 218 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :4
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 218 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :92
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 218 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 218 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :91
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 218 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 218 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :61
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 218 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :33
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.679956
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.673097
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 218 Norm Difference for worker 33 is 0.065173
INFO:root:FL Epoch: 218 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :44
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 218 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 218 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :53
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 218 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 218 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 22
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 218 Ends   ===================
INFO:root:Epoch:218 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:218 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 219 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 219 Workers Selected : [58, 47, 72, 65, 75, 60, 17, 25, 78, 32]
INFO:root:FL Epoch: 219 Fraction of points on each worker in this round: [0.28125  0.046875 0.09375  0.015625 0.03125  0.046875 0.03125  0.375
 0.015625 0.0625  ]
INFO:root:FL Epoch: 219 Num points on workers: [18  3  6  1  2  3  2 24  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 219 Training on worker :58
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 219 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 219 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :47
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 219 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 219 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :72
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 219 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 219 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :65
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 219 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :75
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 219 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 219 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :60
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 219 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 219 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :17
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 219 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 219 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :25
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.694833
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.671721
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 219 Norm Difference for worker 25 is 0.067605
INFO:root:FL Epoch: 219 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :78
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 219 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :32
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 219 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 219 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 58
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 219 Ends   ===================
INFO:root:Epoch:219 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:219 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 220 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 220 Workers Selected : [79, 62, 55, 61, 95, 32, 67, 45, 54, 18]
INFO:root:FL Epoch: 220 Fraction of points on each worker in this round: [0.06451613 0.09677419 0.03225806 0.03225806 0.03225806 0.12903226
 0.38709677 0.06451613 0.03225806 0.12903226]
INFO:root:FL Epoch: 220 Num points on workers: [ 2  3  1  1  1  4 12  2  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 220 Training on worker :79
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 220 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 220 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :62
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 220 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 220 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :55
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 220 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 220 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :61
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 220 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 220 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :95
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 220 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 220 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :32
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 220 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 220 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :67
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 220 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 220 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :45
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 220 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 220 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :54
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 220 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 220 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :18
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 220 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 220 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 79
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 220 Ends   ===================
INFO:root:Epoch:220 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:220 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 221 Begins ===================
INFO:root:FL Epoch: 221 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 221 Workers Selected : [0, 1, 2, 12, 35, 8, 17, 59, 96, 42]
INFO:root:FL Epoch: 221 Fraction of points on each worker in this round: [0.32786885 0.32786885 0.32786885 0.00163934 0.00163934 0.00163934
 0.00327869 0.00163934 0.00163934 0.00491803]
INFO:root:FL Epoch: 221 Num points on workers: [200 200 200   1   1   1   2   1   1   3]
INFO:root:--------------------------
INFO:root:FL Epoch: 221 Training on worker :0
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700403
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696164
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Test Loss: 0.7309752404689789 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Train Loss: 0.6869885861873627 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 221 Norm Difference for worker 0 is 0.082509
INFO:root:FL Epoch: 221 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692183
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690989
INFO:root:FL Epoch: 221 Worker: 1 Backdoor Test Loss: 0.7280376454194387 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 221 Worker: 1 Backdoor Train Loss: 0.6870047807693481 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 221 Norm Difference for worker 1 is 0.081434
INFO:root:FL Epoch: 221 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :2
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696596
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700015
INFO:root:FL Epoch: 221 Worker: 2 Backdoor Test Loss: 0.7314082980155945 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 221 Worker: 2 Backdoor Train Loss: 0.6869247436523438 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 221 Norm Difference for worker 2 is 0.082817
INFO:root:FL Epoch: 221 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :12
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 221 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :35
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 221 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :8
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 221 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :17
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 221 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 221 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :59
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 221 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :96
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 221 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :42
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 221 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 221 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 12
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 221 Ends   ===================
INFO:root:Epoch:221 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:221 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 222 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 222 Workers Selected : [66, 86, 23, 74, 97, 48, 20, 59, 9, 6]
INFO:root:FL Epoch: 222 Fraction of points on each worker in this round: [0.01538462 0.07692308 0.10769231 0.26153846 0.15384615 0.01538462
 0.01538462 0.01538462 0.32307692 0.01538462]
INFO:root:FL Epoch: 222 Num points on workers: [ 1  5  7 17 10  1  1  1 21  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 222 Training on worker :66
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 222 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :86
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 222 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 222 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :23
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 222 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 222 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :74
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 222 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 222 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :97
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 222 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 222 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :48
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 222 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :20
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 222 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :59
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 222 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :9
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.682013
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.675112
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 9 is 0.063538
INFO:root:FL Epoch: 222 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :6
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 222 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 66
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 222 Ends   ===================
INFO:root:Epoch:222 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:222 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 223 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 223 Workers Selected : [32, 39, 33, 62, 40, 51, 77, 42, 28, 10]
INFO:root:FL Epoch: 223 Fraction of points on each worker in this round: [0.06060606 0.1969697  0.45454545 0.04545455 0.01515152 0.06060606
 0.01515152 0.04545455 0.09090909 0.01515152]
INFO:root:FL Epoch: 223 Num points on workers: [ 4 13 30  3  1  4  1  3  6  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 223 Training on worker :32
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 223 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 223 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :39
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 223 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 223 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :33
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.684011
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.673241
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 223 Norm Difference for worker 33 is 0.064917
INFO:root:FL Epoch: 223 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :62
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 223 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 223 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :40
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 223 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :51
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 223 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 223 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :77
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 223 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :42
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 223 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 223 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :28
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 223 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 223 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :10
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 223 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 32
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 223 Ends   ===================
INFO:root:Epoch:223 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:223 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 224 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 224 Workers Selected : [33, 10, 58, 47, 27, 7, 28, 66, 61, 41]
INFO:root:FL Epoch: 224 Fraction of points on each worker in this round: [0.42857143 0.01428571 0.25714286 0.04285714 0.07142857 0.01428571
 0.08571429 0.01428571 0.01428571 0.05714286]
INFO:root:FL Epoch: 224 Num points on workers: [30  1 18  3  5  1  6  1  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 224 Training on worker :33
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.692762
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.674450
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 224 Norm Difference for worker 33 is 0.064487
INFO:root:FL Epoch: 224 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :10
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 224 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :58
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 224 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 224 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :47
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 224 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 224 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :27
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 224 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 224 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :7
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 224 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :28
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 224 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 224 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :66
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 224 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :61
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 224 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :41
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 224 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 224 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 10
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 224 Ends   ===================
INFO:root:Epoch:224 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:224 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 225 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 225 Workers Selected : [17, 82, 97, 55, 9, 21, 60, 45, 92, 86]
INFO:root:FL Epoch: 225 Fraction of points on each worker in this round: [0.02 0.01 0.1  0.01 0.21 0.51 0.03 0.02 0.04 0.05]
INFO:root:FL Epoch: 225 Num points on workers: [ 2  1 10  1 21 51  3  2  4  5]
INFO:root:--------------------------
INFO:root:FL Epoch: 225 Training on worker :17
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 225 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 225 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :82
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 225 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :97
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 225 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 225 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :55
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 225 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :9
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.678849
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.668131
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 9 is 0.06174
INFO:root:FL Epoch: 225 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :21
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.698444
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.645544
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 225 Norm Difference for worker 21 is 0.211789
INFO:root:FL Epoch: 225 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :60
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 225 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 225 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :45
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 225 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 225 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :92
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 225 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 225 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :86
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 225 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 225 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 17
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 225 Ends   ===================
INFO:root:Epoch:225 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:225 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 226 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 226 Workers Selected : [32, 33, 90, 70, 23, 34, 66, 53, 50, 31]
INFO:root:FL Epoch: 226 Fraction of points on each worker in this round: [0.07272727 0.54545455 0.03636364 0.03636364 0.12727273 0.05454545
 0.01818182 0.07272727 0.01818182 0.01818182]
INFO:root:FL Epoch: 226 Num points on workers: [ 4 30  2  2  7  3  1  4  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 226 Training on worker :32
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 226 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 226 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :33
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.680595
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.673863
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 226 Norm Difference for worker 33 is 0.063785
INFO:root:FL Epoch: 226 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :90
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 226 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 226 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :70
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 226 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 226 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :23
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 226 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 226 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :34
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 226 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 226 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :66
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 226 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 226 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :53
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 226 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 226 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :50
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 226 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 226 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :31
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 226 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 226 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 32
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 226 Ends   ===================
INFO:root:Epoch:226 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:226 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 227 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 227 Workers Selected : [97, 17, 83, 51, 28, 13, 49, 45, 22, 92]
INFO:root:FL Epoch: 227 Fraction of points on each worker in this round: [0.27777778 0.05555556 0.05555556 0.11111111 0.16666667 0.11111111
 0.02777778 0.05555556 0.02777778 0.11111111]
INFO:root:FL Epoch: 227 Num points on workers: [10  2  2  4  6  4  1  2  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 227 Training on worker :97
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 227 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 227 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :17
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 227 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 227 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :83
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 227 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 227 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :51
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 227 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 227 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :28
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 227 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 227 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :13
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 227 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 227 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :49
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 227 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :45
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 227 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 227 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :22
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 227 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :92
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 227 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 227 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 97
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 227 Ends   ===================
INFO:root:Epoch:227 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:227 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 228 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 228 Workers Selected : [52, 64, 71, 89, 79, 26, 38, 97, 17, 68]
INFO:root:FL Epoch: 228 Fraction of points on each worker in this round: [0.04166667 0.125      0.04166667 0.04166667 0.08333333 0.04166667
 0.04166667 0.41666667 0.08333333 0.08333333]
INFO:root:FL Epoch: 228 Num points on workers: [ 1  3  1  1  2  1  1 10  2  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 228 Training on worker :52
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 228 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 228 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :64
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 228 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 228 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :71
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 228 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 228 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :89
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 228 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 228 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :79
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 228 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 228 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :26
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 228 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 228 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :38
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 228 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 228 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :97
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 228 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 228 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :17
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 228 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 228 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :68
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 228 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 228 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 52
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 228 Ends   ===================
INFO:root:Epoch:228 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:228 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 229 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 229 Workers Selected : [33, 14, 84, 97, 73, 74, 46, 63, 47, 68]
INFO:root:FL Epoch: 229 Fraction of points on each worker in this round: [0.35714286 0.07142857 0.14285714 0.11904762 0.01190476 0.20238095
 0.01190476 0.02380952 0.03571429 0.02380952]
INFO:root:FL Epoch: 229 Num points on workers: [30  6 12 10  1 17  1  2  3  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 229 Training on worker :33
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.684504
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.669101
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 229 Norm Difference for worker 33 is 0.064196
INFO:root:FL Epoch: 229 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :14
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 229 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 229 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :84
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 229 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 229 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :97
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 229 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 229 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :73
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 229 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :74
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 229 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 229 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :46
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 229 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :63
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 229 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 229 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :47
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 229 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 229 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :68
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 229 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 229 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 14
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 229 Ends   ===================
INFO:root:Epoch:229 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:229 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 230 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 230 Workers Selected : [58, 35, 61, 15, 68, 46, 3, 45, 6, 55]
INFO:root:FL Epoch: 230 Fraction of points on each worker in this round: [0.62068966 0.03448276 0.03448276 0.03448276 0.06896552 0.03448276
 0.03448276 0.06896552 0.03448276 0.03448276]
INFO:root:FL Epoch: 230 Num points on workers: [18  1  1  1  2  1  1  2  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 230 Training on worker :58
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 230 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 230 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :35
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 230 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :61
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 230 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :15
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 230 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :68
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 230 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 230 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :46
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 230 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :3
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 230 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :45
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 230 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 230 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :6
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 230 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :55
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 230 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 58
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 230 Ends   ===================
INFO:root:Epoch:230 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:230 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 231 Begins ===================
INFO:root:FL Epoch: 231 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 231 Workers Selected : [0, 1, 2, 50, 61, 17, 30, 25, 79, 23]
INFO:root:FL Epoch: 231 Fraction of points on each worker in this round: [0.31298905 0.31298905 0.31298905 0.00156495 0.00156495 0.00312989
 0.00312989 0.03755869 0.00312989 0.01095462]
INFO:root:FL Epoch: 231 Num points on workers: [200 200 200   1   1   2   2  24   2   7]
INFO:root:--------------------------
INFO:root:FL Epoch: 231 Training on worker :0
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695141
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682229
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Test Loss: 0.7361477116743723 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Train Loss: 0.6866487681865692 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 231 Norm Difference for worker 0 is 0.086751
INFO:root:FL Epoch: 231 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704933
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702611
INFO:root:FL Epoch: 231 Worker: 1 Backdoor Test Loss: 0.7322690884272257 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 231 Worker: 1 Backdoor Train Loss: 0.6868553996086121 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 231 Norm Difference for worker 1 is 0.083678
INFO:root:FL Epoch: 231 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :2
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687481
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689681
INFO:root:FL Epoch: 231 Worker: 2 Backdoor Test Loss: 0.7321334580580393 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 231 Worker: 2 Backdoor Train Loss: 0.6866692364215851 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 231 Norm Difference for worker 2 is 0.085484
INFO:root:FL Epoch: 231 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :50
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 231 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :61
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 231 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :17
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 231 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 231 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :30
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 231 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 231 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :25
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.692982
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.672624
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 231 Norm Difference for worker 25 is 0.066975
INFO:root:FL Epoch: 231 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :79
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 231 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 231 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :23
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 231 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 231 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 50
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 231 Ends   ===================
INFO:root:Epoch:231 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:231 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 232 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 232 Workers Selected : [41, 43, 96, 21, 83, 89, 64, 70, 4, 98]
INFO:root:FL Epoch: 232 Fraction of points on each worker in this round: [0.05970149 0.01492537 0.01492537 0.76119403 0.02985075 0.01492537
 0.04477612 0.02985075 0.01492537 0.01492537]
INFO:root:FL Epoch: 232 Num points on workers: [ 4  1  1 51  2  1  3  2  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 232 Training on worker :41
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 232 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 232 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :43
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 232 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 232 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :96
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 232 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 232 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :21
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.699440
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.649108
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 232 Norm Difference for worker 21 is 0.208381
INFO:root:FL Epoch: 232 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :83
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 232 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 232 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :89
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 232 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 232 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :64
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 232 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 232 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :70
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 232 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 232 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :4
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 232 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 232 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :98
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 232 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 232 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 41
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 232 Ends   ===================
INFO:root:Epoch:232 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:232 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 233 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 233 Workers Selected : [14, 48, 81, 29, 43, 87, 58, 20, 10, 27]
INFO:root:FL Epoch: 233 Fraction of points on each worker in this round: [0.14285714 0.02380952 0.07142857 0.02380952 0.02380952 0.11904762
 0.42857143 0.02380952 0.02380952 0.11904762]
INFO:root:FL Epoch: 233 Num points on workers: [ 6  1  3  1  1  5 18  1  1  5]
INFO:root:--------------------------
INFO:root:FL Epoch: 233 Training on worker :14
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 233 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 233 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :48
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 233 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :81
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 233 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 233 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :29
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 233 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :43
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 233 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :87
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 233 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 233 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :58
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 233 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 233 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :20
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 233 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :10
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 233 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :27
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 233 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 233 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 14
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 233 Ends   ===================
INFO:root:Epoch:233 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:233 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 234 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 234 Workers Selected : [54, 31, 87, 88, 55, 93, 91, 49, 98, 15]
INFO:root:FL Epoch: 234 Fraction of points on each worker in this round: [0.05555556 0.05555556 0.27777778 0.05555556 0.05555556 0.11111111
 0.22222222 0.05555556 0.05555556 0.05555556]
INFO:root:FL Epoch: 234 Num points on workers: [1 1 5 1 1 2 4 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 234 Training on worker :54
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 234 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 234 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :31
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 234 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 234 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :87
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 234 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 234 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :88
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 234 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 234 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :55
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 234 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 234 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :93
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 234 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 234 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :91
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 234 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 234 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :49
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 234 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 234 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :98
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 234 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 234 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :15
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 234 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 234 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 54
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 234 Ends   ===================
INFO:root:Epoch:234 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:234 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 235 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 235 Workers Selected : [68, 99, 61, 80, 55, 98, 52, 94, 44, 9]
INFO:root:FL Epoch: 235 Fraction of points on each worker in this round: [0.02739726 0.04109589 0.01369863 0.01369863 0.01369863 0.01369863
 0.01369863 0.54794521 0.02739726 0.28767123]
INFO:root:FL Epoch: 235 Num points on workers: [ 2  3  1  1  1  1  1 40  2 21]
INFO:root:--------------------------
INFO:root:FL Epoch: 235 Training on worker :68
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 235 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 235 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :99
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 235 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 235 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :61
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 235 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :80
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 235 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :55
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 235 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :98
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 235 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :52
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 235 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :94
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.686109
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.649490
INFO:root:FL Epoch: 235 Norm Difference for worker 94 is 0.191919
INFO:root:FL Epoch: 235 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :44
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 235 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 235 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :9
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.680822
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.668864
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 9 is 0.061615
INFO:root:FL Epoch: 235 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 68
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 235 Ends   ===================
INFO:root:Epoch:235 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:235 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 236 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 236 Workers Selected : [32, 82, 30, 20, 41, 50, 38, 47, 61, 70]
INFO:root:FL Epoch: 236 Fraction of points on each worker in this round: [0.2  0.05 0.1  0.05 0.2  0.05 0.05 0.15 0.05 0.1 ]
INFO:root:FL Epoch: 236 Num points on workers: [4 1 2 1 4 1 1 3 1 2]
INFO:root:--------------------------
INFO:root:FL Epoch: 236 Training on worker :32
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 236 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 236 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :82
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 236 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :30
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 236 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 236 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :20
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 236 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :41
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 236 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 236 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :50
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 236 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :38
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 236 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :47
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 236 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 236 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :61
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 236 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :70
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 236 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 236 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 32
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 236 Ends   ===================
INFO:root:Epoch:236 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:236 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 237 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 237 Workers Selected : [21, 46, 63, 92, 31, 66, 5, 73, 97, 68]
INFO:root:FL Epoch: 237 Fraction of points on each worker in this round: [0.62195122 0.01219512 0.02439024 0.04878049 0.01219512 0.01219512
 0.1097561  0.01219512 0.12195122 0.02439024]
INFO:root:FL Epoch: 237 Num points on workers: [51  1  2  4  1  1  9  1 10  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 237 Training on worker :21
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.692726
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.649840
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 237 Norm Difference for worker 21 is 0.208569
INFO:root:FL Epoch: 237 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :46
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 237 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :63
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 237 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 237 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :92
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 237 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 237 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :31
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 237 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :66
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 237 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :5
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 237 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 237 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :73
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 237 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :97
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 237 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 237 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :68
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 237 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 237 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 46
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 237 Ends   ===================
INFO:root:Epoch:237 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:237 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 238 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 238 Workers Selected : [65, 97, 67, 63, 76, 21, 15, 92, 5, 73]
INFO:root:FL Epoch: 238 Fraction of points on each worker in this round: [0.01052632 0.10526316 0.12631579 0.02105263 0.04210526 0.53684211
 0.01052632 0.04210526 0.09473684 0.01052632]
INFO:root:FL Epoch: 238 Num points on workers: [ 1 10 12  2  4 51  1  4  9  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 238 Training on worker :65
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 238 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :97
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 238 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 238 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :67
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 238 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 238 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :63
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 238 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 238 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :76
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 238 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 238 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :21
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.697239
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.650676
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 238 Norm Difference for worker 21 is 0.207153
INFO:root:FL Epoch: 238 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :15
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 238 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :92
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 238 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 238 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :5
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 238 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 238 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :73
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 238 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 65
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 238 Ends   ===================
INFO:root:Epoch:238 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:238 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 239 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 239 Workers Selected : [18, 25, 21, 10, 76, 4, 30, 50, 12, 59]
INFO:root:FL Epoch: 239 Fraction of points on each worker in this round: [0.04444444 0.26666667 0.56666667 0.01111111 0.04444444 0.01111111
 0.02222222 0.01111111 0.01111111 0.01111111]
INFO:root:FL Epoch: 239 Num points on workers: [ 4 24 51  1  4  1  2  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 239 Training on worker :18
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 239 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 239 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :25
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.686338
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.673393
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 239 Norm Difference for worker 25 is 0.064565
INFO:root:FL Epoch: 239 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :21
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.691554
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.649866
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 239 Norm Difference for worker 21 is 0.20888
INFO:root:FL Epoch: 239 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :10
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 239 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :76
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 239 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 239 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :4
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 239 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :30
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 239 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 239 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :50
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 239 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :12
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 239 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :59
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 239 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 18
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 239 Ends   ===================
INFO:root:Epoch:239 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:239 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 240 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 240 Workers Selected : [56, 72, 68, 3, 33, 36, 78, 37, 43, 49]
INFO:root:FL Epoch: 240 Fraction of points on each worker in this round: [0.0625     0.125      0.04166667 0.02083333 0.625      0.04166667
 0.02083333 0.02083333 0.02083333 0.02083333]
INFO:root:FL Epoch: 240 Num points on workers: [ 3  6  2  1 30  2  1  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 240 Training on worker :56
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 240 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 240 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :72
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 240 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 240 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :68
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 240 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 240 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :3
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 240 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :33
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.687209
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.668459
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 240 Norm Difference for worker 33 is 0.062175
INFO:root:FL Epoch: 240 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :36
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 240 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 240 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :78
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 240 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :37
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 240 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :43
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 240 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :49
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 240 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 56
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 240 Ends   ===================
INFO:root:Epoch:240 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:240 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 241 Begins ===================
INFO:root:FL Epoch: 241 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 241 Workers Selected : [0, 1, 2, 77, 63, 36, 74, 76, 75, 48]
INFO:root:FL Epoch: 241 Fraction of points on each worker in this round: [0.31796502 0.31796502 0.31796502 0.00158983 0.00317965 0.00317965
 0.02702703 0.0063593  0.00317965 0.00158983]
INFO:root:FL Epoch: 241 Num points on workers: [200 200 200   1   2   2  17   4   2   1]
INFO:root:--------------------------
INFO:root:FL Epoch: 241 Training on worker :0
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695915
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688561
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Test Loss: 0.7286842664082845 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Train Loss: 0.6872760891914368 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 241 Norm Difference for worker 0 is 0.079228
INFO:root:FL Epoch: 241 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702156
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691579
INFO:root:FL Epoch: 241 Worker: 1 Backdoor Test Loss: 0.7317434847354889 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 241 Worker: 1 Backdoor Train Loss: 0.6870025753974914 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 241 Norm Difference for worker 1 is 0.082008
INFO:root:FL Epoch: 241 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :2
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687150
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690559
INFO:root:FL Epoch: 241 Worker: 2 Backdoor Test Loss: 0.7344017426172892 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 241 Worker: 2 Backdoor Train Loss: 0.6867911159992218 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 241 Norm Difference for worker 2 is 0.084775
INFO:root:FL Epoch: 241 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :77
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 241 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 241 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :63
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 241 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 241 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :36
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 241 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 241 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :74
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 241 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 241 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :76
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 241 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 241 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :75
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 241 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 241 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :48
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 241 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 241 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 77
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 241 Ends   ===================
INFO:root:Epoch:241 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:241 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 242 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 242 Workers Selected : [74, 31, 7, 32, 33, 46, 9, 36, 3, 4]
INFO:root:FL Epoch: 242 Fraction of points on each worker in this round: [0.21518987 0.01265823 0.01265823 0.05063291 0.37974684 0.01265823
 0.26582278 0.02531646 0.01265823 0.01265823]
INFO:root:FL Epoch: 242 Num points on workers: [17  1  1  4 30  1 21  2  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 242 Training on worker :74
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 242 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 242 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :31
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 242 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :7
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 242 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :32
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 242 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 242 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :33
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.684981
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.673842
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 242 Norm Difference for worker 33 is 0.06168
INFO:root:FL Epoch: 242 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :46
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 242 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :9
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.678135
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.668047
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 9 is 0.060583
INFO:root:FL Epoch: 242 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :36
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 242 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 242 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :3
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 242 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :4
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 242 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 74
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 242 Ends   ===================
INFO:root:Epoch:242 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:242 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 243 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 243 Workers Selected : [15, 28, 30, 7, 76, 11, 37, 41, 21, 8]
INFO:root:FL Epoch: 243 Fraction of points on each worker in this round: [0.01351351 0.08108108 0.02702703 0.01351351 0.05405405 0.04054054
 0.01351351 0.05405405 0.68918919 0.01351351]
INFO:root:FL Epoch: 243 Num points on workers: [ 1  6  2  1  4  3  1  4 51  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 243 Training on worker :15
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 243 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 243 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :28
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 243 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 243 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :30
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 243 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 243 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :7
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 243 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 243 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :76
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 243 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 243 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :11
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 243 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 243 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :37
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 243 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 243 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :41
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 243 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 243 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :21
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.698895
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.650496
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 243 Norm Difference for worker 21 is 0.203056
INFO:root:FL Epoch: 243 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :8
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 243 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 243 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 15
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 243 Ends   ===================
INFO:root:Epoch:243 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:243 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 244 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 244 Workers Selected : [60, 26, 43, 79, 73, 99, 41, 52, 3, 97]
INFO:root:FL Epoch: 244 Fraction of points on each worker in this round: [0.11111111 0.03703704 0.03703704 0.07407407 0.03703704 0.11111111
 0.14814815 0.03703704 0.03703704 0.37037037]
INFO:root:FL Epoch: 244 Num points on workers: [ 3  1  1  2  1  3  4  1  1 10]
INFO:root:--------------------------
INFO:root:FL Epoch: 244 Training on worker :60
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 244 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 244 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :26
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 244 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :43
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 244 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :79
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 244 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 244 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :73
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 244 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :99
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 244 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 244 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :41
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 244 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 244 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :52
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 244 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :3
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 244 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :97
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 244 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 244 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 60
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 244 Ends   ===================
INFO:root:Epoch:244 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:244 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 245 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 245 Workers Selected : [24, 15, 45, 59, 71, 7, 29, 9, 49, 79]
INFO:root:FL Epoch: 245 Fraction of points on each worker in this round: [0.08823529 0.02941176 0.05882353 0.02941176 0.02941176 0.02941176
 0.02941176 0.61764706 0.02941176 0.05882353]
INFO:root:FL Epoch: 245 Num points on workers: [ 3  1  2  1  1  1  1 21  1  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 245 Training on worker :24
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 245 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 245 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :15
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 245 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :45
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 245 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 245 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :59
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 245 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :71
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 245 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :7
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 245 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :29
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 245 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :9
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.681469
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.668873
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 9 is 0.060354
INFO:root:FL Epoch: 245 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :49
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 245 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :79
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 245 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 245 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 24
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 245 Ends   ===================
INFO:root:Epoch:245 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:245 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 246 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 246 Workers Selected : [11, 6, 88, 70, 91, 79, 61, 55, 27, 98]
INFO:root:FL Epoch: 246 Fraction of points on each worker in this round: [0.14285714 0.04761905 0.04761905 0.0952381  0.19047619 0.0952381
 0.04761905 0.04761905 0.23809524 0.04761905]
INFO:root:FL Epoch: 246 Num points on workers: [3 1 1 2 4 2 1 1 5 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 246 Training on worker :11
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 246 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 246 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :6
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 246 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 246 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :88
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 246 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 246 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :70
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 246 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 246 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :91
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 246 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 246 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :79
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 246 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 246 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :61
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 246 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 246 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :55
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 246 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 246 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :27
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 246 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 246 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :98
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 246 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 246 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 11
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 246 Ends   ===================
INFO:root:Epoch:246 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:246 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 247 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 247 Workers Selected : [69, 35, 58, 99, 52, 20, 96, 81, 54, 31]
INFO:root:FL Epoch: 247 Fraction of points on each worker in this round: [0.36170213 0.0212766  0.38297872 0.06382979 0.0212766  0.0212766
 0.0212766  0.06382979 0.0212766  0.0212766 ]
INFO:root:FL Epoch: 247 Num points on workers: [17  1 18  3  1  1  1  3  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 247 Training on worker :69
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 247 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 247 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :35
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 247 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 247 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :58
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 247 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 247 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :99
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 247 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 247 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :52
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 247 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 247 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :20
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 247 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 247 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :96
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 247 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 247 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :81
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 247 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 247 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :54
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 247 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 247 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :31
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 247 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 247 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 69
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 247 Ends   ===================
INFO:root:Epoch:247 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:247 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 248 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 248 Workers Selected : [44, 48, 4, 63, 90, 53, 68, 84, 3, 62]
INFO:root:FL Epoch: 248 Fraction of points on each worker in this round: [0.06666667 0.03333333 0.03333333 0.06666667 0.06666667 0.13333333
 0.06666667 0.4        0.03333333 0.1       ]
INFO:root:FL Epoch: 248 Num points on workers: [ 2  1  1  2  2  4  2 12  1  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 248 Training on worker :44
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 248 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 248 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :48
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 248 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 248 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :4
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 248 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 248 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :63
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 248 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 248 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :90
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 248 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 248 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :53
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 248 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 248 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :68
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 248 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 248 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :84
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 248 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 248 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :3
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 248 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 248 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :62
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 248 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 248 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 44
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 248 Ends   ===================
INFO:root:Epoch:248 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:248 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 249 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 249 Workers Selected : [8, 43, 24, 3, 23, 60, 72, 99, 71, 17]
INFO:root:FL Epoch: 249 Fraction of points on each worker in this round: [0.03571429 0.03571429 0.10714286 0.03571429 0.25       0.10714286
 0.21428571 0.10714286 0.03571429 0.07142857]
INFO:root:FL Epoch: 249 Num points on workers: [1 1 3 1 7 3 6 3 1 2]
INFO:root:--------------------------
INFO:root:FL Epoch: 249 Training on worker :8
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 249 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :43
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 249 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :24
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 249 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 249 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :3
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 249 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :23
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 249 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 249 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :60
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 249 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 249 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :72
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 249 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 249 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :99
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 249 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 249 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :71
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 249 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :17
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 249 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 249 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 8
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 249 Ends   ===================
INFO:root:Epoch:249 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:249 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 250 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 250 Workers Selected : [7, 44, 85, 58, 54, 59, 92, 11, 45, 70]
INFO:root:FL Epoch: 250 Fraction of points on each worker in this round: [0.02777778 0.05555556 0.05555556 0.5        0.02777778 0.02777778
 0.11111111 0.08333333 0.05555556 0.05555556]
INFO:root:FL Epoch: 250 Num points on workers: [ 1  2  2 18  1  1  4  3  2  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 250 Training on worker :7
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 250 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :44
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 250 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 250 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :85
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 250 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 250 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :58
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 250 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 250 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :54
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 250 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :59
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 250 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :92
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 250 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 250 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :11
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 250 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 250 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :45
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 250 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 250 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :70
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 250 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 250 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 7
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 250 Ends   ===================
INFO:root:Epoch:250 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:250 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 251 Begins ===================
INFO:root:FL Epoch: 251 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 251 Workers Selected : [0, 1, 2, 63, 75, 43, 66, 27, 68, 55]
INFO:root:FL Epoch: 251 Fraction of points on each worker in this round: [0.3257329  0.3257329  0.3257329  0.00325733 0.00325733 0.00162866
 0.00162866 0.00814332 0.00325733 0.00162866]
INFO:root:FL Epoch: 251 Num points on workers: [200 200 200   2   2   1   1   5   2   1]
INFO:root:--------------------------
INFO:root:FL Epoch: 251 Training on worker :0
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697884
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690840
INFO:root:FL Epoch: 251 Worker: 0 Backdoor Test Loss: 0.728534609079361 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 251 Worker: 0 Backdoor Train Loss: 0.6874695003032685 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 251 Norm Difference for worker 0 is 0.076701
INFO:root:FL Epoch: 251 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696130
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698100
INFO:root:FL Epoch: 251 Worker: 1 Backdoor Test Loss: 0.7282133201758066 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 251 Worker: 1 Backdoor Train Loss: 0.6873232066631317 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 251 Norm Difference for worker 1 is 0.078159
INFO:root:FL Epoch: 251 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :2
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698023
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687901
INFO:root:FL Epoch: 251 Worker: 2 Backdoor Test Loss: 0.734054168065389 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 251 Worker: 2 Backdoor Train Loss: 0.6868912875652313 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 251 Norm Difference for worker 2 is 0.083335
INFO:root:FL Epoch: 251 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :63
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 251 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 251 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :75
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 251 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 251 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :43
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 251 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 251 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :66
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 251 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 251 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :27
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 251 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 251 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :68
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 251 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 251 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :55
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 251 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 251 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 63
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 251 Ends   ===================
INFO:root:Epoch:251 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:251 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 252 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 252 Workers Selected : [28, 55, 23, 91, 38, 66, 21, 37, 78, 47]
INFO:root:FL Epoch: 252 Fraction of points on each worker in this round: [0.07894737 0.01315789 0.09210526 0.05263158 0.01315789 0.01315789
 0.67105263 0.01315789 0.01315789 0.03947368]
INFO:root:FL Epoch: 252 Num points on workers: [ 6  1  7  4  1  1 51  1  1  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 252 Training on worker :28
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 252 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 252 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :55
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 252 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 252 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :23
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 252 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 252 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :91
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 252 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 252 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :38
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 252 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 252 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :66
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 252 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 252 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :21
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.699520
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.641684
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 252 Norm Difference for worker 21 is 0.201076
INFO:root:FL Epoch: 252 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :37
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 252 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 252 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :78
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 252 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 252 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :47
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 252 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 252 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 28
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 252 Ends   ===================
INFO:root:Epoch:252 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:252 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 253 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 253 Workers Selected : [30, 26, 47, 74, 70, 92, 22, 88, 90, 17]
INFO:root:FL Epoch: 253 Fraction of points on each worker in this round: [0.05714286 0.02857143 0.08571429 0.48571429 0.05714286 0.11428571
 0.02857143 0.02857143 0.05714286 0.05714286]
INFO:root:FL Epoch: 253 Num points on workers: [ 2  1  3 17  2  4  1  1  2  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 253 Training on worker :30
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 253 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 253 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :26
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 253 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :47
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 253 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 253 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :74
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 253 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 253 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :70
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 253 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 253 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :92
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 253 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 253 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :22
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 253 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :88
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 253 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :90
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 253 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 253 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :17
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 253 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 253 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 30
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 253 Ends   ===================
INFO:root:Epoch:253 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:253 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 254 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 254 Workers Selected : [67, 74, 23, 69, 66, 45, 54, 24, 27, 15]
INFO:root:FL Epoch: 254 Fraction of points on each worker in this round: [0.18181818 0.25757576 0.10606061 0.25757576 0.01515152 0.03030303
 0.01515152 0.04545455 0.07575758 0.01515152]
INFO:root:FL Epoch: 254 Num points on workers: [12 17  7 17  1  2  1  3  5  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 254 Training on worker :67
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 254 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 254 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :74
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 254 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 254 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :23
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 254 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 254 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :69
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 254 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 254 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :66
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 254 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 254 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :45
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 254 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 254 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :54
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 254 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 254 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :24
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 254 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 254 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :27
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 254 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 254 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :15
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 254 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 254 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 67
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 254 Ends   ===================
INFO:root:Epoch:254 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:254 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 255 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 255 Workers Selected : [95, 30, 23, 27, 94, 46, 69, 8, 64, 80]
INFO:root:FL Epoch: 255 Fraction of points on each worker in this round: [0.01282051 0.02564103 0.08974359 0.06410256 0.51282051 0.01282051
 0.21794872 0.01282051 0.03846154 0.01282051]
INFO:root:FL Epoch: 255 Num points on workers: [ 1  2  7  5 40  1 17  1  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 255 Training on worker :95
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 255 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 255 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :30
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 255 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 255 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :23
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 255 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 255 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :27
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 255 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 255 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :94
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.698300
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.647759
INFO:root:FL Epoch: 255 Norm Difference for worker 94 is 0.186209
INFO:root:FL Epoch: 255 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :46
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 255 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 255 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :69
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 255 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 255 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :8
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 255 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 255 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :64
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 255 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 255 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :80
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 255 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 255 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 95
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 255 Ends   ===================
INFO:root:Epoch:255 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:255 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 256 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 256 Workers Selected : [31, 25, 66, 29, 98, 79, 60, 82, 63, 84]
INFO:root:FL Epoch: 256 Fraction of points on each worker in this round: [0.02083333 0.5        0.02083333 0.02083333 0.02083333 0.04166667
 0.0625     0.02083333 0.04166667 0.25      ]
INFO:root:FL Epoch: 256 Num points on workers: [ 1 24  1  1  1  2  3  1  2 12]
INFO:root:--------------------------
INFO:root:FL Epoch: 256 Training on worker :31
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 256 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :25
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.693032
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.673252
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 256 Norm Difference for worker 25 is 0.063189
INFO:root:FL Epoch: 256 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :66
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 256 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :29
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 256 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :98
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 256 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :79
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 256 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 256 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :60
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 256 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 256 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :82
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 256 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :63
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 256 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 256 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :84
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 256 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 256 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 31
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 256 Ends   ===================
INFO:root:Epoch:256 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:256 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 257 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 257 Workers Selected : [51, 5, 55, 17, 98, 26, 48, 10, 36, 52]
INFO:root:FL Epoch: 257 Fraction of points on each worker in this round: [0.17391304 0.39130435 0.04347826 0.08695652 0.04347826 0.04347826
 0.04347826 0.04347826 0.08695652 0.04347826]
INFO:root:FL Epoch: 257 Num points on workers: [4 9 1 2 1 1 1 1 2 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 257 Training on worker :51
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 257 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 257 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :5
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 257 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 257 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :55
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 257 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :17
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 257 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 257 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :98
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 257 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :26
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 257 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :48
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 257 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :10
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 257 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :36
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 257 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 257 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :52
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 257 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 51
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 257 Ends   ===================
INFO:root:Epoch:257 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:257 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 258 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 258 Workers Selected : [50, 21, 89, 87, 49, 58, 39, 96, 43, 97]
INFO:root:FL Epoch: 258 Fraction of points on each worker in this round: [0.00980392 0.5        0.00980392 0.04901961 0.00980392 0.17647059
 0.12745098 0.00980392 0.00980392 0.09803922]
INFO:root:FL Epoch: 258 Num points on workers: [ 1 51  1  5  1 18 13  1  1 10]
INFO:root:--------------------------
INFO:root:FL Epoch: 258 Training on worker :50
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 258 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 258 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :21
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.700167
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.649883
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 258 Norm Difference for worker 21 is 0.199901
INFO:root:FL Epoch: 258 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :89
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 258 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 258 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :87
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 258 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 258 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :49
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 258 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 258 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :58
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 258 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 258 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :39
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 258 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 258 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :96
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 258 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 258 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :43
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 258 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 258 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :97
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 258 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 258 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 50
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 258 Ends   ===================
INFO:root:Epoch:258 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:258 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 259 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 259 Workers Selected : [65, 4, 74, 37, 13, 43, 63, 92, 86, 27]
INFO:root:FL Epoch: 259 Fraction of points on each worker in this round: [0.02439024 0.02439024 0.41463415 0.02439024 0.09756098 0.02439024
 0.04878049 0.09756098 0.12195122 0.12195122]
INFO:root:FL Epoch: 259 Num points on workers: [ 1  1 17  1  4  1  2  4  5  5]
INFO:root:--------------------------
INFO:root:FL Epoch: 259 Training on worker :65
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 259 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :4
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 259 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :74
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 259 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 259 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :37
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 259 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :13
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 259 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 259 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :43
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 259 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :63
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 259 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 259 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :92
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 259 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 259 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :86
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 259 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 259 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :27
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 259 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 259 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 65
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 259 Ends   ===================
INFO:root:Epoch:259 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:259 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 260 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 260 Workers Selected : [65, 89, 30, 26, 17, 96, 22, 52, 84, 39]
INFO:root:FL Epoch: 260 Fraction of points on each worker in this round: [0.02857143 0.02857143 0.05714286 0.02857143 0.05714286 0.02857143
 0.02857143 0.02857143 0.34285714 0.37142857]
INFO:root:FL Epoch: 260 Num points on workers: [ 1  1  2  1  2  1  1  1 12 13]
INFO:root:--------------------------
INFO:root:FL Epoch: 260 Training on worker :65
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 260 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 260 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :89
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 260 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 260 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :30
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 260 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 260 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :26
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 260 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 260 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :17
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 260 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 260 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :96
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 260 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 260 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :22
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 260 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 260 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :52
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 260 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 260 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :84
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 260 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 260 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :39
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 260 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 260 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 65
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 260 Ends   ===================
INFO:root:Epoch:260 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:260 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 261 Begins ===================
INFO:root:FL Epoch: 261 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 261 Workers Selected : [0, 1, 2, 60, 28, 6, 57, 38, 48, 51]
INFO:root:FL Epoch: 261 Fraction of points on each worker in this round: [0.31796502 0.31796502 0.31796502 0.00476948 0.00953895 0.00158983
 0.02066773 0.00158983 0.00158983 0.0063593 ]
INFO:root:FL Epoch: 261 Num points on workers: [200 200 200   3   6   1  13   1   1   4]
INFO:root:--------------------------
INFO:root:FL Epoch: 261 Training on worker :0
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698865
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690169
INFO:root:FL Epoch: 261 Worker: 0 Backdoor Test Loss: 0.7252081334590912 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 261 Worker: 0 Backdoor Train Loss: 0.6877967715263367 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 261 Norm Difference for worker 0 is 0.073395
INFO:root:FL Epoch: 261 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698022
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680287
INFO:root:FL Epoch: 261 Worker: 1 Backdoor Test Loss: 0.7262570957342783 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 261 Worker: 1 Backdoor Train Loss: 0.6876059949398041 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 261 Norm Difference for worker 1 is 0.074717
INFO:root:FL Epoch: 261 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :2
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690348
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696313
INFO:root:FL Epoch: 261 Worker: 2 Backdoor Test Loss: 0.7302070756753286 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 261 Worker: 2 Backdoor Train Loss: 0.6872755348682403 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 261 Norm Difference for worker 2 is 0.078186
INFO:root:FL Epoch: 261 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :60
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 261 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 261 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :28
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 261 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 261 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :6
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 261 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 261 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :57
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 261 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 261 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :38
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 261 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 261 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :48
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 261 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 261 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :51
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 261 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 261 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 60
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 261 Ends   ===================
INFO:root:Epoch:261 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:261 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 262 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 262 Workers Selected : [10, 16, 24, 62, 53, 77, 93, 81, 33, 45]
INFO:root:FL Epoch: 262 Fraction of points on each worker in this round: [0.01960784 0.03921569 0.05882353 0.05882353 0.07843137 0.01960784
 0.03921569 0.05882353 0.58823529 0.03921569]
INFO:root:FL Epoch: 262 Num points on workers: [ 1  2  3  3  4  1  2  3 30  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 262 Training on worker :10
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 262 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :16
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 262 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 262 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :24
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 262 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 262 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :62
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 262 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 262 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :53
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 262 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 262 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :77
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 262 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :93
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 262 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 262 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :81
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 262 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 262 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :33
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.688184
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.673640
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 262 Norm Difference for worker 33 is 0.060135
INFO:root:FL Epoch: 262 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :45
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 262 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 262 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 10
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 262 Ends   ===================
INFO:root:Epoch:262 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:262 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 263 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 263 Workers Selected : [91, 73, 59, 11, 58, 40, 36, 37, 30, 78]
INFO:root:FL Epoch: 263 Fraction of points on each worker in this round: [0.11764706 0.02941176 0.02941176 0.08823529 0.52941176 0.02941176
 0.05882353 0.02941176 0.05882353 0.02941176]
INFO:root:FL Epoch: 263 Num points on workers: [ 4  1  1  3 18  1  2  1  2  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 263 Training on worker :91
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 263 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 263 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :73
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 263 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :59
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 263 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :11
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 263 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 263 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :58
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 263 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 263 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :40
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 263 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :36
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 263 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 263 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :37
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 263 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :30
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 263 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 263 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :78
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 263 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 91
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 263 Ends   ===================
INFO:root:Epoch:263 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:263 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 264 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 264 Workers Selected : [19, 78, 40, 18, 13, 98, 14, 70, 72, 74]
INFO:root:FL Epoch: 264 Fraction of points on each worker in this round: [0.02325581 0.02325581 0.02325581 0.09302326 0.09302326 0.02325581
 0.13953488 0.04651163 0.13953488 0.39534884]
INFO:root:FL Epoch: 264 Num points on workers: [ 1  1  1  4  4  1  6  2  6 17]
INFO:root:--------------------------
INFO:root:FL Epoch: 264 Training on worker :19
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 264 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :78
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 264 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :40
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 264 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :18
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 264 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 264 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :13
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 264 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 264 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :98
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 264 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :14
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 264 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 264 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :70
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 264 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 264 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :72
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 264 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 264 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :74
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 264 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 264 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 19
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 264 Ends   ===================
INFO:root:Epoch:264 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:264 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 265 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 265 Workers Selected : [77, 45, 30, 81, 4, 12, 86, 59, 78, 27]
INFO:root:FL Epoch: 265 Fraction of points on each worker in this round: [0.04545455 0.09090909 0.09090909 0.13636364 0.04545455 0.04545455
 0.22727273 0.04545455 0.04545455 0.22727273]
INFO:root:FL Epoch: 265 Num points on workers: [1 2 2 3 1 1 5 1 1 5]
INFO:root:--------------------------
INFO:root:FL Epoch: 265 Training on worker :77
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 265 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :45
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 265 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 265 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :30
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 265 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 265 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :81
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 265 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 265 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :4
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 265 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :12
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 265 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :86
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 265 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 265 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :59
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 265 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :78
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 265 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :27
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 265 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 265 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 77
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 265 Ends   ===================
INFO:root:Epoch:265 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:265 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 266 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 266 Workers Selected : [47, 82, 99, 42, 81, 89, 18, 62, 40, 61]
INFO:root:FL Epoch: 266 Fraction of points on each worker in this round: [0.13043478 0.04347826 0.13043478 0.13043478 0.13043478 0.04347826
 0.17391304 0.13043478 0.04347826 0.04347826]
INFO:root:FL Epoch: 266 Num points on workers: [3 1 3 3 3 1 4 3 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 266 Training on worker :47
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 266 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 266 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :82
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 266 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :99
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 266 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 266 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :42
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 266 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 266 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :81
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 266 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 266 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :89
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 266 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :18
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 266 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 266 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :62
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 266 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 266 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :40
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 266 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :61
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 266 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 47
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 266 Ends   ===================
INFO:root:Epoch:266 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:266 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 267 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 267 Workers Selected : [38, 16, 20, 72, 15, 58, 60, 92, 11, 94]
INFO:root:FL Epoch: 267 Fraction of points on each worker in this round: [0.01265823 0.02531646 0.01265823 0.07594937 0.01265823 0.2278481
 0.03797468 0.05063291 0.03797468 0.50632911]
INFO:root:FL Epoch: 267 Num points on workers: [ 1  2  1  6  1 18  3  4  3 40]
INFO:root:--------------------------
INFO:root:FL Epoch: 267 Training on worker :38
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 267 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 267 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :16
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 267 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 267 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :20
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 267 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 267 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :72
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 267 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 267 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :15
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 267 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 267 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :58
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 267 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 267 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :60
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 267 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 267 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :92
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 267 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 267 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :11
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 267 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 267 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :94
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.693405
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.651320
INFO:root:FL Epoch: 267 Norm Difference for worker 94 is 0.181414
INFO:root:FL Epoch: 267 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 38
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 267 Ends   ===================
INFO:root:Epoch:267 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:267 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 268 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 268 Workers Selected : [80, 52, 50, 7, 26, 78, 70, 37, 76, 31]
INFO:root:FL Epoch: 268 Fraction of points on each worker in this round: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.14285714 0.07142857 0.28571429 0.07142857]
INFO:root:FL Epoch: 268 Num points on workers: [1 1 1 1 1 1 2 1 4 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 268 Training on worker :80
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 268 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :52
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 268 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :50
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 268 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :7
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 268 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :26
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 268 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :78
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 268 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :70
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 268 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 268 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :37
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 268 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :76
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 268 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 268 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :31
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 268 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 80
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 268 Ends   ===================
INFO:root:Epoch:268 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:268 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 269 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 269 Workers Selected : [16, 29, 76, 83, 33, 41, 56, 92, 24, 93]
INFO:root:FL Epoch: 269 Fraction of points on each worker in this round: [0.03636364 0.01818182 0.07272727 0.03636364 0.54545455 0.07272727
 0.05454545 0.07272727 0.05454545 0.03636364]
INFO:root:FL Epoch: 269 Num points on workers: [ 2  1  4  2 30  4  3  4  3  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 269 Training on worker :16
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 269 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 269 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :29
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 269 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :76
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 269 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 269 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :83
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 269 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 269 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :33
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.682700
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.674797
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 269 Norm Difference for worker 33 is 0.059094
INFO:root:FL Epoch: 269 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :41
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 269 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 269 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :56
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 269 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 269 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :92
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 269 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 269 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :24
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 269 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 269 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :93
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 269 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 269 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 16
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 269 Ends   ===================
INFO:root:Epoch:269 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:269 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 270 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 270 Workers Selected : [83, 36, 97, 67, 13, 75, 77, 81, 85, 41]
INFO:root:FL Epoch: 270 Fraction of points on each worker in this round: [0.04761905 0.04761905 0.23809524 0.28571429 0.0952381  0.04761905
 0.02380952 0.07142857 0.04761905 0.0952381 ]
INFO:root:FL Epoch: 270 Num points on workers: [ 2  2 10 12  4  2  1  3  2  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 270 Training on worker :83
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 270 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 270 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :36
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 270 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 270 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :97
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 270 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 270 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :67
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 270 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 270 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :13
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 270 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 270 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :75
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 270 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 270 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :77
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 270 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 270 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :81
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 270 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 270 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :85
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 270 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 270 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :41
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 270 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 270 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 83
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 270 Ends   ===================
INFO:root:Epoch:270 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:270 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 271 Begins ===================
INFO:root:FL Epoch: 271 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 271 Workers Selected : [0, 1, 2, 68, 22, 44, 11, 82, 76, 73]
INFO:root:FL Epoch: 271 Fraction of points on each worker in this round: [0.3257329  0.3257329  0.3257329  0.00325733 0.00162866 0.00325733
 0.00488599 0.00162866 0.00651466 0.00162866]
INFO:root:FL Epoch: 271 Num points on workers: [200 200 200   2   1   2   3   1   4   1]
INFO:root:--------------------------
INFO:root:FL Epoch: 271 Training on worker :0
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696783
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701481
INFO:root:FL Epoch: 271 Worker: 0 Backdoor Test Loss: 0.7273427645365397 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 271 Worker: 0 Backdoor Train Loss: 0.6875805139541626 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 271 Norm Difference for worker 0 is 0.075285
INFO:root:FL Epoch: 271 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698135
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689333
INFO:root:FL Epoch: 271 Worker: 1 Backdoor Test Loss: 0.7301478981971741 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 271 Worker: 1 Backdoor Train Loss: 0.6874460935592651 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 271 Norm Difference for worker 1 is 0.076952
INFO:root:FL Epoch: 271 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :2
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695996
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684658
INFO:root:FL Epoch: 271 Worker: 2 Backdoor Test Loss: 0.7346376876036326 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 271 Worker: 2 Backdoor Train Loss: 0.6870029926300049 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 271 Norm Difference for worker 2 is 0.082311
INFO:root:FL Epoch: 271 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :68
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 271 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 271 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :22
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 271 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :44
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 271 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 271 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :11
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 271 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 271 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :82
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 271 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :76
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 271 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 271 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :73
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 271 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 68
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 271 Ends   ===================
INFO:root:Epoch:271 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:271 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 272 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 272 Workers Selected : [46, 99, 35, 72, 94, 18, 11, 82, 59, 62]
INFO:root:FL Epoch: 272 Fraction of points on each worker in this round: [0.01587302 0.04761905 0.01587302 0.0952381  0.63492063 0.06349206
 0.04761905 0.01587302 0.01587302 0.04761905]
INFO:root:FL Epoch: 272 Num points on workers: [ 1  3  1  6 40  4  3  1  1  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 272 Training on worker :46
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 272 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :99
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 272 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 272 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :35
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 272 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :72
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 272 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 272 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :94
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.689808
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.655031
INFO:root:FL Epoch: 272 Norm Difference for worker 94 is 0.181189
INFO:root:FL Epoch: 272 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :18
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 272 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 272 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :11
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 272 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 272 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :82
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 272 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :59
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 272 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :62
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 272 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 272 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 46
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 272 Ends   ===================
INFO:root:Epoch:272 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:272 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 273 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 273 Workers Selected : [71, 99, 54, 83, 97, 16, 47, 80, 25, 44]
INFO:root:FL Epoch: 273 Fraction of points on each worker in this round: [0.02040816 0.06122449 0.02040816 0.04081633 0.20408163 0.04081633
 0.06122449 0.02040816 0.48979592 0.04081633]
INFO:root:FL Epoch: 273 Num points on workers: [ 1  3  1  2 10  2  3  1 24  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 273 Training on worker :71
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 273 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 273 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :99
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 273 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 273 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :54
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 273 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 273 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :83
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 273 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 273 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :97
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 273 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 273 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :16
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 273 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 273 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :47
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 273 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 273 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :80
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 273 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 273 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :25
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.686677
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.680021
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 273 Norm Difference for worker 25 is 0.059493
INFO:root:FL Epoch: 273 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :44
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 273 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 273 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 71
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 273 Ends   ===================
INFO:root:Epoch:273 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:273 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 274 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 274 Workers Selected : [94, 21, 69, 36, 33, 17, 62, 86, 30, 53]
INFO:root:FL Epoch: 274 Fraction of points on each worker in this round: [0.25641026 0.32692308 0.10897436 0.01282051 0.19230769 0.01282051
 0.01923077 0.03205128 0.01282051 0.02564103]
INFO:root:FL Epoch: 274 Num points on workers: [40 51 17  2 30  2  3  5  2  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 274 Training on worker :94
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.683466
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.651745
INFO:root:FL Epoch: 274 Norm Difference for worker 94 is 0.179603
INFO:root:FL Epoch: 274 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :21
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.692386
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.650292
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 274 Norm Difference for worker 21 is 0.193398
INFO:root:FL Epoch: 274 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :69
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 274 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 274 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :36
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 274 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 274 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :33
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.685582
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.670967
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 274 Norm Difference for worker 33 is 0.058526
INFO:root:FL Epoch: 274 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :17
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 274 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 274 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :62
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 274 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 274 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :86
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 274 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 274 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :30
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 274 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 274 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :53
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 274 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 274 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 69
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 274 Ends   ===================
INFO:root:Epoch:274 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:274 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 275 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 275 Workers Selected : [69, 46, 5, 51, 79, 96, 80, 94, 30, 54]
INFO:root:FL Epoch: 275 Fraction of points on each worker in this round: [0.21794872 0.01282051 0.11538462 0.05128205 0.02564103 0.01282051
 0.01282051 0.51282051 0.02564103 0.01282051]
INFO:root:FL Epoch: 275 Num points on workers: [17  1  9  4  2  1  1 40  2  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 275 Training on worker :69
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 275 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 275 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :46
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 275 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 275 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :5
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 275 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 275 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :51
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 275 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 275 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :79
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 275 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 275 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :96
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 275 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 275 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :80
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 275 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 275 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :94
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.692522
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.651308
INFO:root:FL Epoch: 275 Norm Difference for worker 94 is 0.179863
INFO:root:FL Epoch: 275 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :30
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 275 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 275 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :54
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 275 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 275 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 69
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 275 Ends   ===================
INFO:root:Epoch:275 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:275 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 276 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 276 Workers Selected : [50, 23, 16, 61, 93, 74, 56, 69, 14, 32]
INFO:root:FL Epoch: 276 Fraction of points on each worker in this round: [0.01666667 0.11666667 0.03333333 0.01666667 0.03333333 0.28333333
 0.05       0.28333333 0.1        0.06666667]
INFO:root:FL Epoch: 276 Num points on workers: [ 1  7  2  1  2 17  3 17  6  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 276 Training on worker :50
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 276 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :23
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 276 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 276 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :16
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 276 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 276 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :61
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 276 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :93
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 276 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 276 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :74
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 276 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 276 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :56
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 276 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 276 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :69
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 276 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 276 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :14
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 276 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 276 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :32
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 276 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 276 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 50
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 276 Ends   ===================
INFO:root:Epoch:276 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:276 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 277 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 277 Workers Selected : [22, 48, 35, 38, 78, 86, 17, 45, 8, 21]
INFO:root:FL Epoch: 277 Fraction of points on each worker in this round: [0.01515152 0.01515152 0.01515152 0.01515152 0.01515152 0.07575758
 0.03030303 0.03030303 0.01515152 0.77272727]
INFO:root:FL Epoch: 277 Num points on workers: [ 1  1  1  1  1  5  2  2  1 51]
INFO:root:--------------------------
INFO:root:FL Epoch: 277 Training on worker :22
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 277 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :48
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 277 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :35
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 277 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :38
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 277 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :78
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 277 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :86
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 277 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 277 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :17
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 277 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 277 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :45
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 277 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 277 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :8
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 277 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :21
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.697701
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.652986
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 277 Norm Difference for worker 21 is 0.19586
INFO:root:FL Epoch: 277 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 22
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 277 Ends   ===================
INFO:root:Epoch:277 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:277 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 278 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 278 Workers Selected : [26, 33, 59, 97, 89, 43, 52, 84, 11, 79]
INFO:root:FL Epoch: 278 Fraction of points on each worker in this round: [0.01612903 0.48387097 0.01612903 0.16129032 0.01612903 0.01612903
 0.01612903 0.19354839 0.0483871  0.03225806]
INFO:root:FL Epoch: 278 Num points on workers: [ 1 30  1 10  1  1  1 12  3  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 278 Training on worker :26
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 278 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :33
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.680529
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.665708
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 278 Norm Difference for worker 33 is 0.057132
INFO:root:FL Epoch: 278 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :59
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 278 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :97
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 278 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 278 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :89
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 278 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :43
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 278 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :52
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 278 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :84
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 278 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 278 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :11
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 278 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 278 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :79
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 278 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 278 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 26
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 278 Ends   ===================
INFO:root:Epoch:278 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:278 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 279 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 279 Workers Selected : [66, 59, 90, 15, 72, 86, 54, 23, 18, 7]
INFO:root:FL Epoch: 279 Fraction of points on each worker in this round: [0.03448276 0.03448276 0.06896552 0.03448276 0.20689655 0.17241379
 0.03448276 0.24137931 0.13793103 0.03448276]
INFO:root:FL Epoch: 279 Num points on workers: [1 1 2 1 6 5 1 7 4 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 279 Training on worker :66
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 279 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :59
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 279 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :90
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 279 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 279 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :15
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 279 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :72
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 279 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 279 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :86
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 279 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 279 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :54
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 279 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :23
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 279 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 279 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :18
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 279 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 279 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :7
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 279 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 66
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 279 Ends   ===================
INFO:root:Epoch:279 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:279 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 280 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 280 Workers Selected : [10, 11, 53, 50, 13, 98, 5, 92, 99, 69]
INFO:root:FL Epoch: 280 Fraction of points on each worker in this round: [0.0212766  0.06382979 0.08510638 0.0212766  0.08510638 0.0212766
 0.19148936 0.08510638 0.06382979 0.36170213]
INFO:root:FL Epoch: 280 Num points on workers: [ 1  3  4  1  4  1  9  4  3 17]
INFO:root:--------------------------
INFO:root:FL Epoch: 280 Training on worker :10
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 280 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 280 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :11
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 280 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 280 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :53
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 280 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 280 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :50
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 280 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 280 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :13
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 280 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 280 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :98
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 280 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 280 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :5
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 280 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 280 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :92
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 280 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 280 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :99
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 280 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 280 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :69
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 280 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 280 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 10
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 280 Ends   ===================
INFO:root:Epoch:280 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:280 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 281 Begins ===================
INFO:root:FL Epoch: 281 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 281 Workers Selected : [0, 1, 2, 20, 28, 65, 70, 63, 37, 26]
INFO:root:FL Epoch: 281 Fraction of points on each worker in this round: [0.3257329  0.3257329  0.3257329  0.00162866 0.00977199 0.00162866
 0.00325733 0.00325733 0.00162866 0.00162866]
INFO:root:FL Epoch: 281 Num points on workers: [200 200 200   1   6   1   2   2   1   1]
INFO:root:--------------------------
INFO:root:FL Epoch: 281 Training on worker :0
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695950
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684253
INFO:root:FL Epoch: 281 Worker: 0 Backdoor Test Loss: 0.7289740443229675 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 281 Worker: 0 Backdoor Train Loss: 0.6874912559986115 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 281 Norm Difference for worker 0 is 0.075809
INFO:root:FL Epoch: 281 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698275
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701075
INFO:root:FL Epoch: 281 Worker: 1 Backdoor Test Loss: 0.727286179860433 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 281 Worker: 1 Backdoor Train Loss: 0.6877246975898743 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 281 Norm Difference for worker 1 is 0.073898
INFO:root:FL Epoch: 281 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :2
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699844
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691114
INFO:root:FL Epoch: 281 Worker: 2 Backdoor Test Loss: 0.7258964578310648 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 281 Worker: 2 Backdoor Train Loss: 0.6879218995571137 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 281 Norm Difference for worker 2 is 0.07182
INFO:root:FL Epoch: 281 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :20
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 281 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 281 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :28
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 281 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 281 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :65
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 281 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 281 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :70
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 281 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 281 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :63
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 281 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 281 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :37
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 281 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 281 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :26
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 281 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 281 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 20
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 281 Ends   ===================
INFO:root:Epoch:281 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:281 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 282 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 282 Workers Selected : [22, 18, 88, 38, 21, 66, 85, 54, 91, 86]
INFO:root:FL Epoch: 282 Fraction of points on each worker in this round: [0.01408451 0.05633803 0.01408451 0.01408451 0.71830986 0.01408451
 0.02816901 0.01408451 0.05633803 0.07042254]
INFO:root:FL Epoch: 282 Num points on workers: [ 1  4  1  1 51  1  2  1  4  5]
INFO:root:--------------------------
INFO:root:FL Epoch: 282 Training on worker :22
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 282 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :18
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 282 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 282 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :88
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 282 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :38
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 282 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :21
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.697576
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.650060
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 282 Norm Difference for worker 21 is 0.18851
INFO:root:FL Epoch: 282 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :66
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 282 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :85
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 282 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 282 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :54
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 282 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :91
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 282 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 282 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :86
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 282 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 282 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 22
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 282 Ends   ===================
INFO:root:Epoch:282 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:282 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 283 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 283 Workers Selected : [26, 35, 98, 77, 8, 74, 49, 95, 56, 66]
INFO:root:FL Epoch: 283 Fraction of points on each worker in this round: [0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.60714286
 0.03571429 0.03571429 0.10714286 0.03571429]
INFO:root:FL Epoch: 283 Num points on workers: [ 1  1  1  1  1 17  1  1  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 283 Training on worker :26
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 283 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :35
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 283 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :98
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 283 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :77
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 283 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :8
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 283 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :74
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 283 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 283 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :49
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 283 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :95
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 283 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :56
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 283 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 283 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :66
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 283 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 26
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 283 Ends   ===================
INFO:root:Epoch:283 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:283 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 284 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 284 Workers Selected : [62, 44, 32, 21, 69, 24, 19, 82, 22, 15]
INFO:root:FL Epoch: 284 Fraction of points on each worker in this round: [0.03571429 0.02380952 0.04761905 0.60714286 0.20238095 0.03571429
 0.01190476 0.01190476 0.01190476 0.01190476]
INFO:root:FL Epoch: 284 Num points on workers: [ 3  2  4 51 17  3  1  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 284 Training on worker :62
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 284 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 284 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :44
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 284 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 284 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :32
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 284 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 284 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :21
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.698613
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.645976
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 284 Norm Difference for worker 21 is 0.190594
INFO:root:FL Epoch: 284 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :69
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 284 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 284 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :24
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 284 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 284 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :19
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 284 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 284 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :82
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 284 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 284 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :22
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 284 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 284 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :15
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 284 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 284 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 62
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 284 Ends   ===================
INFO:root:Epoch:284 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:284 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 285 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 285 Workers Selected : [50, 45, 31, 68, 70, 43, 27, 38, 95, 26]
INFO:root:FL Epoch: 285 Fraction of points on each worker in this round: [0.05882353 0.11764706 0.05882353 0.11764706 0.11764706 0.05882353
 0.29411765 0.05882353 0.05882353 0.05882353]
INFO:root:FL Epoch: 285 Num points on workers: [1 2 1 2 2 1 5 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 285 Training on worker :50
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 285 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 285 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :45
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 285 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 285 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :31
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 285 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 285 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :68
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 285 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 285 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :70
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 285 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 285 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :43
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 285 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 285 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :27
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 285 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 285 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :38
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 285 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 285 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :95
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 285 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 285 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :26
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 285 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 285 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 50
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 285 Ends   ===================
INFO:root:Epoch:285 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:285 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 286 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 286 Workers Selected : [62, 20, 75, 24, 27, 56, 25, 29, 16, 41]
INFO:root:FL Epoch: 286 Fraction of points on each worker in this round: [0.0625     0.02083333 0.04166667 0.0625     0.10416667 0.0625
 0.5        0.02083333 0.04166667 0.08333333]
INFO:root:FL Epoch: 286 Num points on workers: [ 3  1  2  3  5  3 24  1  2  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 286 Training on worker :62
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 286 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 286 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :20
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 286 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 286 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :75
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 286 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 286 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :24
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 286 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 286 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :27
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 286 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 286 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :56
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 286 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 286 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :25
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.681085
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.671986
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 286 Norm Difference for worker 25 is 0.059016
INFO:root:FL Epoch: 286 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :29
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 286 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 286 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :16
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 286 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 286 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :41
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 286 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 286 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 62
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 286 Ends   ===================
INFO:root:Epoch:286 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:286 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 287 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 287 Workers Selected : [82, 48, 69, 77, 46, 71, 5, 92, 23, 30]
INFO:root:FL Epoch: 287 Fraction of points on each worker in this round: [0.02272727 0.02272727 0.38636364 0.02272727 0.02272727 0.02272727
 0.20454545 0.09090909 0.15909091 0.04545455]
INFO:root:FL Epoch: 287 Num points on workers: [ 1  1 17  1  1  1  9  4  7  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 287 Training on worker :82
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 287 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :48
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 287 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :69
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 287 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 287 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :77
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 287 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :46
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 287 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :71
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 287 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :5
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 287 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 287 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :92
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 287 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 287 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :23
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 287 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 287 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :30
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 287 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 287 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 82
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 287 Ends   ===================
INFO:root:Epoch:287 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:287 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 288 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 288 Workers Selected : [21, 46, 29, 32, 45, 62, 52, 8, 88, 18]
INFO:root:FL Epoch: 288 Fraction of points on each worker in this round: [0.73913043 0.01449275 0.01449275 0.05797101 0.02898551 0.04347826
 0.01449275 0.01449275 0.01449275 0.05797101]
INFO:root:FL Epoch: 288 Num points on workers: [51  1  1  4  2  3  1  1  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 288 Training on worker :21
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.703180
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.653677
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 288 Norm Difference for worker 21 is 0.188021
INFO:root:FL Epoch: 288 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :46
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 288 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :29
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 288 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :32
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 288 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 288 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :45
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 288 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 288 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :62
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 288 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 288 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :52
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 288 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :8
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 288 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :88
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 288 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :18
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 288 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 288 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 46
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 288 Ends   ===================
INFO:root:Epoch:288 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:288 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 289 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 289 Workers Selected : [38, 49, 78, 12, 66, 28, 95, 23, 59, 24]
INFO:root:FL Epoch: 289 Fraction of points on each worker in this round: [0.04347826 0.04347826 0.04347826 0.04347826 0.04347826 0.26086957
 0.04347826 0.30434783 0.04347826 0.13043478]
INFO:root:FL Epoch: 289 Num points on workers: [1 1 1 1 1 6 1 7 1 3]
INFO:root:--------------------------
INFO:root:FL Epoch: 289 Training on worker :38
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 289 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :49
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 289 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :78
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 289 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :12
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 289 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :66
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 289 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :28
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 289 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 289 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :95
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 289 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :23
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 289 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 289 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :59
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 289 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :24
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 289 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 289 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 38
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 289 Ends   ===================
INFO:root:Epoch:289 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:289 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 290 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 290 Workers Selected : [61, 74, 82, 60, 28, 87, 22, 54, 25, 48]
INFO:root:FL Epoch: 290 Fraction of points on each worker in this round: [0.01666667 0.28333333 0.01666667 0.05       0.1        0.08333333
 0.01666667 0.01666667 0.4        0.01666667]
INFO:root:FL Epoch: 290 Num points on workers: [ 1 17  1  3  6  5  1  1 24  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 290 Training on worker :61
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 290 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 290 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :74
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 290 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 290 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :82
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 290 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 290 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :60
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 290 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 290 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :28
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 290 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 290 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :87
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 290 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 290 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :22
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 290 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 290 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :54
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 290 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 290 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :25
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.689411
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.675464
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 290 Norm Difference for worker 25 is 0.058087
INFO:root:FL Epoch: 290 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :48
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 290 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 290 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 61
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 290 Ends   ===================
INFO:root:Epoch:290 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:290 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 291 Begins ===================
INFO:root:FL Epoch: 291 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 291 Workers Selected : [0, 1, 2, 32, 27, 49, 99, 26, 25, 83]
INFO:root:FL Epoch: 291 Fraction of points on each worker in this round: [0.3125    0.3125    0.3125    0.00625   0.0078125 0.0015625 0.0046875
 0.0015625 0.0375    0.003125 ]
INFO:root:FL Epoch: 291 Num points on workers: [200 200 200   4   5   1   3   1  24   2]
INFO:root:--------------------------
INFO:root:FL Epoch: 291 Training on worker :0
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696171
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688241
INFO:root:FL Epoch: 291 Worker: 0 Backdoor Test Loss: 0.7265996336936951 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 291 Worker: 0 Backdoor Train Loss: 0.6878261685371398 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 291 Norm Difference for worker 0 is 0.072083
INFO:root:FL Epoch: 291 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695659
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691864
INFO:root:FL Epoch: 291 Worker: 1 Backdoor Test Loss: 0.732157826423645 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 291 Worker: 1 Backdoor Train Loss: 0.6874035418033599 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 291 Norm Difference for worker 1 is 0.077846
INFO:root:FL Epoch: 291 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :2
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689237
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697931
INFO:root:FL Epoch: 291 Worker: 2 Backdoor Test Loss: 0.7280290722846985 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 291 Worker: 2 Backdoor Train Loss: 0.6877668261528015 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 291 Norm Difference for worker 2 is 0.073374
INFO:root:FL Epoch: 291 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :32
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 291 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 291 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :27
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 291 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 291 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :49
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 291 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 291 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :99
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 291 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 291 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :26
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 291 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 291 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :25
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.687460
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.673396
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 291 Norm Difference for worker 25 is 0.057441
INFO:root:FL Epoch: 291 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :83
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 291 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 291 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 32
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 291 Ends   ===================
INFO:root:Epoch:291 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:291 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 292 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 292 Workers Selected : [48, 44, 68, 86, 50, 67, 81, 7, 28, 78]
INFO:root:FL Epoch: 292 Fraction of points on each worker in this round: [0.02941176 0.05882353 0.05882353 0.14705882 0.02941176 0.35294118
 0.08823529 0.02941176 0.17647059 0.02941176]
INFO:root:FL Epoch: 292 Num points on workers: [ 1  2  2  5  1 12  3  1  6  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 292 Training on worker :48
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 292 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 292 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :44
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 292 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 292 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :68
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 292 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 292 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :86
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 292 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 292 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :50
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 292 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 292 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :67
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 292 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 292 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :81
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 292 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 292 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :7
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 292 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 292 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :28
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 292 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 292 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :78
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 292 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 292 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 48
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 292 Ends   ===================
INFO:root:Epoch:292 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:292 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 293 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 293 Workers Selected : [37, 90, 95, 29, 65, 44, 96, 19, 46, 26]
INFO:root:FL Epoch: 293 Fraction of points on each worker in this round: [0.08333333 0.16666667 0.08333333 0.08333333 0.08333333 0.16666667
 0.08333333 0.08333333 0.08333333 0.08333333]
INFO:root:FL Epoch: 293 Num points on workers: [1 2 1 1 1 2 1 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 293 Training on worker :37
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 293 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :90
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 293 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 293 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :95
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 293 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :29
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 293 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :65
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 293 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :44
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 293 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 293 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :96
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 293 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :19
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 293 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :46
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 293 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :26
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 293 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 37
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 293 Ends   ===================
INFO:root:Epoch:293 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:293 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 294 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 294 Workers Selected : [8, 61, 66, 36, 6, 73, 69, 72, 64, 19]
INFO:root:FL Epoch: 294 Fraction of points on each worker in this round: [0.02941176 0.02941176 0.02941176 0.05882353 0.02941176 0.02941176
 0.5        0.17647059 0.08823529 0.02941176]
INFO:root:FL Epoch: 294 Num points on workers: [ 1  1  1  2  1  1 17  6  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 294 Training on worker :8
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 294 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :61
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 294 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :66
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 294 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :36
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 294 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 294 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :6
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 294 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :73
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 294 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :69
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 294 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 294 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :72
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 294 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 294 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :64
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 294 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 294 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :19
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 294 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 8
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 294 Ends   ===================
INFO:root:Epoch:294 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:294 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 295 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 295 Workers Selected : [79, 15, 3, 50, 84, 94, 48, 18, 45, 51]
INFO:root:FL Epoch: 295 Fraction of points on each worker in this round: [0.02941176 0.01470588 0.01470588 0.01470588 0.17647059 0.58823529
 0.01470588 0.05882353 0.02941176 0.05882353]
INFO:root:FL Epoch: 295 Num points on workers: [ 2  1  1  1 12 40  1  4  2  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 295 Training on worker :79
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 295 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 295 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :15
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 295 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 295 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :3
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 295 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 295 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :50
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 295 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 295 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :84
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 295 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 295 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :94
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.693109
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.649938
INFO:root:FL Epoch: 295 Norm Difference for worker 94 is 0.172299
INFO:root:FL Epoch: 295 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :48
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 295 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 295 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :18
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 295 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 295 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :45
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 295 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 295 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :51
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 295 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 295 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 79
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 295 Ends   ===================
INFO:root:Epoch:295 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:295 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 296 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 296 Workers Selected : [12, 52, 34, 40, 78, 44, 56, 92, 80, 27]
INFO:root:FL Epoch: 296 Fraction of points on each worker in this round: [0.04545455 0.04545455 0.13636364 0.04545455 0.04545455 0.09090909
 0.13636364 0.18181818 0.04545455 0.22727273]
INFO:root:FL Epoch: 296 Num points on workers: [1 1 3 1 1 2 3 4 1 5]
INFO:root:--------------------------
INFO:root:FL Epoch: 296 Training on worker :12
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 296 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :52
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 296 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :34
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 296 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 296 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :40
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 296 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :78
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 296 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :44
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 296 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 296 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :56
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 296 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 296 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :92
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 296 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 296 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :80
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 296 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :27
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 296 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 296 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 12
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 296 Ends   ===================
INFO:root:Epoch:296 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:296 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 297 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 297 Workers Selected : [90, 62, 15, 4, 39, 96, 46, 9, 43, 76]
INFO:root:FL Epoch: 297 Fraction of points on each worker in this round: [0.04166667 0.0625     0.02083333 0.02083333 0.27083333 0.02083333
 0.02083333 0.4375     0.02083333 0.08333333]
INFO:root:FL Epoch: 297 Num points on workers: [ 2  3  1  1 13  1  1 21  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 297 Training on worker :90
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 297 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 297 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :62
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 297 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 297 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :15
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 297 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 297 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :4
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 297 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 297 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :39
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 297 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 297 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :96
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 297 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 297 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :46
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 297 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 297 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :9
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.684304
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.668751
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 297 Norm Difference for worker 9 is 0.055239
INFO:root:FL Epoch: 297 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :43
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 297 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 297 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :76
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 297 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 297 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 90
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 297 Ends   ===================
INFO:root:Epoch:297 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:297 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 298 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 298 Workers Selected : [46, 23, 50, 43, 67, 71, 80, 41, 44, 32]
INFO:root:FL Epoch: 298 Fraction of points on each worker in this round: [0.02941176 0.20588235 0.02941176 0.02941176 0.35294118 0.02941176
 0.02941176 0.11764706 0.05882353 0.11764706]
INFO:root:FL Epoch: 298 Num points on workers: [ 1  7  1  1 12  1  1  4  2  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 298 Training on worker :46
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 298 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :23
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 298 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 298 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :50
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 298 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :43
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 298 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :67
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 298 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 298 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :71
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 298 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :80
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 298 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :41
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 298 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 298 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :44
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 298 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 298 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :32
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 298 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 298 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 46
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 298 Ends   ===================
INFO:root:Epoch:298 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:298 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 299 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 299 Workers Selected : [42, 37, 92, 60, 79, 96, 6, 55, 47, 12]
INFO:root:FL Epoch: 299 Fraction of points on each worker in this round: [0.15 0.05 0.2  0.15 0.1  0.05 0.05 0.05 0.15 0.05]
INFO:root:FL Epoch: 299 Num points on workers: [3 1 4 3 2 1 1 1 3 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 299 Training on worker :42
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 299 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 299 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :37
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 299 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 299 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :92
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 299 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 299 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :60
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 299 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 299 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :79
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 299 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 299 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :96
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 299 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 299 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :6
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 299 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 299 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :55
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 299 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 299 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :47
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 299 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 299 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :12
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 299 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 299 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 299 Ends   ===================
INFO:root:Epoch:299 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:299 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 300 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 300 Workers Selected : [50, 96, 95, 42, 78, 10, 74, 20, 92, 30]
INFO:root:FL Epoch: 300 Fraction of points on each worker in this round: [0.03125 0.03125 0.03125 0.09375 0.03125 0.03125 0.53125 0.03125 0.125
 0.0625 ]
INFO:root:FL Epoch: 300 Num points on workers: [ 1  1  1  3  1  1 17  1  4  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 300 Training on worker :50
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 300 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 300 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :96
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 300 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 300 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :95
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 300 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 300 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :42
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 300 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 300 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :78
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 300 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 300 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :10
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 300 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 300 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :74
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 300 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 300 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :20
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 300 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 300 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :92
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 300 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 300 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :30
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 300 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 300 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 50
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 300 Saving Checkpoint at this epoch.
INFO:root:FL Epoch: 300 Saved Checkpoint at this epoch.
INFO:root:================FL round 300 Ends   ===================
INFO:root:Epoch:300 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:300 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 301 Begins ===================
INFO:root:FL Epoch: 301 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 301 Workers Selected : [0, 1, 2, 85, 57, 58, 5, 74, 72, 64]
INFO:root:FL Epoch: 301 Fraction of points on each worker in this round: [0.2994012  0.2994012  0.2994012  0.00299401 0.01946108 0.02694611
 0.01347305 0.0254491  0.00898204 0.00449102]
INFO:root:FL Epoch: 301 Num points on workers: [200 200 200   2  13  18   9  17   6   3]
INFO:root:--------------------------
INFO:root:FL Epoch: 301 Training on worker :0
INFO:root:FL Epoch: 301 Using Learning rate : 0.005484820084336939 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689360
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690654
INFO:root:FL Epoch: 301 Worker: 0 Backdoor Test Loss: 0.7280498842398325 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 301 Worker: 0 Backdoor Train Loss: 0.6877616167068481 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 301 Norm Difference for worker 0 is 0.073211
INFO:root:FL Epoch: 301 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1
INFO:root:FL Epoch: 301 Using Learning rate : 0.005484820084336939 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691057
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687703
INFO:root:FL Epoch: 301 Worker: 1 Backdoor Test Loss: 0.7266322374343872 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 301 Worker: 1 Backdoor Train Loss: 0.6878116011619568 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 301 Norm Difference for worker 1 is 0.072632
INFO:root:FL Epoch: 301 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :2
INFO:root:FL Epoch: 301 Using Learning rate : 0.005484820084336939 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689092
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701038
INFO:root:FL Epoch: 301 Worker: 2 Backdoor Test Loss: 0.7268969019254049 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 301 Worker: 2 Backdoor Train Loss: 0.6878890752792358 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 301 Norm Difference for worker 2 is 0.071585
INFO:root:FL Epoch: 301 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :85
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 301 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 301 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :57
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 301 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 301 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :58
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 301 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 301 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :5
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 301 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 301 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :74
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 301 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 301 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :72
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 301 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 301 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :64
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 301 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 301 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 85
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 301 Ends   ===================
INFO:root:Epoch:301 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:301 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 302 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 302 Workers Selected : [78, 19, 39, 14, 23, 95, 13, 26, 3, 35]
INFO:root:FL Epoch: 302 Fraction of points on each worker in this round: [0.02777778 0.02777778 0.36111111 0.16666667 0.19444444 0.02777778
 0.11111111 0.02777778 0.02777778 0.02777778]
INFO:root:FL Epoch: 302 Num points on workers: [ 1  1 13  6  7  1  4  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 302 Training on worker :78
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 302 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :19
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 302 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :39
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 302 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 302 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :14
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 302 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 302 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :23
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 302 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 302 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :95
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 302 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :13
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 302 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 302 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :26
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 302 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :3
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 302 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :35
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 302 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 302 Ends   ===================
INFO:root:Epoch:302 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:302 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 303 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 303 Workers Selected : [12, 85, 16, 21, 70, 90, 75, 63, 92, 32]
INFO:root:FL Epoch: 303 Fraction of points on each worker in this round: [0.01388889 0.02777778 0.02777778 0.70833333 0.02777778 0.02777778
 0.02777778 0.02777778 0.05555556 0.05555556]
INFO:root:FL Epoch: 303 Num points on workers: [ 1  2  2 51  2  2  2  2  4  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 303 Training on worker :12
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 303 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 303 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :85
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 303 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 303 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :16
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 303 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 303 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :21
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.699114
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.656410
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 303 Norm Difference for worker 21 is 0.182883
INFO:root:FL Epoch: 303 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :70
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 303 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 303 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :90
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 303 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 303 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :75
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 303 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 303 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :63
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 303 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 303 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :92
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 303 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 303 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :32
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 303 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 303 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 12
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 303 Ends   ===================
INFO:root:Epoch:303 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:303 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 304 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 304 Workers Selected : [80, 60, 28, 79, 41, 5, 84, 13, 90, 82]
INFO:root:FL Epoch: 304 Fraction of points on each worker in this round: [0.02272727 0.06818182 0.13636364 0.04545455 0.09090909 0.20454545
 0.27272727 0.09090909 0.04545455 0.02272727]
INFO:root:FL Epoch: 304 Num points on workers: [ 1  3  6  2  4  9 12  4  2  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 304 Training on worker :80
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 304 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 304 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :60
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 304 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 304 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :28
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 304 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 304 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :79
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 304 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 304 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :41
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 304 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 304 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :5
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 304 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 304 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :84
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 304 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 304 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :13
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 304 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 304 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :90
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 304 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 304 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :82
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 304 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 304 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 80
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 304 Ends   ===================
INFO:root:Epoch:304 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:304 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 305 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 305 Workers Selected : [74, 21, 92, 39, 29, 59, 30, 41, 68, 63]
INFO:root:FL Epoch: 305 Fraction of points on each worker in this round: [0.17525773 0.5257732  0.04123711 0.13402062 0.01030928 0.01030928
 0.02061856 0.04123711 0.02061856 0.02061856]
INFO:root:FL Epoch: 305 Num points on workers: [17 51  4 13  1  1  2  4  2  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 305 Training on worker :74
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 305 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 305 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :21
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.696780
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.654634
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 305 Norm Difference for worker 21 is 0.182074
INFO:root:FL Epoch: 305 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :92
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 305 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 305 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :39
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 305 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 305 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :29
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 305 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :59
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 305 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :30
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 305 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 305 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :41
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 305 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 305 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :68
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 305 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 305 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :63
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 305 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 305 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 74
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 305 Ends   ===================
INFO:root:Epoch:305 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:305 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 306 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 306 Workers Selected : [24, 46, 70, 84, 90, 74, 28, 33, 96, 22]
INFO:root:FL Epoch: 306 Fraction of points on each worker in this round: [0.04       0.01333333 0.02666667 0.16       0.02666667 0.22666667
 0.08       0.4        0.01333333 0.01333333]
INFO:root:FL Epoch: 306 Num points on workers: [ 3  1  2 12  2 17  6 30  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 306 Training on worker :24
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 306 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 306 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :46
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 306 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 306 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :70
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 306 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 306 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :84
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 306 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 306 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :90
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 306 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 306 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :74
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 306 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 306 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :28
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 306 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 306 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :33
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.691017
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.673499
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 306 Norm Difference for worker 33 is 0.05512
INFO:root:FL Epoch: 306 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :96
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 306 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 306 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :22
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 306 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 306 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 24
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 306 Ends   ===================
INFO:root:Epoch:306 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:306 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 307 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 307 Workers Selected : [14, 72, 3, 30, 16, 21, 5, 83, 61, 20]
INFO:root:FL Epoch: 307 Fraction of points on each worker in this round: [0.07407407 0.07407407 0.01234568 0.02469136 0.02469136 0.62962963
 0.11111111 0.02469136 0.01234568 0.01234568]
INFO:root:FL Epoch: 307 Num points on workers: [ 6  6  1  2  2 51  9  2  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 307 Training on worker :14
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 307 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 307 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :72
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 307 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 307 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :3
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 307 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 307 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :30
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 307 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 307 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :16
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 307 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 307 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :21
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.701555
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.658056
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 307 Norm Difference for worker 21 is 0.181141
INFO:root:FL Epoch: 307 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :5
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 307 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 307 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :83
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 307 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 307 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :61
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 307 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 307 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :20
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 307 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 307 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 14
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 307 Ends   ===================
INFO:root:Epoch:307 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:307 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 308 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 308 Workers Selected : [25, 58, 47, 27, 77, 72, 48, 18, 42, 46]
INFO:root:FL Epoch: 308 Fraction of points on each worker in this round: [0.36363636 0.27272727 0.04545455 0.07575758 0.01515152 0.09090909
 0.01515152 0.06060606 0.04545455 0.01515152]
INFO:root:FL Epoch: 308 Num points on workers: [24 18  3  5  1  6  1  4  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 308 Training on worker :25
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.685051
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.674984
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 308 Norm Difference for worker 25 is 0.056921
INFO:root:FL Epoch: 308 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :58
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 308 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 308 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :47
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 308 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 308 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :27
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 308 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 308 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :77
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 308 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :72
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 308 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 308 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :48
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 308 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :18
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 308 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 308 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :42
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 308 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 308 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :46
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 308 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 58
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 308 Ends   ===================
INFO:root:Epoch:308 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:308 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 309 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 309 Workers Selected : [32, 44, 72, 7, 42, 35, 38, 69, 41, 22]
INFO:root:FL Epoch: 309 Fraction of points on each worker in this round: [0.1   0.05  0.15  0.025 0.075 0.025 0.025 0.425 0.1   0.025]
INFO:root:FL Epoch: 309 Num points on workers: [ 4  2  6  1  3  1  1 17  4  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 309 Training on worker :32
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 309 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 309 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :44
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 309 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 309 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :72
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 309 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 309 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :7
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 309 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 309 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :42
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 309 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 309 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :35
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 309 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 309 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :38
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 309 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 309 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :69
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 309 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 309 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :41
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 309 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 309 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :22
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 309 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 309 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 32
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 309 Ends   ===================
INFO:root:Epoch:309 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:309 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 310 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 310 Workers Selected : [53, 29, 9, 40, 62, 25, 22, 84, 88, 94]
INFO:root:FL Epoch: 310 Fraction of points on each worker in this round: [0.03703704 0.00925926 0.19444444 0.00925926 0.02777778 0.22222222
 0.00925926 0.11111111 0.00925926 0.37037037]
INFO:root:FL Epoch: 310 Num points on workers: [ 4  1 21  1  3 24  1 12  1 40]
INFO:root:--------------------------
INFO:root:FL Epoch: 310 Training on worker :53
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 310 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 310 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :29
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 310 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :9
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.684630
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.675372
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 9 is 0.053115
INFO:root:FL Epoch: 310 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :40
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 310 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :62
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 310 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 310 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :25
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.694253
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.674971
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 310 Norm Difference for worker 25 is 0.056331
INFO:root:FL Epoch: 310 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :22
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 310 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :84
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 310 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 310 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :88
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 310 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :94
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.692985
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.652144
INFO:root:FL Epoch: 310 Norm Difference for worker 94 is 0.166865
INFO:root:FL Epoch: 310 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 53
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 310 Ends   ===================
INFO:root:Epoch:310 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:310 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 311 Begins ===================
INFO:root:FL Epoch: 311 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 311 Workers Selected : [0, 1, 2, 19, 85, 11, 65, 97, 4, 72]
INFO:root:FL Epoch: 311 Fraction of points on each worker in this round: [0.32051282 0.32051282 0.32051282 0.00160256 0.00320513 0.00480769
 0.00160256 0.01602564 0.00160256 0.00961538]
INFO:root:FL Epoch: 311 Num points on workers: [200 200 200   1   2   3   1  10   1   6]
INFO:root:--------------------------
INFO:root:FL Epoch: 311 Training on worker :0
INFO:root:FL Epoch: 311 Using Learning rate : 0.00537610570322294 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700669
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688311
INFO:root:FL Epoch: 311 Worker: 0 Backdoor Test Loss: 0.7253187398115793 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 311 Worker: 0 Backdoor Train Loss: 0.6881604313850402 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 311 Norm Difference for worker 0 is 0.068806
INFO:root:FL Epoch: 311 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1
INFO:root:FL Epoch: 311 Using Learning rate : 0.00537610570322294 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693512
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695292
INFO:root:FL Epoch: 311 Worker: 1 Backdoor Test Loss: 0.7275632520516714 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 311 Worker: 1 Backdoor Train Loss: 0.6878776311874389 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 311 Norm Difference for worker 1 is 0.071952
INFO:root:FL Epoch: 311 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :2
INFO:root:FL Epoch: 311 Using Learning rate : 0.00537610570322294 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695126
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688606
INFO:root:FL Epoch: 311 Worker: 2 Backdoor Test Loss: 0.725405365228653 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 311 Worker: 2 Backdoor Train Loss: 0.6881058275699615 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 311 Norm Difference for worker 2 is 0.069081
INFO:root:FL Epoch: 311 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :19
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 311 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 311 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :85
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 311 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 311 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :11
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 311 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 311 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :65
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 311 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 311 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :97
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 311 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 311 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :4
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 311 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 311 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :72
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 311 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 311 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 19
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 311 Ends   ===================
INFO:root:Epoch:311 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:311 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 312 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 312 Workers Selected : [50, 14, 51, 82, 96, 52, 18, 21, 29, 4]
INFO:root:FL Epoch: 312 Fraction of points on each worker in this round: [0.01408451 0.08450704 0.05633803 0.01408451 0.01408451 0.01408451
 0.05633803 0.71830986 0.01408451 0.01408451]
INFO:root:FL Epoch: 312 Num points on workers: [ 1  6  4  1  1  1  4 51  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 312 Training on worker :50
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 312 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :14
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 312 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 312 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :51
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 312 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 312 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :82
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 312 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :96
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 312 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :52
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 312 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :18
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 312 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 312 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :21
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.700142
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.649934
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 312 Norm Difference for worker 21 is 0.17988
INFO:root:FL Epoch: 312 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :29
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 312 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :4
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 312 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 50
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 312 Ends   ===================
INFO:root:Epoch:312 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:312 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 313 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 313 Workers Selected : [8, 44, 46, 33, 9, 96, 73, 64, 54, 70]
INFO:root:FL Epoch: 313 Fraction of points on each worker in this round: [0.01587302 0.03174603 0.01587302 0.47619048 0.33333333 0.01587302
 0.01587302 0.04761905 0.01587302 0.03174603]
INFO:root:FL Epoch: 313 Num points on workers: [ 1  2  1 30 21  1  1  3  1  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 313 Training on worker :8
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 313 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :44
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 313 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 313 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :46
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 313 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :33
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.685675
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.674857
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 313 Norm Difference for worker 33 is 0.053949
INFO:root:FL Epoch: 313 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :9
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.681881
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.674832
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 9 is 0.052245
INFO:root:FL Epoch: 313 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :96
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 313 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :73
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 313 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :64
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 313 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 313 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :54
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 313 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :70
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 313 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 313 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 8
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 313 Ends   ===================
INFO:root:Epoch:313 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:313 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 314 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 314 Workers Selected : [77, 14, 75, 67, 65, 76, 8, 53, 18, 79]
INFO:root:FL Epoch: 314 Fraction of points on each worker in this round: [0.02702703 0.16216216 0.05405405 0.32432432 0.02702703 0.10810811
 0.02702703 0.10810811 0.10810811 0.05405405]
INFO:root:FL Epoch: 314 Num points on workers: [ 1  6  2 12  1  4  1  4  4  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 314 Training on worker :77
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 314 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 314 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :14
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 314 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 314 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :75
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 314 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 314 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :67
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 314 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 314 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :65
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 314 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 314 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :76
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 314 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 314 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :8
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 314 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 314 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :53
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 314 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 314 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :18
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 314 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 314 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :79
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 314 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 314 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 77
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 314 Ends   ===================
INFO:root:Epoch:314 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:314 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 315 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 315 Workers Selected : [69, 71, 9, 29, 99, 22, 55, 89, 13, 36]
INFO:root:FL Epoch: 315 Fraction of points on each worker in this round: [0.32692308 0.01923077 0.40384615 0.01923077 0.05769231 0.01923077
 0.01923077 0.01923077 0.07692308 0.03846154]
INFO:root:FL Epoch: 315 Num points on workers: [17  1 21  1  3  1  1  1  4  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 315 Training on worker :69
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 315 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 315 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :71
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 315 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 315 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :9
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.681163
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.669935
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 315 Norm Difference for worker 9 is 0.052021
INFO:root:FL Epoch: 315 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :29
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 315 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 315 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :99
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 315 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 315 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :22
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 315 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 315 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :55
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 315 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 315 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :89
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 315 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 315 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :13
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 315 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 315 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :36
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 315 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 315 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 69
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 315 Ends   ===================
INFO:root:Epoch:315 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:315 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 316 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 316 Workers Selected : [85, 44, 82, 72, 36, 29, 96, 66, 80, 93]
INFO:root:FL Epoch: 316 Fraction of points on each worker in this round: [0.10526316 0.10526316 0.05263158 0.31578947 0.10526316 0.05263158
 0.05263158 0.05263158 0.05263158 0.10526316]
INFO:root:FL Epoch: 316 Num points on workers: [2 2 1 6 2 1 1 1 1 2]
INFO:root:--------------------------
INFO:root:FL Epoch: 316 Training on worker :85
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 316 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 316 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :44
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 316 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 316 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :82
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 316 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 316 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :72
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 316 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 316 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :36
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 316 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 316 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :29
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 316 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 316 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :96
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 316 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 316 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :66
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 316 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 316 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :80
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 316 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 316 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :93
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 316 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 316 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 85
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 316 Ends   ===================
INFO:root:Epoch:316 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:316 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 317 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 317 Workers Selected : [47, 72, 29, 16, 77, 83, 93, 26, 76, 32]
INFO:root:FL Epoch: 317 Fraction of points on each worker in this round: [0.11538462 0.23076923 0.03846154 0.07692308 0.03846154 0.07692308
 0.07692308 0.03846154 0.15384615 0.15384615]
INFO:root:FL Epoch: 317 Num points on workers: [3 6 1 2 1 2 2 1 4 4]
INFO:root:--------------------------
INFO:root:FL Epoch: 317 Training on worker :47
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 317 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 317 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :72
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 317 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 317 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :29
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 317 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :16
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 317 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 317 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :77
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 317 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :83
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 317 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 317 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :93
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 317 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 317 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :26
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 317 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :76
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 317 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 317 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :32
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 317 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 317 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 47
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 317 Ends   ===================
INFO:root:Epoch:317 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:317 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 318 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 318 Workers Selected : [59, 74, 96, 53, 6, 60, 47, 72, 94, 10]
INFO:root:FL Epoch: 318 Fraction of points on each worker in this round: [0.01298701 0.22077922 0.01298701 0.05194805 0.01298701 0.03896104
 0.03896104 0.07792208 0.51948052 0.01298701]
INFO:root:FL Epoch: 318 Num points on workers: [ 1 17  1  4  1  3  3  6 40  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 318 Training on worker :59
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 318 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 318 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :74
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 318 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 318 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :96
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 318 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 318 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :53
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 318 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 318 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :6
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 318 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 318 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :60
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 318 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 318 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :47
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 318 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 318 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :72
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 318 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 318 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :94
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.689901
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.659711
INFO:root:FL Epoch: 318 Norm Difference for worker 94 is 0.163161
INFO:root:FL Epoch: 318 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :10
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 318 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 318 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 59
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 318 Ends   ===================
INFO:root:Epoch:318 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:318 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 319 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 319 Workers Selected : [61, 15, 95, 79, 77, 28, 92, 33, 72, 47]
INFO:root:FL Epoch: 319 Fraction of points on each worker in this round: [0.01818182 0.01818182 0.01818182 0.03636364 0.01818182 0.10909091
 0.07272727 0.54545455 0.10909091 0.05454545]
INFO:root:FL Epoch: 319 Num points on workers: [ 1  1  1  2  1  6  4 30  6  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 319 Training on worker :61
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 319 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 319 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :15
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 319 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 319 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :95
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 319 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 319 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :79
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 319 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 319 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :77
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 319 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 319 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :28
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 319 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 319 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :92
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 319 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 319 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :33
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.682229
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.670802
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 319 Norm Difference for worker 33 is 0.05352
INFO:root:FL Epoch: 319 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :72
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 319 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 319 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :47
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 319 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 319 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 61
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 319 Ends   ===================
INFO:root:Epoch:319 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:319 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 320 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 320 Workers Selected : [89, 57, 76, 12, 14, 5, 29, 78, 80, 71]
INFO:root:FL Epoch: 320 Fraction of points on each worker in this round: [0.02631579 0.34210526 0.10526316 0.02631579 0.15789474 0.23684211
 0.02631579 0.02631579 0.02631579 0.02631579]
INFO:root:FL Epoch: 320 Num points on workers: [ 1 13  4  1  6  9  1  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 320 Training on worker :89
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 320 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :57
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 320 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 320 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :76
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 320 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 320 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :12
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 320 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :14
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 320 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 320 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :5
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 320 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 320 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :29
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 320 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :78
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 320 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :80
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 320 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :71
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 320 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 89
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 320 Ends   ===================
INFO:root:Epoch:320 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:320 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 321 Begins ===================
INFO:root:FL Epoch: 321 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 321 Workers Selected : [0, 1, 2, 12, 20, 24, 54, 35, 31, 47]
INFO:root:FL Epoch: 321 Fraction of points on each worker in this round: [0.32733224 0.32733224 0.32733224 0.00163666 0.00163666 0.00490998
 0.00163666 0.00163666 0.00163666 0.00490998]
INFO:root:FL Epoch: 321 Num points on workers: [200 200 200   1   1   3   1   1   1   3]
INFO:root:--------------------------
INFO:root:FL Epoch: 321 Training on worker :0
INFO:root:FL Epoch: 321 Using Learning rate : 0.005269546145144021 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699238
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698069
INFO:root:FL Epoch: 321 Worker: 0 Backdoor Test Loss: 0.727050801118215 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 321 Worker: 0 Backdoor Train Loss: 0.6880634486675262 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 321 Norm Difference for worker 0 is 0.069832
INFO:root:FL Epoch: 321 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1
INFO:root:FL Epoch: 321 Using Learning rate : 0.005269546145144021 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691802
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694257
INFO:root:FL Epoch: 321 Worker: 1 Backdoor Test Loss: 0.7274503608544668 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 321 Worker: 1 Backdoor Train Loss: 0.688068276643753 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 321 Norm Difference for worker 1 is 0.069321
INFO:root:FL Epoch: 321 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :2
INFO:root:FL Epoch: 321 Using Learning rate : 0.005269546145144021 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693631
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693587
INFO:root:FL Epoch: 321 Worker: 2 Backdoor Test Loss: 0.7230743368466696 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 321 Worker: 2 Backdoor Train Loss: 0.6884171724319458 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 321 Norm Difference for worker 2 is 0.065977
INFO:root:FL Epoch: 321 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :12
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 321 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 321 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :20
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 321 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 321 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :24
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 321 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 321 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :54
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 321 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 321 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :35
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 321 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 321 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :31
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 321 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 321 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :47
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 321 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 321 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 12
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 321 Ends   ===================
INFO:root:Epoch:321 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:321 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 322 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 322 Workers Selected : [16, 77, 20, 55, 98, 65, 62, 11, 26, 51]
INFO:root:FL Epoch: 322 Fraction of points on each worker in this round: [0.11111111 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556
 0.16666667 0.16666667 0.05555556 0.22222222]
INFO:root:FL Epoch: 322 Num points on workers: [2 1 1 1 1 1 3 3 1 4]
INFO:root:--------------------------
INFO:root:FL Epoch: 322 Training on worker :16
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 322 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 322 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :77
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 322 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 322 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :20
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 322 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 322 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :55
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 322 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 322 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :98
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 322 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 322 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :65
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 322 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 322 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :62
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 322 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 322 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :11
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 322 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 322 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :26
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 322 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 322 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :51
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 322 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 322 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 16
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 322 Ends   ===================
INFO:root:Epoch:322 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:322 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 323 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 323 Workers Selected : [33, 24, 62, 65, 18, 45, 54, 49, 46, 39]
INFO:root:FL Epoch: 323 Fraction of points on each worker in this round: [0.50847458 0.05084746 0.05084746 0.01694915 0.06779661 0.03389831
 0.01694915 0.01694915 0.01694915 0.22033898]
INFO:root:FL Epoch: 323 Num points on workers: [30  3  3  1  4  2  1  1  1 13]
INFO:root:--------------------------
INFO:root:FL Epoch: 323 Training on worker :33
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.681670
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.671814
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 323 Norm Difference for worker 33 is 0.052638
INFO:root:FL Epoch: 323 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :24
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 323 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 323 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :62
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 323 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 323 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :65
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 323 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :18
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 323 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 323 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :45
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 323 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 323 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :54
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 323 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :49
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 323 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :46
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 323 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :39
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 323 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 323 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 24
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 323 Ends   ===================
INFO:root:Epoch:323 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:323 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 324 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 324 Workers Selected : [67, 78, 14, 4, 6, 76, 42, 96, 75, 85]
INFO:root:FL Epoch: 324 Fraction of points on each worker in this round: [0.36363636 0.03030303 0.18181818 0.03030303 0.03030303 0.12121212
 0.09090909 0.03030303 0.06060606 0.06060606]
INFO:root:FL Epoch: 324 Num points on workers: [12  1  6  1  1  4  3  1  2  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 324 Training on worker :67
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 324 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 324 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :78
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 324 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 324 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :14
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 324 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 324 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :4
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 324 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 324 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :6
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 324 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 324 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :76
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 324 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 324 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :42
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 324 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 324 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :96
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 324 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 324 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :75
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 324 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 324 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :85
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 324 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 324 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 67
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 324 Ends   ===================
INFO:root:Epoch:324 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:324 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 325 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 325 Workers Selected : [69, 94, 27, 58, 33, 29, 42, 6, 98, 12]
INFO:root:FL Epoch: 325 Fraction of points on each worker in this round: [0.14529915 0.34188034 0.04273504 0.15384615 0.25641026 0.00854701
 0.02564103 0.00854701 0.00854701 0.00854701]
INFO:root:FL Epoch: 325 Num points on workers: [17 40  5 18 30  1  3  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 325 Training on worker :69
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 325 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 325 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :94
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.691681
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.651166
INFO:root:FL Epoch: 325 Norm Difference for worker 94 is 0.161912
INFO:root:FL Epoch: 325 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :27
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 325 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 325 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :58
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 325 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 325 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :33
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.686515
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.678252
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 325 Norm Difference for worker 33 is 0.052613
INFO:root:FL Epoch: 325 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :29
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 325 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 325 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :42
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 325 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 325 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :6
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 325 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 325 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :98
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 325 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 325 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :12
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 325 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 325 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 69
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 325 Ends   ===================
INFO:root:Epoch:325 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:325 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 326 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 326 Workers Selected : [6, 10, 68, 29, 46, 4, 95, 55, 31, 71]
INFO:root:FL Epoch: 326 Fraction of points on each worker in this round: [0.09090909 0.09090909 0.18181818 0.09090909 0.09090909 0.09090909
 0.09090909 0.09090909 0.09090909 0.09090909]
INFO:root:FL Epoch: 326 Num points on workers: [1 1 2 1 1 1 1 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 326 Training on worker :6
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 326 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 326 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :10
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 326 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 326 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :68
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 326 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 326 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :29
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 326 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 326 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :46
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 326 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 326 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :4
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 326 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 326 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :95
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 326 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 326 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :55
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 326 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 326 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :31
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 326 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 326 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :71
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 326 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 326 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 6
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 326 Ends   ===================
INFO:root:Epoch:326 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:326 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 327 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 327 Workers Selected : [64, 63, 98, 66, 93, 38, 14, 23, 89, 76]
INFO:root:FL Epoch: 327 Fraction of points on each worker in this round: [0.10714286 0.07142857 0.03571429 0.03571429 0.07142857 0.03571429
 0.21428571 0.25       0.03571429 0.14285714]
INFO:root:FL Epoch: 327 Num points on workers: [3 2 1 1 2 1 6 7 1 4]
INFO:root:--------------------------
INFO:root:FL Epoch: 327 Training on worker :64
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 327 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 327 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :63
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 327 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 327 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :98
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 327 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :66
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 327 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :93
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 327 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 327 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :38
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 327 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :14
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 327 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 327 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :23
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 327 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 327 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :89
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 327 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :76
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 327 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 327 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 64
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 327 Ends   ===================
INFO:root:Epoch:327 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:327 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 328 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 328 Workers Selected : [51, 37, 97, 93, 52, 58, 33, 95, 54, 66]
INFO:root:FL Epoch: 328 Fraction of points on each worker in this round: [0.05797101 0.01449275 0.14492754 0.02898551 0.01449275 0.26086957
 0.43478261 0.01449275 0.01449275 0.01449275]
INFO:root:FL Epoch: 328 Num points on workers: [ 4  1 10  2  1 18 30  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 328 Training on worker :51
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 328 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 328 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :37
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 328 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 328 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :97
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 328 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 328 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :93
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 328 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 328 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :52
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 328 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 328 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :58
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 328 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 328 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :33
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.685862
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.675164
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 328 Norm Difference for worker 33 is 0.053202
INFO:root:FL Epoch: 328 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :95
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 328 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 328 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :54
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 328 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 328 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :66
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 328 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 328 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 51
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 328 Ends   ===================
INFO:root:Epoch:328 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:328 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 329 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 329 Workers Selected : [8, 53, 57, 71, 89, 96, 86, 84, 55, 60]
INFO:root:FL Epoch: 329 Fraction of points on each worker in this round: [0.02380952 0.0952381  0.30952381 0.02380952 0.02380952 0.02380952
 0.11904762 0.28571429 0.02380952 0.07142857]
INFO:root:FL Epoch: 329 Num points on workers: [ 1  4 13  1  1  1  5 12  1  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 329 Training on worker :8
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 329 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 329 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :53
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 329 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 329 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :57
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 329 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 329 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :71
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 329 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 329 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :89
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 329 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 329 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :96
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 329 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 329 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :86
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 329 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 329 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :84
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 329 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 329 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :55
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 329 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 329 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :60
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 329 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 329 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 8
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 329 Ends   ===================
INFO:root:Epoch:329 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:329 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 330 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 330 Workers Selected : [77, 26, 17, 43, 31, 58, 45, 57, 30, 55]
INFO:root:FL Epoch: 330 Fraction of points on each worker in this round: [0.02380952 0.02380952 0.04761905 0.02380952 0.02380952 0.42857143
 0.04761905 0.30952381 0.04761905 0.02380952]
INFO:root:FL Epoch: 330 Num points on workers: [ 1  1  2  1  1 18  2 13  2  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 330 Training on worker :77
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 330 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :26
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 330 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :17
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 330 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 330 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :43
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 330 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :31
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 330 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :58
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 330 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 330 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :45
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 330 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 330 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :57
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 330 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 330 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :30
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 330 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 330 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :55
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 330 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 77
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 330 Ends   ===================
INFO:root:Epoch:330 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:330 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 331 Begins ===================
INFO:root:FL Epoch: 331 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 331 Workers Selected : [0, 1, 2, 23, 96, 86, 54, 27, 88, 53]
INFO:root:FL Epoch: 331 Fraction of points on each worker in this round: [0.32051282 0.32051282 0.32051282 0.01121795 0.00160256 0.00801282
 0.00160256 0.00801282 0.00160256 0.00641026]
INFO:root:FL Epoch: 331 Num points on workers: [200 200 200   7   1   5   1   5   1   4]
INFO:root:--------------------------
INFO:root:FL Epoch: 331 Training on worker :0
INFO:root:FL Epoch: 331 Using Learning rate : 0.005165098699446219 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692491
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687313
INFO:root:FL Epoch: 331 Worker: 0 Backdoor Test Loss: 0.7245790163675944 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 331 Worker: 0 Backdoor Train Loss: 0.6882993757724762 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 331 Norm Difference for worker 0 is 0.066978
INFO:root:FL Epoch: 331 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1
INFO:root:FL Epoch: 331 Using Learning rate : 0.005165098699446219 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699564
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687226
INFO:root:FL Epoch: 331 Worker: 1 Backdoor Test Loss: 0.7254695693651835 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 331 Worker: 1 Backdoor Train Loss: 0.6882955074310303 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 331 Norm Difference for worker 1 is 0.067306
INFO:root:FL Epoch: 331 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :2
INFO:root:FL Epoch: 331 Using Learning rate : 0.005165098699446219 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700771
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684706
INFO:root:FL Epoch: 331 Worker: 2 Backdoor Test Loss: 0.7282739480336508 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 331 Worker: 2 Backdoor Train Loss: 0.6880577504634857 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 331 Norm Difference for worker 2 is 0.069931
INFO:root:FL Epoch: 331 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :23
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 331 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 331 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :96
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 331 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 331 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :86
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 331 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 331 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :54
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 331 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 331 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :27
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 331 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 331 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :88
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 331 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 331 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :53
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 331 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 331 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 23
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 331 Ends   ===================
INFO:root:Epoch:331 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:331 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 332 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 332 Workers Selected : [33, 93, 80, 50, 44, 91, 36, 57, 69, 51]
INFO:root:FL Epoch: 332 Fraction of points on each worker in this round: [0.39473684 0.02631579 0.01315789 0.01315789 0.02631579 0.05263158
 0.02631579 0.17105263 0.22368421 0.05263158]
INFO:root:FL Epoch: 332 Num points on workers: [30  2  1  1  2  4  2 13 17  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 332 Training on worker :33
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.683564
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.675545
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 332 Norm Difference for worker 33 is 0.052024
INFO:root:FL Epoch: 332 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :93
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 332 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 332 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :80
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 332 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 332 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :50
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 332 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 332 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :44
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 332 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 332 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :91
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 332 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 332 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :36
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 332 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 332 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :57
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 332 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 332 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :69
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 332 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 332 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :51
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 332 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 332 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 93
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 332 Ends   ===================
INFO:root:Epoch:332 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:332 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 333 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 333 Workers Selected : [59, 92, 54, 74, 96, 35, 32, 89, 41, 40]
INFO:root:FL Epoch: 333 Fraction of points on each worker in this round: [0.02857143 0.11428571 0.02857143 0.48571429 0.02857143 0.02857143
 0.11428571 0.02857143 0.11428571 0.02857143]
INFO:root:FL Epoch: 333 Num points on workers: [ 1  4  1 17  1  1  4  1  4  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 333 Training on worker :59
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 333 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 333 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :92
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 333 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 333 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :54
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 333 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 333 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :74
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 333 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 333 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :96
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 333 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 333 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :35
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 333 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 333 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :32
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 333 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 333 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :89
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 333 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 333 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :41
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 333 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 333 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :40
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 333 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 333 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 59
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 333 Ends   ===================
INFO:root:Epoch:333 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:333 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 334 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 334 Workers Selected : [16, 38, 43, 57, 77, 62, 90, 25, 87, 7]
INFO:root:FL Epoch: 334 Fraction of points on each worker in this round: [0.03773585 0.01886792 0.01886792 0.24528302 0.01886792 0.05660377
 0.03773585 0.45283019 0.09433962 0.01886792]
INFO:root:FL Epoch: 334 Num points on workers: [ 2  1  1 13  1  3  2 24  5  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 334 Training on worker :16
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 334 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 334 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :38
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 334 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :43
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 334 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :57
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 334 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 334 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :77
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 334 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :62
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 334 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 334 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :90
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 334 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 334 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :25
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.690391
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.674971
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 334 Norm Difference for worker 25 is 0.053548
INFO:root:FL Epoch: 334 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :87
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 334 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 334 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :7
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 334 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 16
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 334 Ends   ===================
INFO:root:Epoch:334 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:334 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 335 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 335 Workers Selected : [75, 9, 41, 51, 25, 69, 91, 99, 72, 63]
INFO:root:FL Epoch: 335 Fraction of points on each worker in this round: [0.02298851 0.24137931 0.04597701 0.04597701 0.27586207 0.1954023
 0.04597701 0.03448276 0.06896552 0.02298851]
INFO:root:FL Epoch: 335 Num points on workers: [ 2 21  4  4 24 17  4  3  6  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 335 Training on worker :75
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 335 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 335 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :9
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.682262
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.669541
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 9 is 0.050263
INFO:root:FL Epoch: 335 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :41
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 335 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 335 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :51
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 335 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 335 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :25
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.687099
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.671450
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 335 Norm Difference for worker 25 is 0.053282
INFO:root:FL Epoch: 335 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :69
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 335 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 335 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :91
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 335 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 335 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :99
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 335 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 335 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :72
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 335 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 335 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :63
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 335 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 335 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 75
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 335 Ends   ===================
INFO:root:Epoch:335 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:335 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 336 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 336 Workers Selected : [24, 3, 44, 39, 52, 27, 72, 94, 40, 90]
INFO:root:FL Epoch: 336 Fraction of points on each worker in this round: [0.04054054 0.01351351 0.02702703 0.17567568 0.01351351 0.06756757
 0.08108108 0.54054054 0.01351351 0.02702703]
INFO:root:FL Epoch: 336 Num points on workers: [ 3  1  2 13  1  5  6 40  1  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 336 Training on worker :24
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 336 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 336 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :3
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 336 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 336 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :44
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 336 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 336 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :39
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 336 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 336 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :52
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 336 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 336 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :27
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 336 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 336 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :72
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 336 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 336 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :94
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.687922
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.662402
INFO:root:FL Epoch: 336 Norm Difference for worker 94 is 0.158271
INFO:root:FL Epoch: 336 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :40
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 336 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 336 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :90
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 336 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 336 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 24
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 336 Ends   ===================
INFO:root:Epoch:336 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:336 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 337 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 337 Workers Selected : [38, 95, 16, 3, 60, 55, 20, 69, 99, 71]
INFO:root:FL Epoch: 337 Fraction of points on each worker in this round: [0.03225806 0.03225806 0.06451613 0.03225806 0.09677419 0.03225806
 0.03225806 0.5483871  0.09677419 0.03225806]
INFO:root:FL Epoch: 337 Num points on workers: [ 1  1  2  1  3  1  1 17  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 337 Training on worker :38
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 337 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :95
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 337 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :16
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 337 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 337 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :3
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 337 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :60
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 337 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 337 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :55
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 337 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :20
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 337 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :69
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 337 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 337 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :99
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 337 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 337 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :71
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 337 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 38
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 337 Ends   ===================
INFO:root:Epoch:337 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:337 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 338 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 338 Workers Selected : [96, 79, 50, 67, 75, 32, 44, 37, 77, 15]
INFO:root:FL Epoch: 338 Fraction of points on each worker in this round: [0.03703704 0.07407407 0.03703704 0.44444444 0.07407407 0.14814815
 0.07407407 0.03703704 0.03703704 0.03703704]
INFO:root:FL Epoch: 338 Num points on workers: [ 1  2  1 12  2  4  2  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 338 Training on worker :96
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 338 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 338 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :79
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 338 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 338 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :50
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 338 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 338 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :67
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 338 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 338 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :75
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 338 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 338 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :32
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 338 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 338 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :44
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 338 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 338 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :37
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 338 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 338 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :77
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 338 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 338 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :15
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 338 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 338 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 96
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 338 Ends   ===================
INFO:root:Epoch:338 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:338 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 339 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 339 Workers Selected : [78, 69, 80, 8, 65, 70, 72, 24, 4, 85]
INFO:root:FL Epoch: 339 Fraction of points on each worker in this round: [0.02857143 0.48571429 0.02857143 0.02857143 0.02857143 0.05714286
 0.17142857 0.08571429 0.02857143 0.05714286]
INFO:root:FL Epoch: 339 Num points on workers: [ 1 17  1  1  1  2  6  3  1  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 339 Training on worker :78
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 339 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :69
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 339 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 339 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :80
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 339 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :8
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 339 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :65
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 339 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :70
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 339 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 339 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :72
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 339 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 339 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :24
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 339 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 339 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :4
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 339 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :85
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 339 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 339 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 339 Ends   ===================
INFO:root:Epoch:339 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:339 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 340 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 340 Workers Selected : [57, 52, 12, 62, 16, 24, 10, 85, 54, 99]
INFO:root:FL Epoch: 340 Fraction of points on each worker in this round: [0.43333333 0.03333333 0.03333333 0.1        0.06666667 0.1
 0.03333333 0.06666667 0.03333333 0.1       ]
INFO:root:FL Epoch: 340 Num points on workers: [13  1  1  3  2  3  1  2  1  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 340 Training on worker :57
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 340 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 340 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :52
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 340 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :12
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 340 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :62
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 340 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 340 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :16
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 340 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 340 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :24
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 340 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 340 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :10
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 340 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :85
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 340 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 340 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :54
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 340 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :99
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 340 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 340 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 57
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 340 Ends   ===================
INFO:root:Epoch:340 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:340 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 341 Begins ===================
INFO:root:FL Epoch: 341 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 341 Workers Selected : [0, 1, 2, 67, 32, 4, 75, 56, 33, 60]
INFO:root:FL Epoch: 341 Fraction of points on each worker in this round: [0.30534351 0.30534351 0.30534351 0.01832061 0.00610687 0.00152672
 0.00305344 0.00458015 0.04580153 0.00458015]
INFO:root:FL Epoch: 341 Num points on workers: [200 200 200  12   4   1   2   3  30   3]
INFO:root:--------------------------
INFO:root:FL Epoch: 341 Training on worker :0
INFO:root:FL Epoch: 341 Using Learning rate : 0.005062721502041593 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698644
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701681
INFO:root:FL Epoch: 341 Worker: 0 Backdoor Test Loss: 0.7260585427284241 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 341 Worker: 0 Backdoor Train Loss: 0.6883043229579926 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 341 Norm Difference for worker 0 is 0.067238
INFO:root:FL Epoch: 341 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1
INFO:root:FL Epoch: 341 Using Learning rate : 0.005062721502041593 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692933
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700172
INFO:root:FL Epoch: 341 Worker: 1 Backdoor Test Loss: 0.7264325320720673 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 341 Worker: 1 Backdoor Train Loss: 0.6883055329322815 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 341 Norm Difference for worker 1 is 0.067433
INFO:root:FL Epoch: 341 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :2
INFO:root:FL Epoch: 341 Using Learning rate : 0.005062721502041593 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696321
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688005
INFO:root:FL Epoch: 341 Worker: 2 Backdoor Test Loss: 0.7261956532796224 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 341 Worker: 2 Backdoor Train Loss: 0.6883237421512604 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 341 Norm Difference for worker 2 is 0.066739
INFO:root:FL Epoch: 341 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :67
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 341 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 341 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :32
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 341 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 341 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :4
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 341 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 341 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :75
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 341 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 341 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :56
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 341 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 341 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :33
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.692006
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.671252
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 341 Norm Difference for worker 33 is 0.051751
INFO:root:FL Epoch: 341 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :60
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 341 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 341 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 67
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 341 Ends   ===================
INFO:root:Epoch:341 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:341 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 342 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 342 Workers Selected : [28, 84, 69, 67, 29, 40, 80, 94, 74, 23]
INFO:root:FL Epoch: 342 Fraction of points on each worker in this round: [0.05263158 0.10526316 0.14912281 0.10526316 0.00877193 0.00877193
 0.00877193 0.35087719 0.14912281 0.06140351]
INFO:root:FL Epoch: 342 Num points on workers: [ 6 12 17 12  1  1  1 40 17  7]
INFO:root:--------------------------
INFO:root:FL Epoch: 342 Training on worker :28
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 342 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 342 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :84
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 342 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 342 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :69
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 342 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 342 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :67
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 342 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 342 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :29
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 342 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :40
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 342 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :80
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 342 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :94
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.688344
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.661356
INFO:root:FL Epoch: 342 Norm Difference for worker 94 is 0.156499
INFO:root:FL Epoch: 342 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :74
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 342 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 342 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :23
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 342 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 342 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 28
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 342 Ends   ===================
INFO:root:Epoch:342 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:342 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 343 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 343 Workers Selected : [16, 15, 29, 64, 88, 53, 66, 34, 86, 81]
INFO:root:FL Epoch: 343 Fraction of points on each worker in this round: [0.08333333 0.04166667 0.04166667 0.125      0.04166667 0.16666667
 0.04166667 0.125      0.20833333 0.125     ]
INFO:root:FL Epoch: 343 Num points on workers: [2 1 1 3 1 4 1 3 5 3]
INFO:root:--------------------------
INFO:root:FL Epoch: 343 Training on worker :16
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 343 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 343 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :15
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 343 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 343 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :29
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 343 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 343 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :64
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 343 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 343 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :88
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 343 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 343 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :53
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 343 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 343 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :66
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 343 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 343 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :34
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 343 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 343 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :86
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 343 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 343 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :81
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 343 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 343 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 16
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 343 Ends   ===================
INFO:root:Epoch:343 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:343 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 344 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 344 Workers Selected : [90, 80, 89, 22, 20, 86, 94, 68, 72, 33]
INFO:root:FL Epoch: 344 Fraction of points on each worker in this round: [0.02247191 0.01123596 0.01123596 0.01123596 0.01123596 0.05617978
 0.4494382  0.02247191 0.06741573 0.33707865]
INFO:root:FL Epoch: 344 Num points on workers: [ 2  1  1  1  1  5 40  2  6 30]
INFO:root:--------------------------
INFO:root:FL Epoch: 344 Training on worker :90
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 344 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 344 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :80
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 344 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :89
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 344 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :22
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 344 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :20
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 344 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :86
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 344 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 344 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :94
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.688625
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.657170
INFO:root:FL Epoch: 344 Norm Difference for worker 94 is 0.157849
INFO:root:FL Epoch: 344 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :68
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 344 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 344 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :72
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 344 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 344 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :33
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.687631
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.674814
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 344 Norm Difference for worker 33 is 0.050907
INFO:root:FL Epoch: 344 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 90
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 344 Ends   ===================
INFO:root:Epoch:344 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:344 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 345 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 345 Workers Selected : [58, 16, 96, 59, 78, 26, 14, 82, 29, 9]
INFO:root:FL Epoch: 345 Fraction of points on each worker in this round: [0.33962264 0.03773585 0.01886792 0.01886792 0.01886792 0.01886792
 0.11320755 0.01886792 0.01886792 0.39622642]
INFO:root:FL Epoch: 345 Num points on workers: [18  2  1  1  1  1  6  1  1 21]
INFO:root:--------------------------
INFO:root:FL Epoch: 345 Training on worker :58
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 345 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 345 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :16
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 345 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 345 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :96
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 345 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :59
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 345 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :78
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 345 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :26
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 345 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :14
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 345 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 345 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :82
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 345 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :29
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 345 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :9
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.681779
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.667761
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 9 is 0.049851
INFO:root:FL Epoch: 345 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 58
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 345 Ends   ===================
INFO:root:Epoch:345 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:345 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 346 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 346 Workers Selected : [17, 90, 35, 22, 98, 53, 31, 52, 73, 80]
INFO:root:FL Epoch: 346 Fraction of points on each worker in this round: [0.13333333 0.13333333 0.06666667 0.06666667 0.06666667 0.26666667
 0.06666667 0.06666667 0.06666667 0.06666667]
INFO:root:FL Epoch: 346 Num points on workers: [2 2 1 1 1 4 1 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 346 Training on worker :17
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 346 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 346 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :90
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 346 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 346 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :35
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 346 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 346 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :22
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 346 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 346 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :98
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 346 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 346 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :53
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 346 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 346 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :31
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 346 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 346 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :52
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 346 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 346 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :73
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 346 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 346 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :80
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 346 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 346 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 17
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 346 Ends   ===================
INFO:root:Epoch:346 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:346 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 347 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 347 Workers Selected : [92, 12, 26, 20, 36, 72, 53, 44, 19, 27]
INFO:root:FL Epoch: 347 Fraction of points on each worker in this round: [0.14814815 0.03703704 0.03703704 0.03703704 0.07407407 0.22222222
 0.14814815 0.07407407 0.03703704 0.18518519]
INFO:root:FL Epoch: 347 Num points on workers: [4 1 1 1 2 6 4 2 1 5]
INFO:root:--------------------------
INFO:root:FL Epoch: 347 Training on worker :92
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 347 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 347 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :12
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 347 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 347 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :26
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 347 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 347 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :20
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 347 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 347 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :36
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 347 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 347 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :72
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 347 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 347 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :53
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 347 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 347 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :44
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 347 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 347 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :19
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 347 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 347 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :27
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 347 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 347 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 92
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 347 Ends   ===================
INFO:root:Epoch:347 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:347 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 348 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 348 Workers Selected : [54, 7, 36, 73, 20, 59, 72, 9, 83, 47]
INFO:root:FL Epoch: 348 Fraction of points on each worker in this round: [0.02564103 0.02564103 0.05128205 0.02564103 0.02564103 0.02564103
 0.15384615 0.53846154 0.05128205 0.07692308]
INFO:root:FL Epoch: 348 Num points on workers: [ 1  1  2  1  1  1  6 21  2  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 348 Training on worker :54
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 348 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 348 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :7
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 348 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 348 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :36
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 348 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 348 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :73
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 348 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 348 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :20
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 348 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 348 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :59
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 348 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 348 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :72
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 348 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 348 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :9
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.677695
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.673034
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 348 Norm Difference for worker 9 is 0.049475
INFO:root:FL Epoch: 348 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :83
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 348 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 348 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :47
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 348 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 348 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 54
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 348 Ends   ===================
INFO:root:Epoch:348 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:348 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 349 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 349 Workers Selected : [19, 45, 48, 34, 64, 95, 90, 97, 7, 32]
INFO:root:FL Epoch: 349 Fraction of points on each worker in this round: [0.03571429 0.07142857 0.03571429 0.10714286 0.10714286 0.03571429
 0.07142857 0.35714286 0.03571429 0.14285714]
INFO:root:FL Epoch: 349 Num points on workers: [ 1  2  1  3  3  1  2 10  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 349 Training on worker :19
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 349 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :45
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 349 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 349 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :48
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 349 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :34
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 349 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 349 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :64
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 349 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 349 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :95
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 349 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :90
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 349 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 349 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :97
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 349 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 349 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :7
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 349 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :32
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 349 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 349 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 19
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 349 Ends   ===================
INFO:root:Epoch:349 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:349 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 350 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 350 Workers Selected : [57, 25, 68, 88, 40, 31, 19, 22, 64, 97]
INFO:root:FL Epoch: 350 Fraction of points on each worker in this round: [0.22807018 0.42105263 0.03508772 0.01754386 0.01754386 0.01754386
 0.01754386 0.01754386 0.05263158 0.1754386 ]
INFO:root:FL Epoch: 350 Num points on workers: [13 24  2  1  1  1  1  1  3 10]
INFO:root:--------------------------
INFO:root:FL Epoch: 350 Training on worker :57
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 350 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 350 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :25
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.691871
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.671926
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 350 Norm Difference for worker 25 is 0.051851
INFO:root:FL Epoch: 350 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :68
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 350 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 350 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :88
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 350 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :40
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 350 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :31
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 350 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :19
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 350 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :22
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 350 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :64
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 350 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 350 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :97
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 350 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 350 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 57
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 350 Ends   ===================
INFO:root:Epoch:350 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:350 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 351 Begins ===================
INFO:root:FL Epoch: 351 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 351 Workers Selected : [0, 1, 2, 68, 47, 36, 73, 45, 75, 63]
INFO:root:FL Epoch: 351 Fraction of points on each worker in this round: [0.3257329  0.3257329  0.3257329  0.00325733 0.00488599 0.00325733
 0.00162866 0.00325733 0.00325733 0.00325733]
INFO:root:FL Epoch: 351 Num points on workers: [200 200 200   2   3   2   1   2   2   2]
INFO:root:--------------------------
INFO:root:FL Epoch: 351 Training on worker :0
INFO:root:FL Epoch: 351 Using Learning rate : 0.004962373518628473 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700317
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696660
INFO:root:FL Epoch: 351 Worker: 0 Backdoor Test Loss: 0.722441037495931 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 351 Worker: 0 Backdoor Train Loss: 0.6887272119522094 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 351 Norm Difference for worker 0 is 0.062821
INFO:root:FL Epoch: 351 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1
INFO:root:FL Epoch: 351 Using Learning rate : 0.004962373518628473 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701534
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703741
INFO:root:FL Epoch: 351 Worker: 1 Backdoor Test Loss: 0.7263363500436147 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 351 Worker: 1 Backdoor Train Loss: 0.6883304178714752 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 351 Norm Difference for worker 1 is 0.066486
INFO:root:FL Epoch: 351 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :2
INFO:root:FL Epoch: 351 Using Learning rate : 0.004962373518628473 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703685
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703943
INFO:root:FL Epoch: 351 Worker: 2 Backdoor Test Loss: 0.7210683027903239 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 351 Worker: 2 Backdoor Train Loss: 0.688891339302063 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 351 Norm Difference for worker 2 is 0.061079
INFO:root:FL Epoch: 351 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :68
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 351 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 351 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :47
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 351 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 351 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :36
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 351 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 351 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :73
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 351 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 351 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :45
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 351 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 351 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :75
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 351 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 351 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :63
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 351 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 351 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 68
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 351 Ends   ===================
INFO:root:Epoch:351 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:351 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 352 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 352 Workers Selected : [92, 98, 95, 35, 84, 77, 20, 37, 70, 50]
INFO:root:FL Epoch: 352 Fraction of points on each worker in this round: [0.16 0.04 0.04 0.04 0.48 0.04 0.04 0.04 0.08 0.04]
INFO:root:FL Epoch: 352 Num points on workers: [ 4  1  1  1 12  1  1  1  2  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 352 Training on worker :92
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 352 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 352 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :98
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 352 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 352 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :95
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 352 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 352 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :35
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 352 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 352 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :84
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 352 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 352 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :77
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 352 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 352 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :20
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 352 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 352 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :37
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 352 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 352 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :70
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 352 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 352 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :50
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 352 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 352 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 92
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 352 Ends   ===================
INFO:root:Epoch:352 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:352 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 353 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 353 Workers Selected : [25, 51, 98, 40, 60, 57, 43, 45, 39, 19]
INFO:root:FL Epoch: 353 Fraction of points on each worker in this round: [0.38095238 0.06349206 0.01587302 0.01587302 0.04761905 0.20634921
 0.01587302 0.03174603 0.20634921 0.01587302]
INFO:root:FL Epoch: 353 Num points on workers: [24  4  1  1  3 13  1  2 13  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 353 Training on worker :25
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.681281
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.679284
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 353 Norm Difference for worker 25 is 0.051055
INFO:root:FL Epoch: 353 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :51
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 353 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 353 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :98
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 353 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 353 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :40
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 353 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 353 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :60
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 353 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 353 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :57
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 353 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 353 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :43
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 353 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 353 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :45
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 353 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 353 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :39
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 353 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 353 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :19
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 353 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 353 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 51
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 353 Ends   ===================
INFO:root:Epoch:353 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:353 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 354 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 354 Workers Selected : [39, 99, 37, 21, 62, 9, 69, 65, 53, 97]
INFO:root:FL Epoch: 354 Fraction of points on each worker in this round: [0.10483871 0.02419355 0.00806452 0.41129032 0.02419355 0.16935484
 0.13709677 0.00806452 0.03225806 0.08064516]
INFO:root:FL Epoch: 354 Num points on workers: [13  3  1 51  3 21 17  1  4 10]
INFO:root:--------------------------
INFO:root:FL Epoch: 354 Training on worker :39
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 354 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 354 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :99
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 354 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 354 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :37
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 354 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :21
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.694638
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.658798
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 354 Norm Difference for worker 21 is 0.165624
INFO:root:FL Epoch: 354 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :62
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 354 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 354 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :9
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.687101
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.675016
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 9 is 0.048963
INFO:root:FL Epoch: 354 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :69
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 354 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 354 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :65
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 354 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :53
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 354 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 354 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :97
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 354 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 354 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 39
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 354 Ends   ===================
INFO:root:Epoch:354 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:354 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 355 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 355 Workers Selected : [84, 24, 90, 42, 4, 73, 36, 45, 16, 47]
INFO:root:FL Epoch: 355 Fraction of points on each worker in this round: [0.38709677 0.09677419 0.06451613 0.09677419 0.03225806 0.03225806
 0.06451613 0.06451613 0.06451613 0.09677419]
INFO:root:FL Epoch: 355 Num points on workers: [12  3  2  3  1  1  2  2  2  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 355 Training on worker :84
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 355 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 355 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :24
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 355 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 355 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :90
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 355 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 355 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :42
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 355 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 355 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :4
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 355 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 355 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :73
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 355 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 355 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :36
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 355 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 355 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :45
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 355 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 355 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :16
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 355 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 355 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :47
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 355 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 355 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 84
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 355 Ends   ===================
INFO:root:Epoch:355 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:355 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 356 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 356 Workers Selected : [30, 76, 75, 10, 19, 14, 31, 61, 62, 48]
INFO:root:FL Epoch: 356 Fraction of points on each worker in this round: [0.09090909 0.18181818 0.09090909 0.04545455 0.04545455 0.27272727
 0.04545455 0.04545455 0.13636364 0.04545455]
INFO:root:FL Epoch: 356 Num points on workers: [2 4 2 1 1 6 1 1 3 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 356 Training on worker :30
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 356 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 356 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :76
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 356 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 356 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :75
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 356 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 356 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :10
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 356 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :19
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 356 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :14
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 356 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 356 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :31
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 356 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :61
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 356 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :62
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 356 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 356 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :48
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 356 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 30
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 356 Ends   ===================
INFO:root:Epoch:356 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:356 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 357 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 357 Workers Selected : [12, 21, 70, 8, 54, 95, 29, 93, 86, 33]
INFO:root:FL Epoch: 357 Fraction of points on each worker in this round: [0.01052632 0.53684211 0.02105263 0.01052632 0.01052632 0.01052632
 0.01052632 0.02105263 0.05263158 0.31578947]
INFO:root:FL Epoch: 357 Num points on workers: [ 1 51  2  1  1  1  1  2  5 30]
INFO:root:--------------------------
INFO:root:FL Epoch: 357 Training on worker :12
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 357 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :21
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.699788
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.664659
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 357 Norm Difference for worker 21 is 0.164504
INFO:root:FL Epoch: 357 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :70
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 357 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 357 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :8
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 357 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :54
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 357 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :95
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 357 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :29
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 357 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :93
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 357 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 357 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :86
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 357 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 357 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :33
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.681875
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.676731
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 357 Norm Difference for worker 33 is 0.049547
INFO:root:FL Epoch: 357 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 12
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 357 Ends   ===================
INFO:root:Epoch:357 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:357 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 358 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 358 Workers Selected : [52, 38, 71, 17, 73, 26, 44, 91, 67, 61]
INFO:root:FL Epoch: 358 Fraction of points on each worker in this round: [0.03846154 0.03846154 0.03846154 0.07692308 0.03846154 0.03846154
 0.07692308 0.15384615 0.46153846 0.03846154]
INFO:root:FL Epoch: 358 Num points on workers: [ 1  1  1  2  1  1  2  4 12  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 358 Training on worker :52
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 358 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :38
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 358 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :71
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 358 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :17
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 358 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 358 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :73
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 358 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :26
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 358 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :44
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 358 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 358 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :91
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 358 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 358 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :67
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 358 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 358 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :61
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 358 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 52
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 358 Ends   ===================
INFO:root:Epoch:358 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:358 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 359 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 359 Workers Selected : [66, 96, 22, 88, 64, 29, 49, 44, 7, 51]
INFO:root:FL Epoch: 359 Fraction of points on each worker in this round: [0.0625 0.0625 0.0625 0.0625 0.1875 0.0625 0.0625 0.125  0.0625 0.25  ]
INFO:root:FL Epoch: 359 Num points on workers: [1 1 1 1 3 1 1 2 1 4]
INFO:root:--------------------------
INFO:root:FL Epoch: 359 Training on worker :66
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 359 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :96
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 359 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :22
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 359 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :88
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 359 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :64
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 359 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 359 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :29
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 359 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :49
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 359 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :44
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 359 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 359 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :7
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 359 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :51
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 359 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 359 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 66
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 359 Ends   ===================
INFO:root:Epoch:359 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:359 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 360 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 360 Workers Selected : [98, 46, 97, 16, 75, 10, 93, 96, 89, 99]
INFO:root:FL Epoch: 360 Fraction of points on each worker in this round: [0.04166667 0.04166667 0.41666667 0.08333333 0.08333333 0.04166667
 0.08333333 0.04166667 0.04166667 0.125     ]
INFO:root:FL Epoch: 360 Num points on workers: [ 1  1 10  2  2  1  2  1  1  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 360 Training on worker :98
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 360 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :46
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 360 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :97
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 360 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 360 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :16
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 360 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 360 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :75
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 360 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 360 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :10
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 360 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :93
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 360 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 360 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :96
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 360 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :89
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 360 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :99
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 360 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 360 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 98
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 360 Ends   ===================
INFO:root:Epoch:360 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:360 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 361 Begins ===================
INFO:root:FL Epoch: 361 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 361 Workers Selected : [0, 1, 2, 87, 95, 36, 26, 89, 21, 33]
INFO:root:FL Epoch: 361 Fraction of points on each worker in this round: [0.2894356  0.2894356  0.2894356  0.00723589 0.00144718 0.00289436
 0.00144718 0.00144718 0.07380608 0.04341534]
INFO:root:FL Epoch: 361 Num points on workers: [200 200 200   5   1   2   1   1  51  30]
INFO:root:--------------------------
INFO:root:FL Epoch: 361 Training on worker :0
INFO:root:FL Epoch: 361 Using Learning rate : 0.004864014528244303 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697364
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696443
INFO:root:FL Epoch: 361 Worker: 0 Backdoor Test Loss: 0.7243235111236572 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 361 Worker: 0 Backdoor Train Loss: 0.6885417461395263 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 361 Norm Difference for worker 0 is 0.064272
INFO:root:FL Epoch: 361 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1
INFO:root:FL Epoch: 361 Using Learning rate : 0.004864014528244303 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689738
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694733
INFO:root:FL Epoch: 361 Worker: 1 Backdoor Test Loss: 0.7280154923597971 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 361 Worker: 1 Backdoor Train Loss: 0.6883768856525421 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 361 Norm Difference for worker 1 is 0.066803
INFO:root:FL Epoch: 361 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :2
INFO:root:FL Epoch: 361 Using Learning rate : 0.004864014528244303 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698250
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688757
INFO:root:FL Epoch: 361 Worker: 2 Backdoor Test Loss: 0.7242887715498606 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 361 Worker: 2 Backdoor Train Loss: 0.6886763334274292 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 361 Norm Difference for worker 2 is 0.063029
INFO:root:FL Epoch: 361 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :87
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 361 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 361 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :95
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 361 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 361 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :36
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 361 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 361 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :26
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 361 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 361 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :89
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 361 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 361 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :21
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.694342
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.656444
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 361 Norm Difference for worker 21 is 0.163423
INFO:root:FL Epoch: 361 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :33
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.686161
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.674333
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 361 Norm Difference for worker 33 is 0.049166
INFO:root:FL Epoch: 361 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 87
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 361 Ends   ===================
INFO:root:Epoch:361 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:361 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 362 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 362 Workers Selected : [50, 3, 63, 45, 74, 29, 67, 69, 90, 96]
INFO:root:FL Epoch: 362 Fraction of points on each worker in this round: [0.01785714 0.01785714 0.03571429 0.03571429 0.30357143 0.01785714
 0.21428571 0.30357143 0.03571429 0.01785714]
INFO:root:FL Epoch: 362 Num points on workers: [ 1  1  2  2 17  1 12 17  2  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 362 Training on worker :50
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 362 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 362 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :3
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 362 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 362 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :63
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 362 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 362 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :45
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 362 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 362 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :74
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 362 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 362 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :29
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 362 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 362 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :67
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 362 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 362 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :69
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 362 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 362 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :90
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 362 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 362 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :96
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 362 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 362 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 50
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 362 Ends   ===================
INFO:root:Epoch:362 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:362 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 363 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 363 Workers Selected : [99, 72, 16, 4, 52, 22, 75, 88, 98, 54]
INFO:root:FL Epoch: 363 Fraction of points on each worker in this round: [0.15789474 0.31578947 0.10526316 0.05263158 0.05263158 0.05263158
 0.10526316 0.05263158 0.05263158 0.05263158]
INFO:root:FL Epoch: 363 Num points on workers: [3 6 2 1 1 1 2 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 363 Training on worker :99
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 363 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 363 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :72
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 363 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 363 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :16
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 363 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 363 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :4
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 363 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 363 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :52
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 363 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 363 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :22
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 363 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 363 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :75
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 363 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 363 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :88
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 363 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 363 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :98
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 363 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 363 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :54
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 363 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 363 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 99
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 363 Ends   ===================
INFO:root:Epoch:363 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:363 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 364 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 364 Workers Selected : [7, 31, 90, 99, 62, 24, 18, 26, 72, 6]
INFO:root:FL Epoch: 364 Fraction of points on each worker in this round: [0.04 0.04 0.08 0.12 0.12 0.12 0.16 0.04 0.24 0.04]
INFO:root:FL Epoch: 364 Num points on workers: [1 1 2 3 3 3 4 1 6 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 364 Training on worker :7
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 364 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :31
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 364 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :90
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 364 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 364 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :99
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 364 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 364 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :62
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 364 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 364 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :24
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 364 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 364 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :18
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 364 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 364 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :26
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 364 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :72
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 364 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 364 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :6
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 364 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 7
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 364 Ends   ===================
INFO:root:Epoch:364 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:364 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 365 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 365 Workers Selected : [97, 28, 36, 82, 8, 60, 91, 95, 38, 73]
INFO:root:FL Epoch: 365 Fraction of points on each worker in this round: [0.33333333 0.2        0.06666667 0.03333333 0.03333333 0.1
 0.13333333 0.03333333 0.03333333 0.03333333]
INFO:root:FL Epoch: 365 Num points on workers: [10  6  2  1  1  3  4  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 365 Training on worker :97
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 365 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 365 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :28
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 365 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 365 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :36
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 365 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 365 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :82
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 365 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 365 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :8
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 365 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 365 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :60
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 365 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 365 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :91
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 365 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 365 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :95
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 365 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 365 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :38
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 365 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 365 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :73
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 365 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 365 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 97
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 365 Ends   ===================
INFO:root:Epoch:365 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:365 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 366 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 366 Workers Selected : [4, 90, 56, 91, 23, 67, 64, 95, 46, 84]
INFO:root:FL Epoch: 366 Fraction of points on each worker in this round: [0.02173913 0.04347826 0.06521739 0.08695652 0.15217391 0.26086957
 0.06521739 0.02173913 0.02173913 0.26086957]
INFO:root:FL Epoch: 366 Num points on workers: [ 1  2  3  4  7 12  3  1  1 12]
INFO:root:--------------------------
INFO:root:FL Epoch: 366 Training on worker :4
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 366 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 366 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :90
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 366 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 366 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :56
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 366 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 366 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :91
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 366 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 366 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :23
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 366 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 366 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :67
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 366 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 366 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :64
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 366 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 366 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :95
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 366 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 366 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :46
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 366 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 366 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :84
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 366 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 366 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 4
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 366 Ends   ===================
INFO:root:Epoch:366 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:366 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 367 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 367 Workers Selected : [33, 88, 23, 49, 35, 27, 46, 76, 5, 89]
INFO:root:FL Epoch: 367 Fraction of points on each worker in this round: [0.5        0.01666667 0.11666667 0.01666667 0.01666667 0.08333333
 0.01666667 0.06666667 0.15       0.01666667]
INFO:root:FL Epoch: 367 Num points on workers: [30  1  7  1  1  5  1  4  9  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 367 Training on worker :33
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.688810
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.681817
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 367 Norm Difference for worker 33 is 0.048866
INFO:root:FL Epoch: 367 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :88
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 367 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :23
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 367 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 367 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :49
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 367 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :35
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 367 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :27
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 367 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 367 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :46
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 367 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :76
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 367 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 367 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :5
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 367 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 367 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :89
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 367 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 88
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 367 Ends   ===================
INFO:root:Epoch:367 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:367 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 368 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 368 Workers Selected : [97, 9, 86, 82, 60, 54, 32, 21, 83, 64]
INFO:root:FL Epoch: 368 Fraction of points on each worker in this round: [0.0990099  0.20792079 0.04950495 0.00990099 0.02970297 0.00990099
 0.03960396 0.5049505  0.01980198 0.02970297]
INFO:root:FL Epoch: 368 Num points on workers: [10 21  5  1  3  1  4 51  2  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 368 Training on worker :97
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 368 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 368 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :9
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.685835
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.670168
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 9 is 0.047012
INFO:root:FL Epoch: 368 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :86
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 368 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 368 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :82
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 368 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :60
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 368 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 368 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :54
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 368 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :32
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 368 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 368 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :21
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.701088
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.661735
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 368 Norm Difference for worker 21 is 0.160852
INFO:root:FL Epoch: 368 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :83
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 368 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 368 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :64
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 368 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 368 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 97
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 368 Ends   ===================
INFO:root:Epoch:368 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:368 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 369 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 369 Workers Selected : [61, 10, 27, 95, 41, 87, 89, 55, 46, 11]
INFO:root:FL Epoch: 369 Fraction of points on each worker in this round: [0.04347826 0.04347826 0.2173913  0.04347826 0.17391304 0.2173913
 0.04347826 0.04347826 0.04347826 0.13043478]
INFO:root:FL Epoch: 369 Num points on workers: [1 1 5 1 4 5 1 1 1 3]
INFO:root:--------------------------
INFO:root:FL Epoch: 369 Training on worker :61
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 369 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :10
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 369 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :27
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 369 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 369 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :95
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 369 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :41
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 369 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 369 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :87
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 369 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 369 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :89
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 369 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :55
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 369 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :46
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 369 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :11
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 369 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 369 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 61
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 369 Ends   ===================
INFO:root:Epoch:369 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:369 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 370 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 370 Workers Selected : [90, 36, 10, 85, 54, 60, 64, 53, 7, 14]
INFO:root:FL Epoch: 370 Fraction of points on each worker in this round: [0.08 0.08 0.04 0.08 0.04 0.12 0.12 0.16 0.04 0.24]
INFO:root:FL Epoch: 370 Num points on workers: [2 2 1 2 1 3 3 4 1 6]
INFO:root:--------------------------
INFO:root:FL Epoch: 370 Training on worker :90
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 370 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 370 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :36
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 370 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 370 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :10
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 370 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :85
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 370 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 370 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :54
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 370 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :60
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 370 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 370 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :64
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 370 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 370 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :53
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 370 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 370 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :7
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 370 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :14
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 370 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 370 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 90
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 370 Ends   ===================
INFO:root:Epoch:370 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:370 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 371 Begins ===================
INFO:root:FL Epoch: 371 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 371 Workers Selected : [0, 1, 2, 99, 90, 60, 77, 33, 25, 18]
INFO:root:FL Epoch: 371 Fraction of points on each worker in this round: [0.29985007 0.29985007 0.29985007 0.00449775 0.0029985  0.00449775
 0.00149925 0.04497751 0.03598201 0.005997  ]
INFO:root:FL Epoch: 371 Num points on workers: [200 200 200   3   2   3   1  30  24   4]
INFO:root:--------------------------
INFO:root:FL Epoch: 371 Training on worker :0
INFO:root:FL Epoch: 371 Using Learning rate : 0.0047676051071444845 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704987
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693325
INFO:root:FL Epoch: 371 Worker: 0 Backdoor Test Loss: 0.7262348333994547 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 371 Worker: 0 Backdoor Train Loss: 0.6885258674621582 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 371 Norm Difference for worker 0 is 0.064833
INFO:root:FL Epoch: 371 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1
INFO:root:FL Epoch: 371 Using Learning rate : 0.0047676051071444845 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693543
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691782
INFO:root:FL Epoch: 371 Worker: 1 Backdoor Test Loss: 0.7220011651515961 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 371 Worker: 1 Backdoor Train Loss: 0.6888766348361969 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 371 Norm Difference for worker 1 is 0.060525
INFO:root:FL Epoch: 371 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :2
INFO:root:FL Epoch: 371 Using Learning rate : 0.0047676051071444845 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700811
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690547
INFO:root:FL Epoch: 371 Worker: 2 Backdoor Test Loss: 0.7238458395004272 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 371 Worker: 2 Backdoor Train Loss: 0.6887264668941497 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 371 Norm Difference for worker 2 is 0.062429
INFO:root:FL Epoch: 371 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :99
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 371 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 371 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :90
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 371 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 371 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :60
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 371 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 371 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :77
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 371 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 371 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :33
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.688419
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.675465
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 371 Norm Difference for worker 33 is 0.048083
INFO:root:FL Epoch: 371 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :25
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.693463
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.677876
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 371 Norm Difference for worker 25 is 0.04964
INFO:root:FL Epoch: 371 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :18
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 371 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 371 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 99
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 371 Ends   ===================
INFO:root:Epoch:371 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:371 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 372 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 372 Workers Selected : [77, 53, 47, 5, 39, 40, 90, 33, 19, 91]
INFO:root:FL Epoch: 372 Fraction of points on each worker in this round: [0.01470588 0.05882353 0.04411765 0.13235294 0.19117647 0.01470588
 0.02941176 0.44117647 0.01470588 0.05882353]
INFO:root:FL Epoch: 372 Num points on workers: [ 1  4  3  9 13  1  2 30  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 372 Training on worker :77
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 372 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 372 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :53
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 372 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 372 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :47
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 372 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 372 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :5
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 372 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 372 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :39
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 372 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 372 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :40
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 372 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 372 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :90
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 372 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 372 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :33
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.691671
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.670728
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 372 Norm Difference for worker 33 is 0.048534
INFO:root:FL Epoch: 372 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :19
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 372 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 372 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :91
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 372 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 372 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 77
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 372 Ends   ===================
INFO:root:Epoch:372 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:372 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 373 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 373 Workers Selected : [19, 96, 77, 32, 59, 75, 67, 49, 27, 89]
INFO:root:FL Epoch: 373 Fraction of points on each worker in this round: [0.03448276 0.03448276 0.03448276 0.13793103 0.03448276 0.06896552
 0.4137931  0.03448276 0.17241379 0.03448276]
INFO:root:FL Epoch: 373 Num points on workers: [ 1  1  1  4  1  2 12  1  5  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 373 Training on worker :19
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 373 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 373 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :96
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 373 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 373 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :77
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 373 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 373 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :32
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 373 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 373 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :59
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 373 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 373 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :75
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 373 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 373 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :67
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 373 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 373 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :49
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 373 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 373 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :27
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 373 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 373 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :89
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 373 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 373 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 19
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 373 Ends   ===================
INFO:root:Epoch:373 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:373 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 374 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 374 Workers Selected : [50, 98, 10, 17, 66, 24, 86, 93, 11, 34]
INFO:root:FL Epoch: 374 Fraction of points on each worker in this round: [0.04545455 0.04545455 0.04545455 0.09090909 0.04545455 0.13636364
 0.22727273 0.09090909 0.13636364 0.13636364]
INFO:root:FL Epoch: 374 Num points on workers: [1 1 1 2 1 3 5 2 3 3]
INFO:root:--------------------------
INFO:root:FL Epoch: 374 Training on worker :50
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 374 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 374 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :98
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 374 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 374 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :10
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 374 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 374 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :17
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 374 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 374 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :66
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 374 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 374 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :24
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 374 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 374 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :86
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 374 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 374 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :93
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 374 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 374 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :11
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 374 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 374 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :34
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 374 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 374 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 50
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 374 Ends   ===================
INFO:root:Epoch:374 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:374 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 375 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 375 Workers Selected : [81, 13, 8, 48, 72, 96, 46, 93, 60, 77]
INFO:root:FL Epoch: 375 Fraction of points on each worker in this round: [0.13043478 0.17391304 0.04347826 0.04347826 0.26086957 0.04347826
 0.04347826 0.08695652 0.13043478 0.04347826]
INFO:root:FL Epoch: 375 Num points on workers: [3 4 1 1 6 1 1 2 3 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 375 Training on worker :81
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 375 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 375 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :13
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 375 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 375 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :8
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 375 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :48
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 375 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :72
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 375 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 375 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :96
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 375 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :46
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 375 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :93
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 375 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 375 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :60
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 375 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 375 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :77
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 375 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 81
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 375 Ends   ===================
INFO:root:Epoch:375 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:375 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 376 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 376 Workers Selected : [71, 44, 79, 55, 89, 32, 9, 81, 90, 22]
INFO:root:FL Epoch: 376 Fraction of points on each worker in this round: [0.02631579 0.05263158 0.05263158 0.02631579 0.02631579 0.10526316
 0.55263158 0.07894737 0.05263158 0.02631579]
INFO:root:FL Epoch: 376 Num points on workers: [ 1  2  2  1  1  4 21  3  2  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 376 Training on worker :71
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 376 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 376 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :44
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 376 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 376 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :79
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 376 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 376 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :55
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 376 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 376 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :89
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 376 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 376 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :32
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 376 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 376 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :9
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.682058
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.668744
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 376 Norm Difference for worker 9 is 0.046074
INFO:root:FL Epoch: 376 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :81
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 376 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 376 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :90
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 376 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 376 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :22
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 376 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 376 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 71
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 376 Ends   ===================
INFO:root:Epoch:376 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:376 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 377 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 377 Workers Selected : [4, 85, 93, 13, 39, 65, 36, 49, 42, 12]
INFO:root:FL Epoch: 377 Fraction of points on each worker in this round: [0.03333333 0.06666667 0.06666667 0.13333333 0.43333333 0.03333333
 0.06666667 0.03333333 0.1        0.03333333]
INFO:root:FL Epoch: 377 Num points on workers: [ 1  2  2  4 13  1  2  1  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 377 Training on worker :4
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 377 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :85
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 377 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 377 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :93
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 377 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 377 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :13
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 377 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 377 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :39
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 377 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 377 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :65
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 377 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :36
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 377 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 377 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :49
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 377 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :42
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 377 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 377 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :12
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 377 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 4
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 377 Ends   ===================
INFO:root:Epoch:377 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:377 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 378 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 378 Workers Selected : [55, 6, 66, 26, 70, 48, 14, 94, 44, 63]
INFO:root:FL Epoch: 378 Fraction of points on each worker in this round: [0.01754386 0.01754386 0.01754386 0.01754386 0.03508772 0.01754386
 0.10526316 0.70175439 0.03508772 0.03508772]
INFO:root:FL Epoch: 378 Num points on workers: [ 1  1  1  1  2  1  6 40  2  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 378 Training on worker :55
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 378 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 378 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :6
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 378 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 378 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :66
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 378 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 378 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :26
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 378 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 378 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :70
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 378 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 378 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :48
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 378 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 378 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :14
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 378 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 378 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :94
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.693944
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.653558
INFO:root:FL Epoch: 378 Norm Difference for worker 94 is 0.145748
INFO:root:FL Epoch: 378 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :44
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 378 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 378 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :63
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 378 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 378 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 55
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 378 Ends   ===================
INFO:root:Epoch:378 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:378 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 379 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 379 Workers Selected : [69, 17, 85, 47, 15, 21, 43, 24, 50, 74]
INFO:root:FL Epoch: 379 Fraction of points on each worker in this round: [0.17346939 0.02040816 0.02040816 0.03061224 0.01020408 0.52040816
 0.01020408 0.03061224 0.01020408 0.17346939]
INFO:root:FL Epoch: 379 Num points on workers: [17  2  2  3  1 51  1  3  1 17]
INFO:root:--------------------------
INFO:root:FL Epoch: 379 Training on worker :69
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 379 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 379 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :17
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 379 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 379 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :85
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 379 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 379 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :47
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 379 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 379 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :15
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 379 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :21
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.704300
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.660815
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 379 Norm Difference for worker 21 is 0.159068
INFO:root:FL Epoch: 379 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :43
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 379 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :24
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 379 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 379 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :50
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 379 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :74
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 379 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 379 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 69
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 379 Ends   ===================
INFO:root:Epoch:379 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:379 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 380 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 380 Workers Selected : [81, 30, 59, 36, 42, 28, 85, 34, 79, 4]
INFO:root:FL Epoch: 380 Fraction of points on each worker in this round: [0.12 0.08 0.04 0.08 0.12 0.24 0.08 0.12 0.08 0.04]
INFO:root:FL Epoch: 380 Num points on workers: [3 2 1 2 3 6 2 3 2 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 380 Training on worker :81
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 380 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 380 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :30
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 380 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 380 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :59
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 380 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 380 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :36
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 380 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 380 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :42
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 380 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 380 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :28
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 380 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 380 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :85
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 380 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 380 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :34
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 380 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 380 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :79
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 380 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 380 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :4
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 380 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 380 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 81
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 380 Ends   ===================
INFO:root:Epoch:380 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:380 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 381 Begins ===================
INFO:root:FL Epoch: 381 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 381 Workers Selected : [0, 1, 2, 11, 73, 88, 59, 91, 57, 44]
INFO:root:FL Epoch: 381 Fraction of points on each worker in this round: [0.32   0.32   0.32   0.0048 0.0016 0.0016 0.0016 0.0064 0.0208 0.0032]
INFO:root:FL Epoch: 381 Num points on workers: [200 200 200   3   1   1   1   4  13   2]
INFO:root:--------------------------
INFO:root:FL Epoch: 381 Training on worker :0
INFO:root:FL Epoch: 381 Using Learning rate : 0.00467310661300075 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688597
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682095
INFO:root:FL Epoch: 381 Worker: 0 Backdoor Test Loss: 0.7223841349283854 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 381 Worker: 0 Backdoor Train Loss: 0.6889149904251098 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 381 Norm Difference for worker 0 is 0.060402
INFO:root:FL Epoch: 381 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1
INFO:root:FL Epoch: 381 Using Learning rate : 0.00467310661300075 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693480
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692225
INFO:root:FL Epoch: 381 Worker: 1 Backdoor Test Loss: 0.7251703341801962 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 381 Worker: 1 Backdoor Train Loss: 0.6887649178504944 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 381 Norm Difference for worker 1 is 0.062043
INFO:root:FL Epoch: 381 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :2
INFO:root:FL Epoch: 381 Using Learning rate : 0.00467310661300075 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699795
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695288
INFO:root:FL Epoch: 381 Worker: 2 Backdoor Test Loss: 0.7263953586419424 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 381 Worker: 2 Backdoor Train Loss: 0.6885534167289734 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 381 Norm Difference for worker 2 is 0.064465
INFO:root:FL Epoch: 381 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :11
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 381 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 381 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :73
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 381 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 381 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :88
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 381 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 381 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :59
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 381 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 381 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :91
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 381 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 381 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :57
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 381 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 381 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :44
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 381 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 381 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 11
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 381 Ends   ===================
INFO:root:Epoch:381 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:381 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 382 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 382 Workers Selected : [39, 40, 68, 67, 21, 16, 92, 5, 43, 64]
INFO:root:FL Epoch: 382 Fraction of points on each worker in this round: [0.13265306 0.01020408 0.02040816 0.12244898 0.52040816 0.02040816
 0.04081633 0.09183673 0.01020408 0.03061224]
INFO:root:FL Epoch: 382 Num points on workers: [13  1  2 12 51  2  4  9  1  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 382 Training on worker :39
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 382 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 382 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :40
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 382 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 382 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :68
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 382 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 382 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :67
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 382 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 382 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :21
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.691800
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.655857
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 382 Norm Difference for worker 21 is 0.157964
INFO:root:FL Epoch: 382 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :16
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 382 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 382 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :92
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 382 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 382 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :5
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 382 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 382 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :43
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 382 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 382 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :64
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 382 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 382 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 39
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 382 Ends   ===================
INFO:root:Epoch:382 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:382 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 383 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 383 Workers Selected : [33, 97, 34, 67, 72, 24, 64, 35, 40, 56]
INFO:root:FL Epoch: 383 Fraction of points on each worker in this round: [0.41666667 0.13888889 0.04166667 0.16666667 0.08333333 0.04166667
 0.04166667 0.01388889 0.01388889 0.04166667]
INFO:root:FL Epoch: 383 Num points on workers: [30 10  3 12  6  3  3  1  1  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 383 Training on worker :33
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.682126
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.672326
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 383 Norm Difference for worker 33 is 0.046818
INFO:root:FL Epoch: 383 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :97
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 383 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 383 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :34
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 383 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 383 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :67
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 383 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 383 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :72
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 383 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 383 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :24
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 383 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 383 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :64
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 383 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 383 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :35
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 383 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 383 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :40
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 383 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 383 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :56
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 383 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 383 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 97
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 383 Ends   ===================
INFO:root:Epoch:383 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:383 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 384 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 384 Workers Selected : [38, 42, 77, 12, 56, 39, 6, 40, 27, 26]
INFO:root:FL Epoch: 384 Fraction of points on each worker in this round: [0.03333333 0.1        0.03333333 0.03333333 0.1        0.43333333
 0.03333333 0.03333333 0.16666667 0.03333333]
INFO:root:FL Epoch: 384 Num points on workers: [ 1  3  1  1  3 13  1  1  5  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 384 Training on worker :38
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 384 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :42
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 384 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 384 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :77
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 384 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :12
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 384 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :56
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 384 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 384 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :39
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 384 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 384 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :6
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 384 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :40
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 384 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :27
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 384 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 384 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :26
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 384 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 38
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 384 Ends   ===================
INFO:root:Epoch:384 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:384 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 385 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 385 Workers Selected : [28, 66, 26, 81, 5, 53, 41, 97, 72, 99]
INFO:root:FL Epoch: 385 Fraction of points on each worker in this round: [0.12765957 0.0212766  0.0212766  0.06382979 0.19148936 0.08510638
 0.08510638 0.21276596 0.12765957 0.06382979]
INFO:root:FL Epoch: 385 Num points on workers: [ 6  1  1  3  9  4  4 10  6  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 385 Training on worker :28
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 385 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 385 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :66
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 385 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 385 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :26
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 385 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 385 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :81
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 385 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 385 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :5
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 385 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 385 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :53
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 385 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 385 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :41
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 385 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 385 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :97
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 385 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 385 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :72
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 385 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 385 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :99
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 385 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 385 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 28
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 385 Ends   ===================
INFO:root:Epoch:385 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:385 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 386 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 386 Workers Selected : [53, 85, 97, 84, 82, 49, 94, 89, 32, 40]
INFO:root:FL Epoch: 386 Fraction of points on each worker in this round: [0.05263158 0.02631579 0.13157895 0.15789474 0.01315789 0.01315789
 0.52631579 0.01315789 0.05263158 0.01315789]
INFO:root:FL Epoch: 386 Num points on workers: [ 4  2 10 12  1  1 40  1  4  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 386 Training on worker :53
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 386 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 386 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :85
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 386 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 386 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :97
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 386 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 386 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :84
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 386 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 386 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :82
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 386 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 386 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :49
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 386 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 386 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :94
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.689541
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.658873
INFO:root:FL Epoch: 386 Norm Difference for worker 94 is 0.143669
INFO:root:FL Epoch: 386 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :89
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 386 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 386 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :32
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 386 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 386 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :40
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 386 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 386 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 53
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 386 Ends   ===================
INFO:root:Epoch:386 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:386 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 387 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 387 Workers Selected : [29, 21, 28, 94, 77, 88, 7, 99, 23, 65]
INFO:root:FL Epoch: 387 Fraction of points on each worker in this round: [0.00892857 0.45535714 0.05357143 0.35714286 0.00892857 0.00892857
 0.00892857 0.02678571 0.0625     0.00892857]
INFO:root:FL Epoch: 387 Num points on workers: [ 1 51  6 40  1  1  1  3  7  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 387 Training on worker :29
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 387 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :21
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.696950
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.658628
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 387 Norm Difference for worker 21 is 0.156451
INFO:root:FL Epoch: 387 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :28
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 387 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 387 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :94
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.690987
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.659473
INFO:root:FL Epoch: 387 Norm Difference for worker 94 is 0.141223
INFO:root:FL Epoch: 387 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :77
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 387 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :88
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 387 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :7
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 387 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :99
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 387 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 387 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :23
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 387 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 387 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :65
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 387 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 29
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 387 Ends   ===================
INFO:root:Epoch:387 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:387 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 388 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 388 Workers Selected : [47, 86, 91, 32, 62, 21, 87, 10, 12, 98]
INFO:root:FL Epoch: 388 Fraction of points on each worker in this round: [0.03846154 0.06410256 0.05128205 0.05128205 0.03846154 0.65384615
 0.06410256 0.01282051 0.01282051 0.01282051]
INFO:root:FL Epoch: 388 Num points on workers: [ 3  5  4  4  3 51  5  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 388 Training on worker :47
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 388 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 388 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :86
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 388 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 388 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :91
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 388 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 388 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :32
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 388 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 388 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :62
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 388 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 388 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :21
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.697821
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.656444
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 388 Norm Difference for worker 21 is 0.15493
INFO:root:FL Epoch: 388 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :87
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 388 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 388 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :10
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 388 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :12
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 388 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :98
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 388 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 47
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 388 Ends   ===================
INFO:root:Epoch:388 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:388 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 389 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 389 Workers Selected : [15, 96, 17, 62, 80, 71, 84, 19, 94, 34]
INFO:root:FL Epoch: 389 Fraction of points on each worker in this round: [0.01538462 0.01538462 0.03076923 0.04615385 0.01538462 0.01538462
 0.18461538 0.01538462 0.61538462 0.04615385]
INFO:root:FL Epoch: 389 Num points on workers: [ 1  1  2  3  1  1 12  1 40  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 389 Training on worker :15
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 389 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 389 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :96
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 389 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 389 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :17
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 389 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 389 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :62
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 389 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 389 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :80
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 389 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 389 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :71
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 389 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 389 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :84
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 389 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 389 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :19
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 389 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 389 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :94
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.693815
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.666712
INFO:root:FL Epoch: 389 Norm Difference for worker 94 is 0.143218
INFO:root:FL Epoch: 389 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :34
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 389 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 389 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 15
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 389 Ends   ===================
INFO:root:Epoch:389 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:389 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 390 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 390 Workers Selected : [66, 49, 76, 63, 25, 20, 33, 34, 61, 28]
INFO:root:FL Epoch: 390 Fraction of points on each worker in this round: [0.01369863 0.01369863 0.05479452 0.02739726 0.32876712 0.01369863
 0.4109589  0.04109589 0.01369863 0.08219178]
INFO:root:FL Epoch: 390 Num points on workers: [ 1  1  4  2 24  1 30  3  1  6]
INFO:root:--------------------------
INFO:root:FL Epoch: 390 Training on worker :66
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 390 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :49
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 390 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :76
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 390 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 390 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :63
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 390 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 390 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :25
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.689386
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.669072
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 390 Norm Difference for worker 25 is 0.047525
INFO:root:FL Epoch: 390 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :20
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 390 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :33
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.684861
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.673353
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 390 Norm Difference for worker 33 is 0.04617
INFO:root:FL Epoch: 390 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :34
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 390 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 390 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :61
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 390 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :28
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 390 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 390 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 66
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 390 Ends   ===================
INFO:root:Epoch:390 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:390 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 391 Begins ===================
INFO:root:FL Epoch: 391 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 391 Workers Selected : [0, 1, 2, 17, 53, 9, 57, 38, 63, 10]
INFO:root:FL Epoch: 391 Fraction of points on each worker in this round: [0.31055901 0.31055901 0.31055901 0.00310559 0.00621118 0.0326087
 0.02018634 0.0015528  0.00310559 0.0015528 ]
INFO:root:FL Epoch: 391 Num points on workers: [200 200 200   2   4  21  13   1   2   1]
INFO:root:--------------------------
INFO:root:FL Epoch: 391 Training on worker :0
INFO:root:FL Epoch: 391 Using Learning rate : 0.004580481169412743 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689092
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694501
INFO:root:FL Epoch: 391 Worker: 0 Backdoor Test Loss: 0.722176859776179 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 391 Worker: 0 Backdoor Train Loss: 0.6891351759433746 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 391 Norm Difference for worker 0 is 0.057893
INFO:root:FL Epoch: 391 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1
INFO:root:FL Epoch: 391 Using Learning rate : 0.004580481169412743 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700839
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684534
INFO:root:FL Epoch: 391 Worker: 1 Backdoor Test Loss: 0.7253469228744507 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 391 Worker: 1 Backdoor Train Loss: 0.6887897789478302 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 391 Norm Difference for worker 1 is 0.061733
INFO:root:FL Epoch: 391 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :2
INFO:root:FL Epoch: 391 Using Learning rate : 0.004580481169412743 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700255
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687872
INFO:root:FL Epoch: 391 Worker: 2 Backdoor Test Loss: 0.7223740518093109 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 391 Worker: 2 Backdoor Train Loss: 0.688869959115982 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 391 Norm Difference for worker 2 is 0.060599
INFO:root:FL Epoch: 391 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :17
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 391 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 391 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :53
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 391 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 391 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :9
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.677071
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.670561
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 391 Norm Difference for worker 9 is 0.044675
INFO:root:FL Epoch: 391 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :57
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 391 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 391 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :38
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 391 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 391 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :63
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 391 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 391 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :10
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 391 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 391 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 17
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 391 Ends   ===================
INFO:root:Epoch:391 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:391 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 392 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 392 Workers Selected : [15, 11, 55, 66, 77, 65, 44, 93, 91, 23]
INFO:root:FL Epoch: 392 Fraction of points on each worker in this round: [0.04347826 0.13043478 0.04347826 0.04347826 0.04347826 0.04347826
 0.08695652 0.08695652 0.17391304 0.30434783]
INFO:root:FL Epoch: 392 Num points on workers: [1 3 1 1 1 1 2 2 4 7]
INFO:root:--------------------------
INFO:root:FL Epoch: 392 Training on worker :15
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 392 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :11
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 392 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 392 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :55
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 392 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :66
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 392 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :77
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 392 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :65
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 392 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :44
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 392 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 392 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :93
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 392 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 392 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :91
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 392 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 392 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :23
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 392 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 392 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 15
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 392 Ends   ===================
INFO:root:Epoch:392 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:392 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 393 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 393 Workers Selected : [17, 74, 91, 76, 80, 56, 97, 8, 28, 38]
INFO:root:FL Epoch: 393 Fraction of points on each worker in this round: [0.04081633 0.34693878 0.08163265 0.08163265 0.02040816 0.06122449
 0.20408163 0.02040816 0.12244898 0.02040816]
INFO:root:FL Epoch: 393 Num points on workers: [ 2 17  4  4  1  3 10  1  6  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 393 Training on worker :17
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 393 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 393 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :74
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 393 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 393 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :91
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 393 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 393 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :76
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 393 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 393 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :80
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 393 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :56
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 393 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 393 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :97
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 393 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 393 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :8
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 393 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :28
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 393 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 393 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :38
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 393 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 17
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 393 Ends   ===================
INFO:root:Epoch:393 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:393 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 394 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 394 Workers Selected : [52, 17, 48, 29, 6, 46, 14, 36, 65, 85]
INFO:root:FL Epoch: 394 Fraction of points on each worker in this round: [0.05555556 0.11111111 0.05555556 0.05555556 0.05555556 0.05555556
 0.33333333 0.11111111 0.05555556 0.11111111]
INFO:root:FL Epoch: 394 Num points on workers: [1 2 1 1 1 1 6 2 1 2]
INFO:root:--------------------------
INFO:root:FL Epoch: 394 Training on worker :52
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 394 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 394 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :17
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 394 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 394 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :48
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 394 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 394 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :29
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 394 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 394 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :6
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 394 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 394 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :46
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 394 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 394 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :14
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 394 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 394 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :36
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 394 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 394 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :65
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 394 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 394 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :85
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 394 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 394 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 52
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 394 Ends   ===================
INFO:root:Epoch:394 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:394 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 395 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 395 Workers Selected : [88, 37, 60, 5, 12, 64, 83, 26, 3, 51]
INFO:root:FL Epoch: 395 Fraction of points on each worker in this round: [0.03846154 0.03846154 0.11538462 0.34615385 0.03846154 0.11538462
 0.07692308 0.03846154 0.03846154 0.15384615]
INFO:root:FL Epoch: 395 Num points on workers: [1 1 3 9 1 3 2 1 1 4]
INFO:root:--------------------------
INFO:root:FL Epoch: 395 Training on worker :88
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 395 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :37
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 395 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :60
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 395 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 395 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :5
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 395 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 395 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :12
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 395 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :64
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 395 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 395 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :83
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 395 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 395 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :26
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 395 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :3
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 395 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :51
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 395 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 395 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 88
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 395 Ends   ===================
INFO:root:Epoch:395 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:395 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 396 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 396 Workers Selected : [24, 87, 81, 59, 36, 78, 34, 49, 62, 21]
INFO:root:FL Epoch: 396 Fraction of points on each worker in this round: [0.04109589 0.06849315 0.04109589 0.01369863 0.02739726 0.01369863
 0.04109589 0.01369863 0.04109589 0.69863014]
INFO:root:FL Epoch: 396 Num points on workers: [ 3  5  3  1  2  1  3  1  3 51]
INFO:root:--------------------------
INFO:root:FL Epoch: 396 Training on worker :24
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 396 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 396 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :87
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 396 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 396 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :81
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 396 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 396 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :59
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 396 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :36
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 396 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 396 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :78
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 396 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :34
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 396 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 396 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :49
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 396 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :62
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 396 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 396 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :21
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.698575
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.659867
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 396 Norm Difference for worker 21 is 0.151846
INFO:root:FL Epoch: 396 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 24
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 396 Ends   ===================
INFO:root:Epoch:396 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:396 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 397 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 397 Workers Selected : [64, 45, 34, 70, 59, 71, 54, 86, 56, 37]
INFO:root:FL Epoch: 397 Fraction of points on each worker in this round: [0.13636364 0.09090909 0.13636364 0.09090909 0.04545455 0.04545455
 0.04545455 0.22727273 0.13636364 0.04545455]
INFO:root:FL Epoch: 397 Num points on workers: [3 2 3 2 1 1 1 5 3 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 397 Training on worker :64
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 397 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 397 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :45
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 397 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 397 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :34
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 397 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 397 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :70
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 397 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 397 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :59
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 397 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :71
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 397 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :54
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 397 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :86
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 397 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 397 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :56
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 397 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 397 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :37
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 397 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 64
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 397 Ends   ===================
INFO:root:Epoch:397 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:397 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 398 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 398 Workers Selected : [51, 69, 82, 75, 63, 62, 89, 65, 22, 6]
INFO:root:FL Epoch: 398 Fraction of points on each worker in this round: [0.12121212 0.51515152 0.03030303 0.06060606 0.06060606 0.09090909
 0.03030303 0.03030303 0.03030303 0.03030303]
INFO:root:FL Epoch: 398 Num points on workers: [ 4 17  1  2  2  3  1  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 398 Training on worker :51
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 398 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 398 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :69
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 398 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 398 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :82
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 398 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 398 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :75
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 398 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 398 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :63
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 398 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 398 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :62
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 398 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 398 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :89
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 398 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 398 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :65
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 398 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 398 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :22
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 398 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 398 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :6
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 398 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 398 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 51
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 398 Ends   ===================
INFO:root:Epoch:398 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:398 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 399 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 399 Workers Selected : [57, 71, 76, 69, 82, 81, 97, 46, 35, 49]
INFO:root:FL Epoch: 399 Fraction of points on each worker in this round: [0.25       0.01923077 0.07692308 0.32692308 0.01923077 0.05769231
 0.19230769 0.01923077 0.01923077 0.01923077]
INFO:root:FL Epoch: 399 Num points on workers: [13  1  4 17  1  3 10  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 399 Training on worker :57
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 399 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 399 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :71
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 399 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :76
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 399 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 399 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :69
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 399 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 399 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :82
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 399 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :81
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 399 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 399 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :97
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 399 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 399 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :46
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 399 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :35
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 399 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :49
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 399 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 57
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 399 Ends   ===================
INFO:root:Epoch:399 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:399 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 400 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 400 Workers Selected : [89, 27, 16, 22, 12, 72, 68, 53, 92, 47]
INFO:root:FL Epoch: 400 Fraction of points on each worker in this round: [0.03448276 0.17241379 0.06896552 0.03448276 0.03448276 0.20689655
 0.06896552 0.13793103 0.13793103 0.10344828]
INFO:root:FL Epoch: 400 Num points on workers: [1 5 2 1 1 6 2 4 4 3]
INFO:root:--------------------------
INFO:root:FL Epoch: 400 Training on worker :89
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 400 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :27
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 400 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 400 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :16
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 400 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 400 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :22
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 400 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :12
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 400 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :72
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 400 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 400 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :68
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 400 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 400 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :53
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 400 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 400 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :92
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 400 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 400 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :47
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 400 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 400 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 89
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 400 Ends   ===================
INFO:root:Epoch:400 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:400 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 401 Begins ===================
INFO:root:FL Epoch: 401 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 401 Workers Selected : [0, 1, 2, 51, 7, 45, 54, 99, 21, 18]
INFO:root:FL Epoch: 401 Fraction of points on each worker in this round: [0.3003003  0.3003003  0.3003003  0.00600601 0.0015015  0.003003
 0.0015015  0.0045045  0.07657658 0.00600601]
INFO:root:FL Epoch: 401 Num points on workers: [200 200 200   4   1   2   1   3  51   4]
INFO:root:--------------------------
INFO:root:FL Epoch: 401 Training on worker :0
INFO:root:FL Epoch: 401 Using Learning rate : 0.004489691650726601 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691679
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698793
INFO:root:FL Epoch: 401 Worker: 0 Backdoor Test Loss: 0.7205002109209696 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 401 Worker: 0 Backdoor Train Loss: 0.6893047153949737 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 401 Norm Difference for worker 0 is 0.056376
INFO:root:FL Epoch: 401 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1
INFO:root:FL Epoch: 401 Using Learning rate : 0.004489691650726601 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692579
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693150
INFO:root:FL Epoch: 401 Worker: 1 Backdoor Test Loss: 0.7253066301345825 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 401 Worker: 1 Backdoor Train Loss: 0.6887081980705261 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 401 Norm Difference for worker 1 is 0.062412
INFO:root:FL Epoch: 401 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :2
INFO:root:FL Epoch: 401 Using Learning rate : 0.004489691650726601 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695874
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688608
INFO:root:FL Epoch: 401 Worker: 2 Backdoor Test Loss: 0.7276389102141062 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 401 Worker: 2 Backdoor Train Loss: 0.6884954750537873 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 401 Norm Difference for worker 2 is 0.064998
INFO:root:FL Epoch: 401 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :51
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 401 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 401 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :7
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 401 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 401 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :45
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 401 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 401 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :54
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 401 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 401 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :99
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 401 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 401 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :21
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.696953
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.657271
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 401 Norm Difference for worker 21 is 0.149202
INFO:root:FL Epoch: 401 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :18
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 401 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 401 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 51
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 401 Ends   ===================
INFO:root:Epoch:401 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:401 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 402 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 402 Workers Selected : [53, 16, 8, 60, 43, 86, 4, 64, 73, 23]
INFO:root:FL Epoch: 402 Fraction of points on each worker in this round: [0.14285714 0.07142857 0.03571429 0.10714286 0.03571429 0.17857143
 0.03571429 0.10714286 0.03571429 0.25      ]
INFO:root:FL Epoch: 402 Num points on workers: [4 2 1 3 1 5 1 3 1 7]
INFO:root:--------------------------
INFO:root:FL Epoch: 402 Training on worker :53
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 402 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 402 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :16
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 402 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 402 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :8
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 402 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 402 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :60
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 402 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 402 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :43
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 402 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 402 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :86
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 402 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 402 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :4
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 402 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 402 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :64
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 402 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 402 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :73
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 402 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 402 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :23
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 402 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 402 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 53
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 402 Ends   ===================
INFO:root:Epoch:402 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:402 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 403 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 403 Workers Selected : [78, 97, 48, 45, 75, 55, 83, 86, 95, 30]
INFO:root:FL Epoch: 403 Fraction of points on each worker in this round: [0.03703704 0.37037037 0.03703704 0.07407407 0.07407407 0.03703704
 0.07407407 0.18518519 0.03703704 0.07407407]
INFO:root:FL Epoch: 403 Num points on workers: [ 1 10  1  2  2  1  2  5  1  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 403 Training on worker :78
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 403 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 403 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :97
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 403 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 403 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :48
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 403 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 403 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :45
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 403 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 403 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :75
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 403 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 403 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :55
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 403 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 403 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :83
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 403 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 403 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :86
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 403 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 403 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :95
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 403 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 403 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :30
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 403 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 403 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 403 Ends   ===================
INFO:root:Epoch:403 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:403 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 404 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 404 Workers Selected : [18, 94, 74, 30, 22, 63, 42, 52, 10, 79]
INFO:root:FL Epoch: 404 Fraction of points on each worker in this round: [0.05479452 0.54794521 0.23287671 0.02739726 0.01369863 0.02739726
 0.04109589 0.01369863 0.01369863 0.02739726]
INFO:root:FL Epoch: 404 Num points on workers: [ 4 40 17  2  1  2  3  1  1  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 404 Training on worker :18
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 404 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 404 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :94
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.692323
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.661610
INFO:root:FL Epoch: 404 Norm Difference for worker 94 is 0.137784
INFO:root:FL Epoch: 404 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :74
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 404 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 404 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :30
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 404 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 404 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :22
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 404 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 404 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :63
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 404 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 404 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :42
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 404 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 404 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :52
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 404 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 404 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :10
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 404 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 404 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :79
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 404 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 404 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 18
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 404 Ends   ===================
INFO:root:Epoch:404 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:404 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 405 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 405 Workers Selected : [42, 83, 27, 55, 67, 12, 6, 77, 47, 46]
INFO:root:FL Epoch: 405 Fraction of points on each worker in this round: [0.1        0.06666667 0.16666667 0.03333333 0.4        0.03333333
 0.03333333 0.03333333 0.1        0.03333333]
INFO:root:FL Epoch: 405 Num points on workers: [ 3  2  5  1 12  1  1  1  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 405 Training on worker :42
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 405 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 405 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :83
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 405 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 405 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :27
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 405 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 405 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :55
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 405 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :67
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 405 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 405 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :12
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 405 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :6
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 405 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :77
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 405 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :47
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 405 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 405 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :46
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 405 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 405 Ends   ===================
INFO:root:Epoch:405 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:405 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 406 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 406 Workers Selected : [33, 49, 12, 39, 29, 84, 86, 80, 18, 38]
INFO:root:FL Epoch: 406 Fraction of points on each worker in this round: [0.43478261 0.01449275 0.01449275 0.1884058  0.01449275 0.17391304
 0.07246377 0.01449275 0.05797101 0.01449275]
INFO:root:FL Epoch: 406 Num points on workers: [30  1  1 13  1 12  5  1  4  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 406 Training on worker :33
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.682065
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.676826
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 406 Norm Difference for worker 33 is 0.044458
INFO:root:FL Epoch: 406 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :49
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 406 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 406 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :12
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 406 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 406 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :39
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 406 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 406 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :29
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 406 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 406 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :84
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 406 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 406 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :86
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 406 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 406 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :80
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 406 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 406 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :18
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 406 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 406 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :38
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 406 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 406 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 49
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 406 Ends   ===================
INFO:root:Epoch:406 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:406 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 407 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 407 Workers Selected : [3, 21, 90, 99, 62, 69, 15, 53, 76, 65]
INFO:root:FL Epoch: 407 Fraction of points on each worker in this round: [0.01149425 0.5862069  0.02298851 0.03448276 0.03448276 0.1954023
 0.01149425 0.04597701 0.04597701 0.01149425]
INFO:root:FL Epoch: 407 Num points on workers: [ 1 51  2  3  3 17  1  4  4  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 407 Training on worker :3
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 407 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 407 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :21
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.695619
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.663986
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 407 Norm Difference for worker 21 is 0.148661
INFO:root:FL Epoch: 407 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :90
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 407 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 407 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :99
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 407 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 407 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :62
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 407 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 407 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :69
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 407 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 407 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :15
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 407 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 407 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :53
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 407 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 407 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :76
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 407 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 407 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :65
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 407 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 407 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 3
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 407 Ends   ===================
INFO:root:Epoch:407 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:407 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 408 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 408 Workers Selected : [15, 22, 97, 83, 30, 56, 37, 68, 78, 31]
INFO:root:FL Epoch: 408 Fraction of points on each worker in this round: [0.04166667 0.04166667 0.41666667 0.08333333 0.08333333 0.125
 0.04166667 0.08333333 0.04166667 0.04166667]
INFO:root:FL Epoch: 408 Num points on workers: [ 1  1 10  2  2  3  1  2  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 408 Training on worker :15
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 408 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 408 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :22
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 408 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 408 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :97
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 408 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 408 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :83
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 408 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 408 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :30
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 408 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 408 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :56
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 408 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 408 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :37
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 408 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 408 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :68
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 408 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 408 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :78
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 408 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 408 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :31
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 408 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 408 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 15
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 408 Ends   ===================
INFO:root:Epoch:408 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:408 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 409 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 409 Workers Selected : [24, 87, 48, 17, 47, 78, 21, 31, 49, 89]
INFO:root:FL Epoch: 409 Fraction of points on each worker in this round: [0.04347826 0.07246377 0.01449275 0.02898551 0.04347826 0.01449275
 0.73913043 0.01449275 0.01449275 0.01449275]
INFO:root:FL Epoch: 409 Num points on workers: [ 3  5  1  2  3  1 51  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 409 Training on worker :24
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 409 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 409 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :87
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 409 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 409 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :48
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 409 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 409 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :17
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 409 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 409 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :47
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 409 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 409 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :78
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 409 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 409 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :21
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.703310
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.666693
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 409 Norm Difference for worker 21 is 0.150422
INFO:root:FL Epoch: 409 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :31
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 409 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 409 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :49
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 409 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 409 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :89
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 409 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 409 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 24
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 409 Ends   ===================
INFO:root:Epoch:409 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:409 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 410 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 410 Workers Selected : [94, 90, 52, 37, 27, 35, 67, 26, 73, 44]
INFO:root:FL Epoch: 410 Fraction of points on each worker in this round: [0.60606061 0.03030303 0.01515152 0.01515152 0.07575758 0.01515152
 0.18181818 0.01515152 0.01515152 0.03030303]
INFO:root:FL Epoch: 410 Num points on workers: [40  2  1  1  5  1 12  1  1  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 410 Training on worker :94
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.690208
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.662864
INFO:root:FL Epoch: 410 Norm Difference for worker 94 is 0.137126
INFO:root:FL Epoch: 410 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :90
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 410 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 410 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :52
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 410 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :37
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 410 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :27
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 410 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 410 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :35
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 410 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :67
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 410 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 410 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :26
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 410 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :73
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 410 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :44
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 410 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 410 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 90
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 410 Ends   ===================
INFO:root:Epoch:410 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:410 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 411 Begins ===================
INFO:root:FL Epoch: 411 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 411 Workers Selected : [0, 1, 2, 71, 47, 62, 34, 80, 20, 65]
INFO:root:FL Epoch: 411 Fraction of points on each worker in this round: [0.32626427 0.32626427 0.32626427 0.00163132 0.00489396 0.00489396
 0.00489396 0.00163132 0.00163132 0.00163132]
INFO:root:FL Epoch: 411 Num points on workers: [200 200 200   1   3   3   3   1   1   1]
INFO:root:--------------------------
INFO:root:FL Epoch: 411 Training on worker :0
INFO:root:FL Epoch: 411 Using Learning rate : 0.004400701667154434 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700248
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689941
INFO:root:FL Epoch: 411 Worker: 0 Backdoor Test Loss: 0.7257333000500997 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 411 Worker: 0 Backdoor Train Loss: 0.6888331651687623 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 411 Norm Difference for worker 0 is 0.061121
INFO:root:FL Epoch: 411 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1
INFO:root:FL Epoch: 411 Using Learning rate : 0.004400701667154434 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692282
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688762
INFO:root:FL Epoch: 411 Worker: 1 Backdoor Test Loss: 0.7227583726247152 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 411 Worker: 1 Backdoor Train Loss: 0.6891148030757904 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 411 Norm Difference for worker 1 is 0.057984
INFO:root:FL Epoch: 411 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :2
INFO:root:FL Epoch: 411 Using Learning rate : 0.004400701667154434 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695743
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684229
INFO:root:FL Epoch: 411 Worker: 2 Backdoor Test Loss: 0.7196662624677023 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 411 Worker: 2 Backdoor Train Loss: 0.6894200444221497 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 411 Norm Difference for worker 2 is 0.054692
INFO:root:FL Epoch: 411 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :71
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 411 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 411 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :47
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 411 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 411 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :62
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 411 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 411 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :34
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 411 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 411 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :80
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 411 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 411 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :20
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 411 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 411 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :65
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 411 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 411 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 71
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 411 Ends   ===================
INFO:root:Epoch:411 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:411 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 412 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 412 Workers Selected : [74, 61, 57, 94, 39, 36, 71, 37, 19, 66]
INFO:root:FL Epoch: 412 Fraction of points on each worker in this round: [0.18888889 0.01111111 0.14444444 0.44444444 0.14444444 0.02222222
 0.01111111 0.01111111 0.01111111 0.01111111]
INFO:root:FL Epoch: 412 Num points on workers: [17  1 13 40 13  2  1  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 412 Training on worker :74
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 412 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 412 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :61
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 412 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 412 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :57
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 412 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 412 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :94
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.693477
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.667111
INFO:root:FL Epoch: 412 Norm Difference for worker 94 is 0.135285
INFO:root:FL Epoch: 412 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :39
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 412 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 412 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :36
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 412 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 412 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :71
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 412 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 412 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :37
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 412 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 412 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :19
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 412 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 412 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :66
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 412 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 412 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 74
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 412 Ends   ===================
INFO:root:Epoch:412 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:412 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 413 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 413 Workers Selected : [48, 7, 72, 84, 67, 32, 50, 40, 14, 35]
INFO:root:FL Epoch: 413 Fraction of points on each worker in this round: [0.02222222 0.02222222 0.13333333 0.26666667 0.26666667 0.08888889
 0.02222222 0.02222222 0.13333333 0.02222222]
INFO:root:FL Epoch: 413 Num points on workers: [ 1  1  6 12 12  4  1  1  6  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 413 Training on worker :48
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 413 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 413 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :7
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 413 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 413 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :72
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 413 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 413 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :84
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 413 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 413 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :67
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 413 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 413 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :32
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 413 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 413 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :50
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 413 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 413 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :40
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 413 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 413 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :14
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 413 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 413 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :35
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 413 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 413 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 48
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 413 Ends   ===================
INFO:root:Epoch:413 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:413 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 414 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 414 Workers Selected : [49, 39, 72, 11, 54, 36, 29, 17, 77, 22]
INFO:root:FL Epoch: 414 Fraction of points on each worker in this round: [0.03225806 0.41935484 0.19354839 0.09677419 0.03225806 0.06451613
 0.03225806 0.06451613 0.03225806 0.03225806]
INFO:root:FL Epoch: 414 Num points on workers: [ 1 13  6  3  1  2  1  2  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 414 Training on worker :49
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 414 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 414 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :39
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 414 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 414 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :72
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 414 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 414 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :11
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 414 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 414 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :54
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 414 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 414 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :36
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 414 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 414 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :29
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 414 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 414 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :17
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 414 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 414 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :77
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 414 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 414 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :22
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 414 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 414 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 49
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 414 Ends   ===================
INFO:root:Epoch:414 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:414 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 415 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 415 Workers Selected : [62, 55, 51, 63, 91, 20, 95, 13, 82, 42]
INFO:root:FL Epoch: 415 Fraction of points on each worker in this round: [0.125      0.04166667 0.16666667 0.08333333 0.16666667 0.04166667
 0.04166667 0.16666667 0.04166667 0.125     ]
INFO:root:FL Epoch: 415 Num points on workers: [3 1 4 2 4 1 1 4 1 3]
INFO:root:--------------------------
INFO:root:FL Epoch: 415 Training on worker :62
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 415 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 415 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :55
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 415 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :51
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 415 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 415 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :63
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 415 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 415 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :91
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 415 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 415 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :20
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 415 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :95
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 415 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :13
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 415 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 415 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :82
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 415 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :42
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 415 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 415 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 62
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 415 Ends   ===================
INFO:root:Epoch:415 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:415 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 416 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 416 Workers Selected : [87, 30, 77, 53, 73, 75, 14, 76, 44, 20]
INFO:root:FL Epoch: 416 Fraction of points on each worker in this round: [0.17857143 0.07142857 0.03571429 0.14285714 0.03571429 0.07142857
 0.21428571 0.14285714 0.07142857 0.03571429]
INFO:root:FL Epoch: 416 Num points on workers: [5 2 1 4 1 2 6 4 2 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 416 Training on worker :87
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 416 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 416 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :30
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 416 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 416 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :77
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 416 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :53
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 416 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 416 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :73
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 416 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :75
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 416 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 416 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :14
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 416 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 416 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :76
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 416 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 416 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :44
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 416 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 416 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :20
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 416 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 87
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 416 Ends   ===================
INFO:root:Epoch:416 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:416 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 417 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 417 Workers Selected : [93, 43, 7, 99, 13, 40, 39, 83, 67, 24]
INFO:root:FL Epoch: 417 Fraction of points on each worker in this round: [0.04761905 0.02380952 0.02380952 0.07142857 0.0952381  0.02380952
 0.30952381 0.04761905 0.28571429 0.07142857]
INFO:root:FL Epoch: 417 Num points on workers: [ 2  1  1  3  4  1 13  2 12  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 417 Training on worker :93
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 417 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 417 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :43
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 417 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 417 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :7
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 417 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 417 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :99
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 417 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 417 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :13
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 417 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 417 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :40
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 417 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 417 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :39
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 417 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 417 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :83
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 417 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 417 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :67
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 417 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 417 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :24
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 417 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 417 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 93
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 417 Ends   ===================
INFO:root:Epoch:417 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:417 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 418 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 418 Workers Selected : [3, 62, 6, 37, 40, 16, 42, 98, 72, 71]
INFO:root:FL Epoch: 418 Fraction of points on each worker in this round: [0.05 0.15 0.05 0.05 0.05 0.1  0.15 0.05 0.3  0.05]
INFO:root:FL Epoch: 418 Num points on workers: [1 3 1 1 1 2 3 1 6 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 418 Training on worker :3
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 418 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :62
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 418 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 418 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :6
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 418 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :37
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 418 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :40
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 418 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :16
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 418 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 418 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :42
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 418 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 418 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :98
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 418 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :72
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 418 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 418 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :71
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 418 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 3
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 418 Ends   ===================
INFO:root:Epoch:418 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:418 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 419 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 419 Workers Selected : [18, 16, 52, 71, 17, 7, 28, 44, 11, 12]
INFO:root:FL Epoch: 419 Fraction of points on each worker in this round: [0.17391304 0.08695652 0.04347826 0.04347826 0.08695652 0.04347826
 0.26086957 0.08695652 0.13043478 0.04347826]
INFO:root:FL Epoch: 419 Num points on workers: [4 2 1 1 2 1 6 2 3 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 419 Training on worker :18
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 419 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 419 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :16
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 419 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 419 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :52
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 419 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :71
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 419 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :17
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 419 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 419 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :7
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 419 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :28
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 419 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 419 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :44
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 419 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 419 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :11
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 419 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 419 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :12
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 419 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 18
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 419 Ends   ===================
INFO:root:Epoch:419 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:419 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 420 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 420 Workers Selected : [23, 58, 35, 44, 5, 81, 36, 66, 65, 71]
INFO:root:FL Epoch: 420 Fraction of points on each worker in this round: [0.15555556 0.4        0.02222222 0.04444444 0.2        0.06666667
 0.04444444 0.02222222 0.02222222 0.02222222]
INFO:root:FL Epoch: 420 Num points on workers: [ 7 18  1  2  9  3  2  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 420 Training on worker :23
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 420 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 420 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :58
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 420 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 420 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :35
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 420 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 420 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :44
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 420 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 420 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :5
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 420 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 420 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :81
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 420 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 420 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :36
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 420 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 420 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :66
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 420 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 420 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :65
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 420 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 420 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :71
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 420 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 420 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 23
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 420 Ends   ===================
INFO:root:Epoch:420 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:420 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 421 Begins ===================
INFO:root:FL Epoch: 421 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 421 Workers Selected : [0, 1, 2, 99, 29, 60, 89, 63, 53, 98]
INFO:root:FL Epoch: 421 Fraction of points on each worker in this round: [0.32520325 0.32520325 0.32520325 0.00487805 0.00162602 0.00487805
 0.00162602 0.00325203 0.00650407 0.00162602]
INFO:root:FL Epoch: 421 Num points on workers: [200 200 200   3   1   3   1   2   4   1]
INFO:root:--------------------------
INFO:root:FL Epoch: 421 Training on worker :0
INFO:root:FL Epoch: 421 Using Learning rate : 0.004313475550188762 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690982
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695217
INFO:root:FL Epoch: 421 Worker: 0 Backdoor Test Loss: 0.7213160395622253 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 421 Worker: 0 Backdoor Train Loss: 0.6892990946769715 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 421 Norm Difference for worker 0 is 0.056122
INFO:root:FL Epoch: 421 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1
INFO:root:FL Epoch: 421 Using Learning rate : 0.004313475550188762 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692583
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694171
INFO:root:FL Epoch: 421 Worker: 1 Backdoor Test Loss: 0.7275153696537018 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 421 Worker: 1 Backdoor Train Loss: 0.688834685087204 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 421 Norm Difference for worker 1 is 0.061747
INFO:root:FL Epoch: 421 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :2
INFO:root:FL Epoch: 421 Using Learning rate : 0.004313475550188762 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696981
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689336
INFO:root:FL Epoch: 421 Worker: 2 Backdoor Test Loss: 0.7253378927707672 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 421 Worker: 2 Backdoor Train Loss: 0.689026701450348 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 421 Norm Difference for worker 2 is 0.059305
INFO:root:FL Epoch: 421 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :99
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 421 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 421 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :29
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 421 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :60
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 421 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 421 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :89
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 421 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :63
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 421 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 421 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :53
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 421 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 421 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :98
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 421 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 99
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 421 Ends   ===================
INFO:root:Epoch:421 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:421 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 422 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 422 Workers Selected : [60, 74, 86, 96, 85, 17, 7, 22, 34, 52]
INFO:root:FL Epoch: 422 Fraction of points on each worker in this round: [0.08333333 0.47222222 0.13888889 0.02777778 0.05555556 0.05555556
 0.02777778 0.02777778 0.08333333 0.02777778]
INFO:root:FL Epoch: 422 Num points on workers: [ 3 17  5  1  2  2  1  1  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 422 Training on worker :60
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 422 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 422 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :74
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 422 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 422 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :86
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 422 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 422 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :96
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 422 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 422 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :85
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 422 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 422 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :17
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 422 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 422 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :7
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 422 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 422 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :22
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 422 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 422 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :34
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 422 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 422 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :52
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 422 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 422 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 60
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 422 Ends   ===================
INFO:root:Epoch:422 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:422 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 423 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 423 Workers Selected : [73, 48, 53, 74, 47, 64, 93, 39, 55, 56]
INFO:root:FL Epoch: 423 Fraction of points on each worker in this round: [0.02083333 0.02083333 0.08333333 0.35416667 0.0625     0.0625
 0.04166667 0.27083333 0.02083333 0.0625    ]
INFO:root:FL Epoch: 423 Num points on workers: [ 1  1  4 17  3  3  2 13  1  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 423 Training on worker :73
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 423 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :48
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 423 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :53
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 423 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 423 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :74
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 423 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 423 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :47
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 423 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 423 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :64
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 423 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 423 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :93
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 423 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 423 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :39
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 423 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 423 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :55
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 423 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :56
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 423 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 423 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 73
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 423 Ends   ===================
INFO:root:Epoch:423 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:423 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 424 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 424 Workers Selected : [47, 48, 82, 61, 66, 55, 80, 63, 40, 5]
INFO:root:FL Epoch: 424 Fraction of points on each worker in this round: [0.14285714 0.04761905 0.04761905 0.04761905 0.04761905 0.04761905
 0.04761905 0.0952381  0.04761905 0.42857143]
INFO:root:FL Epoch: 424 Num points on workers: [3 1 1 1 1 1 1 2 1 9]
INFO:root:--------------------------
INFO:root:FL Epoch: 424 Training on worker :47
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 424 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 424 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :48
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 424 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :82
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 424 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :61
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 424 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :66
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 424 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :55
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 424 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :80
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 424 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :63
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 424 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 424 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :40
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 424 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :5
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 424 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 424 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 47
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 424 Ends   ===================
INFO:root:Epoch:424 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:424 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 425 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 425 Workers Selected : [61, 39, 34, 89, 85, 35, 14, 53, 79, 65]
INFO:root:FL Epoch: 425 Fraction of points on each worker in this round: [0.02941176 0.38235294 0.08823529 0.02941176 0.05882353 0.02941176
 0.17647059 0.11764706 0.05882353 0.02941176]
INFO:root:FL Epoch: 425 Num points on workers: [ 1 13  3  1  2  1  6  4  2  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 425 Training on worker :61
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 425 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :39
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 425 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 425 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :34
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 425 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 425 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :89
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 425 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :85
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 425 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 425 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :35
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 425 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :14
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 425 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 425 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :53
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 425 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 425 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :79
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 425 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 425 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :65
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 425 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 61
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 425 Ends   ===================
INFO:root:Epoch:425 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:425 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 426 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 426 Workers Selected : [40, 65, 11, 51, 70, 25, 21, 77, 90, 36]
INFO:root:FL Epoch: 426 Fraction of points on each worker in this round: [0.01098901 0.01098901 0.03296703 0.04395604 0.02197802 0.26373626
 0.56043956 0.01098901 0.02197802 0.02197802]
INFO:root:FL Epoch: 426 Num points on workers: [ 1  1  3  4  2 24 51  1  2  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 426 Training on worker :40
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 426 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 426 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :65
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 426 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 426 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :11
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 426 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 426 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :51
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 426 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 426 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :70
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 426 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 426 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :25
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.685381
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.676079
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 426 Norm Difference for worker 25 is 0.044347
INFO:root:FL Epoch: 426 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :21
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.694821
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.667001
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 426 Norm Difference for worker 21 is 0.144017
INFO:root:FL Epoch: 426 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :77
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 426 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 426 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :90
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 426 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 426 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :36
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 426 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 426 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 40
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 426 Ends   ===================
INFO:root:Epoch:426 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:426 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 427 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 427 Workers Selected : [71, 16, 69, 46, 54, 17, 22, 59, 97, 26]
INFO:root:FL Epoch: 427 Fraction of points on each worker in this round: [0.02702703 0.05405405 0.45945946 0.02702703 0.02702703 0.05405405
 0.02702703 0.02702703 0.27027027 0.02702703]
INFO:root:FL Epoch: 427 Num points on workers: [ 1  2 17  1  1  2  1  1 10  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 427 Training on worker :71
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 427 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :16
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 427 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 427 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :69
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 427 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 427 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :46
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 427 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :54
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 427 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :17
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 427 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 427 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :22
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 427 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :59
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 427 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :97
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 427 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 427 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :26
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 427 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 71
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 427 Ends   ===================
INFO:root:Epoch:427 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:427 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 428 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 428 Workers Selected : [14, 71, 49, 39, 54, 78, 67, 93, 55, 5]
INFO:root:FL Epoch: 428 Fraction of points on each worker in this round: [0.12765957 0.0212766  0.0212766  0.27659574 0.0212766  0.0212766
 0.25531915 0.04255319 0.0212766  0.19148936]
INFO:root:FL Epoch: 428 Num points on workers: [ 6  1  1 13  1  1 12  2  1  9]
INFO:root:--------------------------
INFO:root:FL Epoch: 428 Training on worker :14
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 428 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 428 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :71
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 428 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :49
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 428 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :39
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 428 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 428 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :54
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 428 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :78
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 428 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :67
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 428 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 428 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :93
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 428 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 428 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :55
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 428 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :5
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 428 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 428 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 14
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 428 Ends   ===================
INFO:root:Epoch:428 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:428 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 429 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 429 Workers Selected : [45, 61, 78, 20, 60, 48, 71, 23, 22, 16]
INFO:root:FL Epoch: 429 Fraction of points on each worker in this round: [0.1  0.05 0.05 0.05 0.15 0.05 0.05 0.35 0.05 0.1 ]
INFO:root:FL Epoch: 429 Num points on workers: [2 1 1 1 3 1 1 7 1 2]
INFO:root:--------------------------
INFO:root:FL Epoch: 429 Training on worker :45
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 429 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 429 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :61
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 429 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 429 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :78
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 429 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 429 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :20
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 429 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 429 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :60
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 429 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 429 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :48
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 429 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 429 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :71
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 429 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 429 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :23
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 429 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 429 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :22
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 429 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 429 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :16
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 429 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 429 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 45
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 429 Ends   ===================
INFO:root:Epoch:429 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:429 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 430 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 430 Workers Selected : [61, 3, 26, 19, 98, 52, 58, 14, 46, 47]
INFO:root:FL Epoch: 430 Fraction of points on each worker in this round: [0.02941176 0.02941176 0.02941176 0.02941176 0.02941176 0.02941176
 0.52941176 0.17647059 0.02941176 0.08823529]
INFO:root:FL Epoch: 430 Num points on workers: [ 1  1  1  1  1  1 18  6  1  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 430 Training on worker :61
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 430 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :3
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 430 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :26
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 430 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :19
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 430 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :98
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 430 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :52
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 430 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :58
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 430 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 430 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :14
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 430 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 430 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :46
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 430 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :47
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 430 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 430 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 61
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 430 Ends   ===================
INFO:root:Epoch:430 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:430 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 431 Begins ===================
INFO:root:FL Epoch: 431 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 431 Workers Selected : [0, 1, 2, 14, 5, 68, 34, 49, 92, 12]
INFO:root:FL Epoch: 431 Fraction of points on each worker in this round: [0.31948882 0.31948882 0.31948882 0.00958466 0.014377   0.00319489
 0.00479233 0.00159744 0.00638978 0.00159744]
INFO:root:FL Epoch: 431 Num points on workers: [200 200 200   6   9   2   3   1   4   1]
INFO:root:--------------------------
INFO:root:FL Epoch: 431 Training on worker :0
INFO:root:FL Epoch: 431 Using Learning rate : 0.004227978338306044 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699984
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692928
INFO:root:FL Epoch: 431 Worker: 0 Backdoor Test Loss: 0.7245814899603525 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 431 Worker: 0 Backdoor Train Loss: 0.6890473186969757 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 431 Norm Difference for worker 0 is 0.058785
INFO:root:FL Epoch: 431 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1
INFO:root:FL Epoch: 431 Using Learning rate : 0.004227978338306044 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701002
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689510
INFO:root:FL Epoch: 431 Worker: 1 Backdoor Test Loss: 0.722262978553772 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 431 Worker: 1 Backdoor Train Loss: 0.6892385601997375 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 431 Norm Difference for worker 1 is 0.056678
INFO:root:FL Epoch: 431 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :2
INFO:root:FL Epoch: 431 Using Learning rate : 0.004227978338306044 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692347
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690396
INFO:root:FL Epoch: 431 Worker: 2 Backdoor Test Loss: 0.7246914207935333 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 431 Worker: 2 Backdoor Train Loss: 0.6889839351177216 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 431 Norm Difference for worker 2 is 0.059287
INFO:root:FL Epoch: 431 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :14
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 431 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 431 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :5
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 431 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 431 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :68
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 431 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 431 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :34
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 431 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 431 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :49
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 431 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 431 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :92
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 431 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 431 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :12
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 431 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 431 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 14
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 431 Ends   ===================
INFO:root:Epoch:431 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:431 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 432 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 432 Workers Selected : [68, 20, 19, 75, 83, 70, 51, 80, 17, 47]
INFO:root:FL Epoch: 432 Fraction of points on each worker in this round: [0.1  0.05 0.05 0.1  0.1  0.1  0.2  0.05 0.1  0.15]
INFO:root:FL Epoch: 432 Num points on workers: [2 1 1 2 2 2 4 1 2 3]
INFO:root:--------------------------
INFO:root:FL Epoch: 432 Training on worker :68
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 432 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 432 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :20
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 432 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 432 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :19
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 432 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 432 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :75
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 432 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 432 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :83
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 432 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 432 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :70
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 432 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 432 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :51
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 432 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 432 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :80
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 432 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 432 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :17
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 432 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 432 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :47
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 432 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 432 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 68
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 432 Ends   ===================
INFO:root:Epoch:432 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:432 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 433 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 433 Workers Selected : [70, 4, 83, 7, 38, 26, 12, 40, 33, 18]
INFO:root:FL Epoch: 433 Fraction of points on each worker in this round: [0.04545455 0.02272727 0.04545455 0.02272727 0.02272727 0.02272727
 0.02272727 0.02272727 0.68181818 0.09090909]
INFO:root:FL Epoch: 433 Num points on workers: [ 2  1  2  1  1  1  1  1 30  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 433 Training on worker :70
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 433 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 433 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :4
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 433 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :83
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 433 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 433 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :7
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 433 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :38
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 433 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :26
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 433 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :12
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 433 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :40
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 433 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :33
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.688264
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.679898
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 433 Norm Difference for worker 33 is 0.042785
INFO:root:FL Epoch: 433 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :18
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 433 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 433 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 433 Ends   ===================
INFO:root:Epoch:433 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:433 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 434 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 434 Workers Selected : [82, 72, 19, 4, 95, 86, 94, 27, 77, 45]
INFO:root:FL Epoch: 434 Fraction of points on each worker in this round: [0.01587302 0.0952381  0.01587302 0.01587302 0.01587302 0.07936508
 0.63492063 0.07936508 0.01587302 0.03174603]
INFO:root:FL Epoch: 434 Num points on workers: [ 1  6  1  1  1  5 40  5  1  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 434 Training on worker :82
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 434 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :72
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 434 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 434 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :19
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 434 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :4
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 434 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :95
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 434 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :86
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 434 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 434 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :94
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.689985
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.664675
INFO:root:FL Epoch: 434 Norm Difference for worker 94 is 0.131017
INFO:root:FL Epoch: 434 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :27
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 434 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 434 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :77
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 434 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :45
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 434 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 434 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 82
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 434 Ends   ===================
INFO:root:Epoch:434 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:434 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 435 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 435 Workers Selected : [84, 79, 71, 33, 86, 36, 4, 96, 73, 6]
INFO:root:FL Epoch: 435 Fraction of points on each worker in this round: [0.21428571 0.03571429 0.01785714 0.53571429 0.08928571 0.03571429
 0.01785714 0.01785714 0.01785714 0.01785714]
INFO:root:FL Epoch: 435 Num points on workers: [12  2  1 30  5  2  1  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 435 Training on worker :84
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 435 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 435 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :79
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 435 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 435 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :71
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 435 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 435 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :33
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.687301
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.677960
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 435 Norm Difference for worker 33 is 0.042435
INFO:root:FL Epoch: 435 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :86
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 435 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 435 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :36
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 435 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 435 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :4
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 435 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 435 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :96
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 435 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 435 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :73
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 435 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 435 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :6
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 435 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 435 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 84
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 435 Ends   ===================
INFO:root:Epoch:435 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:435 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 436 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 436 Workers Selected : [67, 16, 14, 60, 82, 94, 21, 80, 63, 68]
INFO:root:FL Epoch: 436 Fraction of points on each worker in this round: [0.1        0.01666667 0.05       0.025      0.00833333 0.33333333
 0.425      0.00833333 0.01666667 0.01666667]
INFO:root:FL Epoch: 436 Num points on workers: [12  2  6  3  1 40 51  1  2  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 436 Training on worker :67
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 436 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 436 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :16
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 436 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 436 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :14
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 436 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 436 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :60
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 436 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 436 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :82
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 436 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :94
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.691297
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.662651
INFO:root:FL Epoch: 436 Norm Difference for worker 94 is 0.130603
INFO:root:FL Epoch: 436 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :21
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.694900
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.663520
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 436 Norm Difference for worker 21 is 0.139869
INFO:root:FL Epoch: 436 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :80
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 436 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :63
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 436 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 436 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :68
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 436 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 436 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 67
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 436 Ends   ===================
INFO:root:Epoch:436 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:436 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 437 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 437 Workers Selected : [24, 64, 63, 88, 76, 83, 80, 66, 12, 25]
INFO:root:FL Epoch: 437 Fraction of points on each worker in this round: [0.07142857 0.07142857 0.04761905 0.02380952 0.0952381  0.04761905
 0.02380952 0.02380952 0.02380952 0.57142857]
INFO:root:FL Epoch: 437 Num points on workers: [ 3  3  2  1  4  2  1  1  1 24]
INFO:root:--------------------------
INFO:root:FL Epoch: 437 Training on worker :24
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 437 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 437 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :64
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 437 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 437 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :63
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 437 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 437 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :88
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 437 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :76
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 437 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 437 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :83
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 437 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 437 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :80
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 437 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :66
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 437 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :12
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 437 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :25
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.690664
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.677834
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 437 Norm Difference for worker 25 is 0.043778
INFO:root:FL Epoch: 437 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 24
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 437 Ends   ===================
INFO:root:Epoch:437 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:437 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 438 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 438 Workers Selected : [92, 78, 34, 31, 67, 62, 51, 35, 11, 95]
INFO:root:FL Epoch: 438 Fraction of points on each worker in this round: [0.12121212 0.03030303 0.09090909 0.03030303 0.36363636 0.09090909
 0.12121212 0.03030303 0.09090909 0.03030303]
INFO:root:FL Epoch: 438 Num points on workers: [ 4  1  3  1 12  3  4  1  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 438 Training on worker :92
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 438 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 438 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :78
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 438 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 438 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :34
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 438 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 438 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :31
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 438 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 438 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :67
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 438 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 438 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :62
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 438 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 438 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :51
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 438 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 438 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :35
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 438 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 438 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :11
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 438 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 438 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :95
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 438 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 438 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 92
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 438 Ends   ===================
INFO:root:Epoch:438 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:438 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 439 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 439 Workers Selected : [49, 48, 38, 93, 24, 30, 78, 94, 17, 61]
INFO:root:FL Epoch: 439 Fraction of points on each worker in this round: [0.01851852 0.01851852 0.01851852 0.03703704 0.05555556 0.03703704
 0.01851852 0.74074074 0.03703704 0.01851852]
INFO:root:FL Epoch: 439 Num points on workers: [ 1  1  1  2  3  2  1 40  2  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 439 Training on worker :49
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 439 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :48
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 439 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :38
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 439 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :93
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 439 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 439 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :24
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 439 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 439 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :30
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 439 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 439 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :78
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 439 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :94
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.690121
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.658010
INFO:root:FL Epoch: 439 Norm Difference for worker 94 is 0.129707
INFO:root:FL Epoch: 439 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :17
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 439 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 439 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :61
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 439 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 49
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 439 Ends   ===================
INFO:root:Epoch:439 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:439 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 440 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 440 Workers Selected : [29, 25, 34, 12, 60, 94, 53, 69, 15, 91]
INFO:root:FL Epoch: 440 Fraction of points on each worker in this round: [0.01020408 0.24489796 0.03061224 0.01020408 0.03061224 0.40816327
 0.04081633 0.17346939 0.01020408 0.04081633]
INFO:root:FL Epoch: 440 Num points on workers: [ 1 24  3  1  3 40  4 17  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 440 Training on worker :29
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 440 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 440 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :25
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.687776
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.678499
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 440 Norm Difference for worker 25 is 0.042809
INFO:root:FL Epoch: 440 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :34
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 440 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 440 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :12
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 440 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 440 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :60
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 440 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 440 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :94
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.691008
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.658673
INFO:root:FL Epoch: 440 Norm Difference for worker 94 is 0.128704
INFO:root:FL Epoch: 440 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :53
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 440 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 440 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :69
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 440 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 440 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :15
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 440 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 440 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :91
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 440 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 440 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 29
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 440 Ends   ===================
INFO:root:Epoch:440 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:440 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 441 Begins ===================
INFO:root:FL Epoch: 441 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 441 Workers Selected : [0, 1, 2, 33, 10, 65, 21, 6, 85, 18]
INFO:root:FL Epoch: 441 Fraction of points on each worker in this round: [0.28985507 0.28985507 0.28985507 0.04347826 0.00144928 0.00144928
 0.07391304 0.00144928 0.00289855 0.0057971 ]
INFO:root:FL Epoch: 441 Num points on workers: [200 200 200  30   1   1  51   1   2   4]
INFO:root:--------------------------
INFO:root:FL Epoch: 441 Training on worker :0
INFO:root:FL Epoch: 441 Using Learning rate : 0.004144175762953584 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699113
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697902
INFO:root:FL Epoch: 441 Worker: 0 Backdoor Test Loss: 0.7205993036429087 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 441 Worker: 0 Backdoor Train Loss: 0.6894694924354553 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 441 Norm Difference for worker 0 is 0.054271
INFO:root:FL Epoch: 441 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1
INFO:root:FL Epoch: 441 Using Learning rate : 0.004144175762953584 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694239
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691630
INFO:root:FL Epoch: 441 Worker: 1 Backdoor Test Loss: 0.7239479720592499 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 441 Worker: 1 Backdoor Train Loss: 0.689296281337738 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 441 Norm Difference for worker 1 is 0.056021
INFO:root:FL Epoch: 441 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :2
INFO:root:FL Epoch: 441 Using Learning rate : 0.004144175762953584 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700249
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700528
INFO:root:FL Epoch: 441 Worker: 2 Backdoor Test Loss: 0.7218112945556641 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 441 Worker: 2 Backdoor Train Loss: 0.6894055962562561 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 441 Norm Difference for worker 2 is 0.055022
INFO:root:FL Epoch: 441 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :33
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.683669
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.671825
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 441 Norm Difference for worker 33 is 0.041949
INFO:root:FL Epoch: 441 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :10
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 441 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :65
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 441 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :21
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.697712
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.664501
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 441 Norm Difference for worker 21 is 0.138906
INFO:root:FL Epoch: 441 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :6
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 441 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :85
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 441 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 441 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :18
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 441 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 441 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 10
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 441 Ends   ===================
INFO:root:Epoch:441 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:441 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 442 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 442 Workers Selected : [90, 7, 38, 31, 93, 25, 74, 26, 50, 63]
INFO:root:FL Epoch: 442 Fraction of points on each worker in this round: [0.03846154 0.01923077 0.01923077 0.01923077 0.03846154 0.46153846
 0.32692308 0.01923077 0.01923077 0.03846154]
INFO:root:FL Epoch: 442 Num points on workers: [ 2  1  1  1  2 24 17  1  1  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 442 Training on worker :90
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 442 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 442 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :7
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 442 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 442 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :38
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 442 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 442 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :31
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 442 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 442 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :93
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 442 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 442 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :25
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.690589
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.675587
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 442 Norm Difference for worker 25 is 0.043761
INFO:root:FL Epoch: 442 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :74
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 442 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 442 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :26
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 442 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 442 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :50
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 442 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 442 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :63
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 442 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 442 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 90
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 442 Ends   ===================
INFO:root:Epoch:442 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:442 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 443 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 443 Workers Selected : [55, 24, 34, 29, 49, 96, 62, 32, 46, 76]
INFO:root:FL Epoch: 443 Fraction of points on each worker in this round: [0.04545455 0.13636364 0.13636364 0.04545455 0.04545455 0.04545455
 0.13636364 0.18181818 0.04545455 0.18181818]
INFO:root:FL Epoch: 443 Num points on workers: [1 3 3 1 1 1 3 4 1 4]
INFO:root:--------------------------
INFO:root:FL Epoch: 443 Training on worker :55
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 443 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :24
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 443 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 443 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :34
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 443 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 443 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :29
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 443 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :49
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 443 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :96
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 443 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :62
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 443 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 443 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :32
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 443 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 443 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :46
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 443 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :76
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 443 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 443 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 55
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 443 Ends   ===================
INFO:root:Epoch:443 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:443 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 444 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 444 Workers Selected : [34, 63, 13, 15, 92, 7, 42, 74, 12, 32]
INFO:root:FL Epoch: 444 Fraction of points on each worker in this round: [0.075 0.05  0.1   0.025 0.1   0.025 0.075 0.425 0.025 0.1  ]
INFO:root:FL Epoch: 444 Num points on workers: [ 3  2  4  1  4  1  3 17  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 444 Training on worker :34
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 444 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 444 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :63
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 444 Norm Difference for worker 63 is 0.0
INFO:root:FL Epoch: 444 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :13
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 444 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 444 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :15
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 444 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 444 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :92
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 444 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 444 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :7
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 444 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 444 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :42
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 444 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 444 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :74
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 444 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 444 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :12
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 444 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 444 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :32
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 444 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 444 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 34
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 444 Ends   ===================
INFO:root:Epoch:444 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:444 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 445 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 445 Workers Selected : [86, 98, 79, 54, 26, 39, 36, 93, 42, 89]
INFO:root:FL Epoch: 445 Fraction of points on each worker in this round: [0.16129032 0.03225806 0.06451613 0.03225806 0.03225806 0.41935484
 0.06451613 0.06451613 0.09677419 0.03225806]
INFO:root:FL Epoch: 445 Num points on workers: [ 5  1  2  1  1 13  2  2  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 445 Training on worker :86
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 445 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 445 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :98
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 445 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 445 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :79
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 445 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 445 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :54
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 445 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 445 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :26
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 445 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 445 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :39
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 445 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 445 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :36
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 445 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 445 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :93
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 445 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 445 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :42
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 445 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 445 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :89
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 445 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 445 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 86
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 445 Ends   ===================
INFO:root:Epoch:445 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:445 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 446 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 446 Workers Selected : [79, 18, 47, 96, 9, 69, 44, 88, 35, 57]
INFO:root:FL Epoch: 446 Fraction of points on each worker in this round: [0.03076923 0.06153846 0.04615385 0.01538462 0.32307692 0.26153846
 0.03076923 0.01538462 0.01538462 0.2       ]
INFO:root:FL Epoch: 446 Num points on workers: [ 2  4  3  1 21 17  2  1  1 13]
INFO:root:--------------------------
INFO:root:FL Epoch: 446 Training on worker :79
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 446 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 446 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :18
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 446 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 446 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :47
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 446 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 446 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :96
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 446 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :9
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.687748
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.675685
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 9 is 0.040499
INFO:root:FL Epoch: 446 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :69
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 446 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 446 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :44
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 446 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 446 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :88
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 446 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :35
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 446 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :57
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 446 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 446 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 79
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 446 Ends   ===================
INFO:root:Epoch:446 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:446 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 447 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 447 Workers Selected : [75, 18, 52, 41, 42, 30, 58, 54, 17, 38]
INFO:root:FL Epoch: 447 Fraction of points on each worker in this round: [0.05263158 0.10526316 0.02631579 0.10526316 0.07894737 0.05263158
 0.47368421 0.02631579 0.05263158 0.02631579]
INFO:root:FL Epoch: 447 Num points on workers: [ 2  4  1  4  3  2 18  1  2  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 447 Training on worker :75
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 447 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 447 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :18
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 447 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 447 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :52
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 447 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :41
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 447 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 447 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :42
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 447 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 447 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :30
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 447 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 447 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :58
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 447 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 447 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :54
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 447 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :17
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 447 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 447 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :38
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 447 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 75
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 447 Ends   ===================
INFO:root:Epoch:447 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:447 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 448 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 448 Workers Selected : [94, 55, 25, 22, 7, 21, 45, 51, 11, 28]
INFO:root:FL Epoch: 448 Fraction of points on each worker in this round: [0.30075188 0.0075188  0.18045113 0.0075188  0.0075188  0.38345865
 0.01503759 0.03007519 0.02255639 0.04511278]
INFO:root:FL Epoch: 448 Num points on workers: [40  1 24  1  1 51  2  4  3  6]
INFO:root:--------------------------
INFO:root:FL Epoch: 448 Training on worker :94
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.694509
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.664084
INFO:root:FL Epoch: 448 Norm Difference for worker 94 is 0.127063
INFO:root:FL Epoch: 448 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :55
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 448 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 448 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :25
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.687828
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.674136
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 448 Norm Difference for worker 25 is 0.04293
INFO:root:FL Epoch: 448 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :22
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 448 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 448 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :7
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 448 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 448 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :21
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.699904
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.658703
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 448 Norm Difference for worker 21 is 0.13771
INFO:root:FL Epoch: 448 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :45
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 448 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 448 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :51
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 448 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 448 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :11
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 448 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 448 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :28
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 448 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 448 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 55
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 448 Ends   ===================
INFO:root:Epoch:448 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:448 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 449 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 449 Workers Selected : [98, 64, 21, 88, 44, 50, 93, 46, 72, 66]
INFO:root:FL Epoch: 449 Fraction of points on each worker in this round: [0.01449275 0.04347826 0.73913043 0.01449275 0.02898551 0.01449275
 0.02898551 0.01449275 0.08695652 0.01449275]
INFO:root:FL Epoch: 449 Num points on workers: [ 1  3 51  1  2  1  2  1  6  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 449 Training on worker :98
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 449 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 449 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :64
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 449 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 449 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :21
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.701451
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.665294
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 449 Norm Difference for worker 21 is 0.135772
INFO:root:FL Epoch: 449 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :88
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 449 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 449 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :44
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 449 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 449 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :50
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 449 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 449 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :93
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 449 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 449 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :46
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 449 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 449 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :72
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 449 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 449 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :66
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 449 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 449 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 98
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 449 Ends   ===================
INFO:root:Epoch:449 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:449 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 450 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 450 Workers Selected : [88, 41, 4, 67, 53, 69, 79, 77, 43, 91]
INFO:root:FL Epoch: 450 Fraction of points on each worker in this round: [0.0212766  0.08510638 0.0212766  0.25531915 0.08510638 0.36170213
 0.04255319 0.0212766  0.0212766  0.08510638]
INFO:root:FL Epoch: 450 Num points on workers: [ 1  4  1 12  4 17  2  1  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 450 Training on worker :88
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 450 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :41
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 450 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 450 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :4
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 450 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :67
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 450 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 450 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :53
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 450 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 450 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :69
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 450 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 450 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :79
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 450 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 450 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :77
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 450 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :43
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 450 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :91
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 450 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 450 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 88
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 450 Ends   ===================
INFO:root:Epoch:450 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:450 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 451 Begins ===================
INFO:root:FL Epoch: 451 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 451 Workers Selected : [0, 1, 2, 6, 21, 96, 8, 53, 26, 44]
INFO:root:FL Epoch: 451 Fraction of points on each worker in this round: [0.30257186 0.30257186 0.30257186 0.00151286 0.07715582 0.00151286
 0.00151286 0.00605144 0.00151286 0.00302572]
INFO:root:FL Epoch: 451 Num points on workers: [200 200 200   1  51   1   1   4   1   2]
INFO:root:--------------------------
INFO:root:FL Epoch: 451 Training on worker :0
INFO:root:FL Epoch: 451 Using Learning rate : 0.0040620342348141785 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696174
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692060
INFO:root:FL Epoch: 451 Worker: 0 Backdoor Test Loss: 0.7202433248360952 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 451 Worker: 0 Backdoor Train Loss: 0.6896129012107849 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 451 Norm Difference for worker 0 is 0.052663
INFO:root:FL Epoch: 451 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1
INFO:root:FL Epoch: 451 Using Learning rate : 0.0040620342348141785 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705923
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694290
INFO:root:FL Epoch: 451 Worker: 1 Backdoor Test Loss: 0.721696933110555 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 451 Worker: 1 Backdoor Train Loss: 0.6893903315067291 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 451 Norm Difference for worker 1 is 0.054824
INFO:root:FL Epoch: 451 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :2
INFO:root:FL Epoch: 451 Using Learning rate : 0.0040620342348141785 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696549
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685685
INFO:root:FL Epoch: 451 Worker: 2 Backdoor Test Loss: 0.7203239599863688 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 451 Worker: 2 Backdoor Train Loss: 0.6895236492156982 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 451 Norm Difference for worker 2 is 0.053654
INFO:root:FL Epoch: 451 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :6
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 451 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 451 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :21
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.693873
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.661493
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 451 Norm Difference for worker 21 is 0.136873
INFO:root:FL Epoch: 451 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :96
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 451 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 451 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :8
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 451 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 451 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :53
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 451 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 451 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :26
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 451 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 451 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :44
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 451 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 451 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 6
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 451 Ends   ===================
INFO:root:Epoch:451 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:451 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 452 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 452 Workers Selected : [66, 10, 65, 45, 80, 91, 56, 40, 15, 9]
INFO:root:FL Epoch: 452 Fraction of points on each worker in this round: [0.02777778 0.02777778 0.02777778 0.05555556 0.02777778 0.11111111
 0.08333333 0.02777778 0.02777778 0.58333333]
INFO:root:FL Epoch: 452 Num points on workers: [ 1  1  1  2  1  4  3  1  1 21]
INFO:root:--------------------------
INFO:root:FL Epoch: 452 Training on worker :66
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 452 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :10
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 452 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :65
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 452 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :45
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 452 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 452 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :80
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 452 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :91
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 452 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 452 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :56
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 452 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 452 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :40
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 452 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :15
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 452 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :9
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.678307
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.677972
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 9 is 0.040423
INFO:root:FL Epoch: 452 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 66
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 452 Ends   ===================
INFO:root:Epoch:452 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:452 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 453 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 453 Workers Selected : [64, 53, 78, 55, 10, 59, 73, 21, 4, 39]
INFO:root:FL Epoch: 453 Fraction of points on each worker in this round: [0.03896104 0.05194805 0.01298701 0.01298701 0.01298701 0.01298701
 0.01298701 0.66233766 0.01298701 0.16883117]
INFO:root:FL Epoch: 453 Num points on workers: [ 3  4  1  1  1  1  1 51  1 13]
INFO:root:--------------------------
INFO:root:FL Epoch: 453 Training on worker :64
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 453 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 453 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :53
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 453 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 453 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :78
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 453 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :55
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 453 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :10
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 453 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :59
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 453 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :73
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 453 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :21
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.691220
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.667600
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 453 Norm Difference for worker 21 is 0.134407
INFO:root:FL Epoch: 453 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :4
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 453 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :39
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 453 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 453 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 64
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 453 Ends   ===================
INFO:root:Epoch:453 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:453 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 454 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 454 Workers Selected : [65, 69, 78, 82, 47, 62, 19, 22, 8, 29]
INFO:root:FL Epoch: 454 Fraction of points on each worker in this round: [0.03333333 0.56666667 0.03333333 0.03333333 0.1        0.1
 0.03333333 0.03333333 0.03333333 0.03333333]
INFO:root:FL Epoch: 454 Num points on workers: [ 1 17  1  1  3  3  1  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 454 Training on worker :65
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 454 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :69
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 454 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 454 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :78
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 454 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :82
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 454 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :47
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 454 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 454 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :62
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 454 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 454 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :19
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 454 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :22
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 454 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :8
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 454 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :29
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 454 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 65
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 454 Ends   ===================
INFO:root:Epoch:454 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:454 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 455 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 455 Workers Selected : [75, 56, 21, 97, 39, 20, 77, 6, 73, 26]
INFO:root:FL Epoch: 455 Fraction of points on each worker in this round: [0.02380952 0.03571429 0.60714286 0.11904762 0.1547619  0.01190476
 0.01190476 0.01190476 0.01190476 0.01190476]
INFO:root:FL Epoch: 455 Num points on workers: [ 2  3 51 10 13  1  1  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 455 Training on worker :75
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 455 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 455 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :56
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 455 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 455 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :21
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.697621
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.667192
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 455 Norm Difference for worker 21 is 0.1348
INFO:root:FL Epoch: 455 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :97
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 455 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 455 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :39
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 455 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 455 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :20
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 455 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :77
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 455 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :6
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 455 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :73
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 455 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :26
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 455 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 75
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 455 Ends   ===================
INFO:root:Epoch:455 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:455 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 456 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 456 Workers Selected : [31, 96, 72, 83, 9, 70, 12, 8, 37, 29]
INFO:root:FL Epoch: 456 Fraction of points on each worker in this round: [0.02702703 0.02702703 0.16216216 0.05405405 0.56756757 0.05405405
 0.02702703 0.02702703 0.02702703 0.02702703]
INFO:root:FL Epoch: 456 Num points on workers: [ 1  1  6  2 21  2  1  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 456 Training on worker :31
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 456 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 456 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :96
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 456 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 456 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :72
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 456 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 456 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :83
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 456 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 456 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :9
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.686453
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.677409
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 456 Norm Difference for worker 9 is 0.039871
INFO:root:FL Epoch: 456 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :70
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 456 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 456 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :12
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 456 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 456 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :8
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 456 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 456 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :37
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 456 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 456 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :29
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 456 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 456 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 31
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 456 Ends   ===================
INFO:root:Epoch:456 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:456 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 457 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 457 Workers Selected : [33, 70, 34, 32, 29, 78, 69, 8, 56, 5]
INFO:root:FL Epoch: 457 Fraction of points on each worker in this round: [0.42253521 0.02816901 0.04225352 0.05633803 0.01408451 0.01408451
 0.23943662 0.01408451 0.04225352 0.12676056]
INFO:root:FL Epoch: 457 Num points on workers: [30  2  3  4  1  1 17  1  3  9]
INFO:root:--------------------------
INFO:root:FL Epoch: 457 Training on worker :33
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.685546
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.674565
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 457 Norm Difference for worker 33 is 0.040362
INFO:root:FL Epoch: 457 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :70
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 457 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 457 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :34
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 457 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 457 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :32
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 457 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 457 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :29
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 457 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :78
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 457 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :69
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 457 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 457 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :8
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 457 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :56
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 457 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 457 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :5
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 457 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 457 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 457 Ends   ===================
INFO:root:Epoch:457 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:457 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 458 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 458 Workers Selected : [40, 69, 10, 6, 58, 46, 43, 97, 33, 83]
INFO:root:FL Epoch: 458 Fraction of points on each worker in this round: [0.01219512 0.20731707 0.01219512 0.01219512 0.2195122  0.01219512
 0.01219512 0.12195122 0.36585366 0.02439024]
INFO:root:FL Epoch: 458 Num points on workers: [ 1 17  1  1 18  1  1 10 30  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 458 Training on worker :40
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 458 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 458 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :69
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 458 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 458 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :10
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 458 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 458 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :6
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 458 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 458 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :58
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 458 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 458 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :46
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 458 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 458 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :43
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 458 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 458 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :97
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 458 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 458 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :33
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.684425
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.677350
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 458 Norm Difference for worker 33 is 0.040202
INFO:root:FL Epoch: 458 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :83
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 458 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 458 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 40
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 458 Ends   ===================
INFO:root:Epoch:458 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:458 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 459 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 459 Workers Selected : [36, 28, 59, 74, 4, 15, 26, 95, 83, 17]
INFO:root:FL Epoch: 459 Fraction of points on each worker in this round: [0.05882353 0.17647059 0.02941176 0.5        0.02941176 0.02941176
 0.02941176 0.02941176 0.05882353 0.05882353]
INFO:root:FL Epoch: 459 Num points on workers: [ 2  6  1 17  1  1  1  1  2  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 459 Training on worker :36
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 459 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 459 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :28
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 459 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 459 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :59
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 459 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :74
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 459 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 459 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :4
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 459 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :15
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 459 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :26
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 459 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :95
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 459 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :83
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 459 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 459 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :17
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 459 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 459 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 36
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 459 Ends   ===================
INFO:root:Epoch:459 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:459 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 460 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 460 Workers Selected : [53, 40, 83, 57, 37, 14, 75, 28, 47, 69]
INFO:root:FL Epoch: 460 Fraction of points on each worker in this round: [0.07272727 0.01818182 0.03636364 0.23636364 0.01818182 0.10909091
 0.03636364 0.10909091 0.05454545 0.30909091]
INFO:root:FL Epoch: 460 Num points on workers: [ 4  1  2 13  1  6  2  6  3 17]
INFO:root:--------------------------
INFO:root:FL Epoch: 460 Training on worker :53
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 460 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 460 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :40
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 460 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 460 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :83
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 460 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 460 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :57
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 460 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 460 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :37
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 460 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 460 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :14
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 460 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 460 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :75
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 460 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 460 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :28
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 460 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 460 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :47
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 460 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 460 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :69
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 460 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 460 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 53
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 460 Ends   ===================
INFO:root:Epoch:460 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:460 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 461 Begins ===================
INFO:root:FL Epoch: 461 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 461 Workers Selected : [0, 1, 2, 19, 84, 28, 50, 80, 39, 4]
INFO:root:FL Epoch: 461 Fraction of points on each worker in this round: [0.31496063 0.31496063 0.31496063 0.0015748  0.01889764 0.00944882
 0.0015748  0.0015748  0.02047244 0.0015748 ]
INFO:root:FL Epoch: 461 Num points on workers: [200 200 200   1  12   6   1   1  13   1]
INFO:root:--------------------------
INFO:root:FL Epoch: 461 Training on worker :0
INFO:root:FL Epoch: 461 Using Learning rate : 0.003981520830343029 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697796
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690574
INFO:root:FL Epoch: 461 Worker: 0 Backdoor Test Loss: 0.7218639552593231 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 461 Worker: 0 Backdoor Train Loss: 0.6895189881324768 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 461 Norm Difference for worker 0 is 0.053521
INFO:root:FL Epoch: 461 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1
INFO:root:FL Epoch: 461 Using Learning rate : 0.003981520830343029 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697900
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687986
INFO:root:FL Epoch: 461 Worker: 1 Backdoor Test Loss: 0.7249916593233744 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 461 Worker: 1 Backdoor Train Loss: 0.6891274929046631 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 461 Norm Difference for worker 1 is 0.057739
INFO:root:FL Epoch: 461 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :2
INFO:root:FL Epoch: 461 Using Learning rate : 0.003981520830343029 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692556
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688682
INFO:root:FL Epoch: 461 Worker: 2 Backdoor Test Loss: 0.7193223039309183 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 461 Worker: 2 Backdoor Train Loss: 0.689718770980835 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 461 Norm Difference for worker 2 is 0.051213
INFO:root:FL Epoch: 461 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :19
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 461 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 461 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :84
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 461 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 461 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :28
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 461 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 461 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :50
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 461 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 461 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :80
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 461 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 461 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :39
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 461 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 461 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :4
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 461 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 461 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 19
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 461 Ends   ===================
INFO:root:Epoch:461 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:461 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 462 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 462 Workers Selected : [23, 8, 26, 67, 37, 46, 90, 55, 62, 94]
INFO:root:FL Epoch: 462 Fraction of points on each worker in this round: [0.10144928 0.01449275 0.01449275 0.17391304 0.01449275 0.01449275
 0.02898551 0.01449275 0.04347826 0.57971014]
INFO:root:FL Epoch: 462 Num points on workers: [ 7  1  1 12  1  1  2  1  3 40]
INFO:root:--------------------------
INFO:root:FL Epoch: 462 Training on worker :23
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 462 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 462 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :8
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 462 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 462 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :26
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 462 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 462 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :67
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 462 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 462 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :37
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 462 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 462 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :46
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 462 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 462 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :90
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 462 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 462 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :55
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 462 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 462 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :62
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 462 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 462 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :94
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.688768
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.664150
INFO:root:FL Epoch: 462 Norm Difference for worker 94 is 0.122837
INFO:root:FL Epoch: 462 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 23
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 462 Ends   ===================
INFO:root:Epoch:462 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:462 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 463 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 463 Workers Selected : [24, 93, 61, 21, 70, 23, 86, 84, 7, 51]
INFO:root:FL Epoch: 463 Fraction of points on each worker in this round: [0.03409091 0.02272727 0.01136364 0.57954545 0.02272727 0.07954545
 0.05681818 0.13636364 0.01136364 0.04545455]
INFO:root:FL Epoch: 463 Num points on workers: [ 3  2  1 51  2  7  5 12  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 463 Training on worker :24
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 463 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 463 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :93
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 463 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 463 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :61
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 463 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :21
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.699541
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.659758
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 463 Norm Difference for worker 21 is 0.134302
INFO:root:FL Epoch: 463 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :70
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 463 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 463 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :23
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 463 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 463 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :86
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 463 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 463 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :84
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 463 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 463 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :7
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 463 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :51
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 463 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 463 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 24
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 463 Ends   ===================
INFO:root:Epoch:463 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:463 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 464 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 464 Workers Selected : [68, 76, 53, 75, 7, 64, 19, 4, 52, 97]
INFO:root:FL Epoch: 464 Fraction of points on each worker in this round: [0.06896552 0.13793103 0.13793103 0.06896552 0.03448276 0.10344828
 0.03448276 0.03448276 0.03448276 0.34482759]
INFO:root:FL Epoch: 464 Num points on workers: [ 2  4  4  2  1  3  1  1  1 10]
INFO:root:--------------------------
INFO:root:FL Epoch: 464 Training on worker :68
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 464 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 464 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :76
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 464 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 464 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :53
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 464 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 464 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :75
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 464 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 464 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :7
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 464 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :64
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 464 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 464 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :19
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 464 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :4
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 464 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :52
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 464 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :97
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 464 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 464 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 68
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 464 Ends   ===================
INFO:root:Epoch:464 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:464 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 465 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 465 Workers Selected : [20, 91, 23, 99, 25, 22, 86, 28, 36, 27]
INFO:root:FL Epoch: 465 Fraction of points on each worker in this round: [0.01724138 0.06896552 0.12068966 0.05172414 0.4137931  0.01724138
 0.0862069  0.10344828 0.03448276 0.0862069 ]
INFO:root:FL Epoch: 465 Num points on workers: [ 1  4  7  3 24  1  5  6  2  5]
INFO:root:--------------------------
INFO:root:FL Epoch: 465 Training on worker :20
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 465 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :91
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 465 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 465 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :23
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 465 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 465 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :99
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 465 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 465 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :25
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.687206
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.679967
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 465 Norm Difference for worker 25 is 0.041265
INFO:root:FL Epoch: 465 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :22
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 465 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :86
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 465 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 465 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :28
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 465 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 465 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :36
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 465 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 465 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :27
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 465 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 465 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 20
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 465 Ends   ===================
INFO:root:Epoch:465 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:465 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 466 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 466 Workers Selected : [19, 57, 81, 6, 33, 72, 90, 3, 60, 73]
INFO:root:FL Epoch: 466 Fraction of points on each worker in this round: [0.01639344 0.21311475 0.04918033 0.01639344 0.49180328 0.09836066
 0.03278689 0.01639344 0.04918033 0.01639344]
INFO:root:FL Epoch: 466 Num points on workers: [ 1 13  3  1 30  6  2  1  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 466 Training on worker :19
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 466 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 466 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :57
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 466 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 466 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :81
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 466 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 466 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :6
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 466 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 466 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :33
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.694330
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.674665
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 466 Norm Difference for worker 33 is 0.040348
INFO:root:FL Epoch: 466 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :72
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 466 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 466 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :90
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 466 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 466 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :3
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 466 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 466 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :60
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 466 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 466 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :73
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 466 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 466 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 19
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 466 Ends   ===================
INFO:root:Epoch:466 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:466 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 467 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 467 Workers Selected : [48, 24, 50, 75, 74, 42, 54, 65, 73, 91]
INFO:root:FL Epoch: 467 Fraction of points on each worker in this round: [0.02941176 0.08823529 0.02941176 0.05882353 0.5        0.08823529
 0.02941176 0.02941176 0.02941176 0.11764706]
INFO:root:FL Epoch: 467 Num points on workers: [ 1  3  1  2 17  3  1  1  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 467 Training on worker :48
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 467 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 467 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :24
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 467 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 467 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :50
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 467 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 467 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :75
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 467 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 467 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :74
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 467 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 467 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :42
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 467 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 467 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :54
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 467 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 467 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :65
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 467 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 467 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :73
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 467 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 467 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :91
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 467 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 467 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 48
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 467 Ends   ===================
INFO:root:Epoch:467 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:467 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 468 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 468 Workers Selected : [52, 42, 56, 10, 43, 20, 65, 46, 31, 34]
INFO:root:FL Epoch: 468 Fraction of points on each worker in this round: [0.0625 0.1875 0.1875 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.1875]
INFO:root:FL Epoch: 468 Num points on workers: [1 3 3 1 1 1 1 1 1 3]
INFO:root:--------------------------
INFO:root:FL Epoch: 468 Training on worker :52
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 468 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 468 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :42
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 468 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 468 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :56
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 468 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 468 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :10
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 468 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 468 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :43
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 468 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 468 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :20
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 468 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 468 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :65
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 468 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 468 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :46
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 468 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 468 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :31
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 468 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 468 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :34
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 468 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 468 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 52
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 468 Ends   ===================
INFO:root:Epoch:468 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:468 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 469 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 469 Workers Selected : [80, 45, 92, 21, 31, 28, 42, 20, 6, 84]
INFO:root:FL Epoch: 469 Fraction of points on each worker in this round: [0.01219512 0.02439024 0.04878049 0.62195122 0.01219512 0.07317073
 0.03658537 0.01219512 0.01219512 0.14634146]
INFO:root:FL Epoch: 469 Num points on workers: [ 1  2  4 51  1  6  3  1  1 12]
INFO:root:--------------------------
INFO:root:FL Epoch: 469 Training on worker :80
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 469 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 469 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :45
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 469 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 469 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :92
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 469 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 469 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :21
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.699546
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.661086
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 469 Norm Difference for worker 21 is 0.13238
INFO:root:FL Epoch: 469 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :31
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 469 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 469 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :28
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 469 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 469 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :42
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 469 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 469 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :20
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 469 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 469 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :6
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 469 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 469 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :84
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 469 Norm Difference for worker 84 is 0.0
INFO:root:FL Epoch: 469 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 80
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 469 Ends   ===================
INFO:root:Epoch:469 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:469 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 470 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 470 Workers Selected : [35, 44, 64, 45, 85, 6, 88, 56, 43, 54]
INFO:root:FL Epoch: 470 Fraction of points on each worker in this round: [0.05882353 0.11764706 0.17647059 0.11764706 0.11764706 0.05882353
 0.05882353 0.17647059 0.05882353 0.05882353]
INFO:root:FL Epoch: 470 Num points on workers: [1 2 3 2 2 1 1 3 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 470 Training on worker :35
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 470 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 470 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :44
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 470 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 470 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :64
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 470 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 470 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :45
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 470 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 470 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :85
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 470 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 470 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :6
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 470 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 470 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :88
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 470 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 470 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :56
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 470 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 470 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :43
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 470 Norm Difference for worker 43 is 0.0
INFO:root:FL Epoch: 470 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :54
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 470 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 470 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 35
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 470 Ends   ===================
INFO:root:Epoch:470 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:470 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 471 Begins ===================
INFO:root:FL Epoch: 471 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 471 Workers Selected : [0, 1, 2, 64, 19, 24, 45, 42, 56, 70]
INFO:root:FL Epoch: 471 Fraction of points on each worker in this round: [0.32414911 0.32414911 0.32414911 0.00486224 0.00162075 0.00486224
 0.00324149 0.00486224 0.00486224 0.00324149]
INFO:root:FL Epoch: 471 Num points on workers: [200 200 200   3   1   3   2   3   3   2]
INFO:root:--------------------------
INFO:root:FL Epoch: 471 Training on worker :0
INFO:root:FL Epoch: 471 Using Learning rate : 0.00390260327857149 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700625
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693990
INFO:root:FL Epoch: 471 Worker: 0 Backdoor Test Loss: 0.7194024523099264 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 471 Worker: 0 Backdoor Train Loss: 0.6898768305778503 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 471 Norm Difference for worker 0 is 0.049969
INFO:root:FL Epoch: 471 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1
INFO:root:FL Epoch: 471 Using Learning rate : 0.00390260327857149 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697525
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688757
INFO:root:FL Epoch: 471 Worker: 1 Backdoor Test Loss: 0.721140444278717 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 471 Worker: 1 Backdoor Train Loss: 0.6896729052066803 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 471 Norm Difference for worker 1 is 0.05203
INFO:root:FL Epoch: 471 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :2
INFO:root:FL Epoch: 471 Using Learning rate : 0.00390260327857149 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696503
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694718
INFO:root:FL Epoch: 471 Worker: 2 Backdoor Test Loss: 0.7209167083104452 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 471 Worker: 2 Backdoor Train Loss: 0.6897377014160156 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 471 Norm Difference for worker 2 is 0.051259
INFO:root:FL Epoch: 471 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :64
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 471 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 471 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :19
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 471 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 471 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :24
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 471 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 471 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :45
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 471 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 471 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :42
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 471 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 471 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :56
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 471 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 471 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :70
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 471 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 471 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 64
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 471 Ends   ===================
INFO:root:Epoch:471 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:471 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 472 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 472 Workers Selected : [90, 33, 83, 45, 25, 98, 46, 85, 80, 60]
INFO:root:FL Epoch: 472 Fraction of points on each worker in this round: [0.02941176 0.44117647 0.02941176 0.02941176 0.35294118 0.01470588
 0.01470588 0.02941176 0.01470588 0.04411765]
INFO:root:FL Epoch: 472 Num points on workers: [ 2 30  2  2 24  1  1  2  1  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 472 Training on worker :90
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 472 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 472 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :33
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.683790
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.679569
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 472 Norm Difference for worker 33 is 0.039108
INFO:root:FL Epoch: 472 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :83
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 472 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 472 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :45
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 472 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 472 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :25
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.693757
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.686567
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 472 Norm Difference for worker 25 is 0.040634
INFO:root:FL Epoch: 472 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :98
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 472 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 472 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :46
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 472 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 472 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :85
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 472 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 472 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :80
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 472 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 472 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :60
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 472 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 472 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 90
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 472 Ends   ===================
INFO:root:Epoch:472 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:472 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 473 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 473 Workers Selected : [37, 42, 13, 16, 40, 79, 35, 93, 17, 9]
INFO:root:FL Epoch: 473 Fraction of points on each worker in this round: [0.02564103 0.07692308 0.1025641  0.05128205 0.02564103 0.05128205
 0.02564103 0.05128205 0.05128205 0.53846154]
INFO:root:FL Epoch: 473 Num points on workers: [ 1  3  4  2  1  2  1  2  2 21]
INFO:root:--------------------------
INFO:root:FL Epoch: 473 Training on worker :37
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 473 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 473 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :42
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 473 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 473 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :13
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 473 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 473 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :16
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 473 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 473 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :40
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 473 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 473 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :79
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 473 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 473 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :35
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 473 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 473 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :93
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 473 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 473 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :17
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 473 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 473 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :9
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.683569
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.671503
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 473 Norm Difference for worker 9 is 0.038176
INFO:root:FL Epoch: 473 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 37
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 473 Ends   ===================
INFO:root:Epoch:473 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:473 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 474 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 474 Workers Selected : [19, 13, 48, 55, 64, 68, 76, 40, 11, 82]
INFO:root:FL Epoch: 474 Fraction of points on each worker in this round: [0.04761905 0.19047619 0.04761905 0.04761905 0.14285714 0.0952381
 0.19047619 0.04761905 0.14285714 0.04761905]
INFO:root:FL Epoch: 474 Num points on workers: [1 4 1 1 3 2 4 1 3 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 474 Training on worker :19
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 474 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 474 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :13
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 474 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 474 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :48
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 474 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 474 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :55
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 474 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 474 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :64
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 474 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 474 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :68
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 474 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 474 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :76
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 474 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 474 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :40
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 474 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 474 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :11
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 474 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 474 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :82
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 474 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 474 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 19
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 474 Ends   ===================
INFO:root:Epoch:474 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:474 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 475 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 475 Workers Selected : [16, 21, 56, 8, 77, 49, 78, 18, 75, 62]
INFO:root:FL Epoch: 475 Fraction of points on each worker in this round: [0.02898551 0.73913043 0.04347826 0.01449275 0.01449275 0.01449275
 0.01449275 0.05797101 0.02898551 0.04347826]
INFO:root:FL Epoch: 475 Num points on workers: [ 2 51  3  1  1  1  1  4  2  3]
INFO:root:--------------------------
INFO:root:FL Epoch: 475 Training on worker :16
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 475 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 475 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :21
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/51 (0%)]	Loss: 0.697875
INFO:root:ignore batch due to small size = 11
INFO:root:Worker: 21 Train Epoch: 1 [0/51 (0%)]	Loss: 0.662417
INFO:root:ignore batch due to small size = 11
INFO:root:FL Epoch: 475 Norm Difference for worker 21 is 0.131049
INFO:root:FL Epoch: 475 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :56
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 475 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 475 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :8
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 475 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :77
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 475 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :49
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 475 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :78
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 475 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :18
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 475 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 475 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :75
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 475 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 475 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :62
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 475 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 475 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 16
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 475 Ends   ===================
INFO:root:Epoch:475 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:475 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 476 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 476 Workers Selected : [89, 98, 72, 10, 81, 19, 26, 65, 6, 22]
INFO:root:FL Epoch: 476 Fraction of points on each worker in this round: [0.05882353 0.05882353 0.35294118 0.05882353 0.17647059 0.05882353
 0.05882353 0.05882353 0.05882353 0.05882353]
INFO:root:FL Epoch: 476 Num points on workers: [1 1 6 1 3 1 1 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 476 Training on worker :89
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 476 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 476 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :98
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 476 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 476 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :72
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 476 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 476 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :10
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 476 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 476 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :81
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 476 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 476 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :19
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 476 Norm Difference for worker 19 is 0.0
INFO:root:FL Epoch: 476 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :26
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 476 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 476 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :65
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 476 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 476 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :6
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 476 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 476 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :22
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 476 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 476 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 89
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 476 Ends   ===================
INFO:root:Epoch:476 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:476 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 477 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 477 Workers Selected : [36, 95, 34, 25, 7, 81, 70, 58, 51, 54]
INFO:root:FL Epoch: 477 Fraction of points on each worker in this round: [0.03389831 0.01694915 0.05084746 0.40677966 0.01694915 0.05084746
 0.03389831 0.30508475 0.06779661 0.01694915]
INFO:root:FL Epoch: 477 Num points on workers: [ 2  1  3 24  1  3  2 18  4  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 477 Training on worker :36
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 477 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 477 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :95
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 477 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 477 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :34
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 477 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 477 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :25
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.686784
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.676385
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 477 Norm Difference for worker 25 is 0.040033
INFO:root:FL Epoch: 477 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :7
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 477 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 477 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :81
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 477 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 477 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :70
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 477 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 477 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :58
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 477 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 477 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :51
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 477 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 477 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :54
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 477 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 477 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 36
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 477 Ends   ===================
INFO:root:Epoch:477 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:477 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 478 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 478 Workers Selected : [70, 37, 16, 50, 75, 18, 44, 9, 80, 53]
INFO:root:FL Epoch: 478 Fraction of points on each worker in this round: [0.05  0.025 0.05  0.025 0.05  0.1   0.05  0.525 0.025 0.1  ]
INFO:root:FL Epoch: 478 Num points on workers: [ 2  1  2  1  2  4  2 21  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 478 Training on worker :70
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 478 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 478 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :37
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 478 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :16
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 478 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 478 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :50
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 478 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :75
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 478 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 478 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :18
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 478 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 478 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :44
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 478 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 478 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :9
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.682606
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.674069
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 9 is 0.038382
INFO:root:FL Epoch: 478 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :80
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 478 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :53
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 478 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 478 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 478 Ends   ===================
INFO:root:Epoch:478 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:478 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 479 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 479 Workers Selected : [87, 72, 5, 50, 64, 31, 88, 13, 28, 40]
INFO:root:FL Epoch: 479 Fraction of points on each worker in this round: [0.13513514 0.16216216 0.24324324 0.02702703 0.08108108 0.02702703
 0.02702703 0.10810811 0.16216216 0.02702703]
INFO:root:FL Epoch: 479 Num points on workers: [5 6 9 1 3 1 1 4 6 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 479 Training on worker :87
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 479 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 479 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :72
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 479 Norm Difference for worker 72 is 0.0
INFO:root:FL Epoch: 479 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :5
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 479 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 479 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :50
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 479 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 479 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :64
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 479 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 479 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :31
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 479 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 479 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :88
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 479 Norm Difference for worker 88 is 0.0
INFO:root:FL Epoch: 479 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :13
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 479 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 479 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :28
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 479 Norm Difference for worker 28 is 0.0
INFO:root:FL Epoch: 479 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :40
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 479 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 479 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 87
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 479 Ends   ===================
INFO:root:Epoch:479 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:479 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 480 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 480 Workers Selected : [81, 3, 95, 65, 6, 47, 13, 24, 83, 75]
INFO:root:FL Epoch: 480 Fraction of points on each worker in this round: [0.14285714 0.04761905 0.04761905 0.04761905 0.04761905 0.14285714
 0.19047619 0.14285714 0.0952381  0.0952381 ]
INFO:root:FL Epoch: 480 Num points on workers: [3 1 1 1 1 3 4 3 2 2]
INFO:root:--------------------------
INFO:root:FL Epoch: 480 Training on worker :81
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 480 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 480 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :3
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 480 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :95
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 95 is 0.0
INFO:root:FL Epoch: 480 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :65
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 480 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :6
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 480 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :47
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 480 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 480 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :13
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 480 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 480 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :24
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 480 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 480 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :83
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 480 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 480 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :75
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 480 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 480 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 81
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 480 Ends   ===================
INFO:root:Epoch:480 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:480 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 481 Begins ===================
INFO:root:FL Epoch: 481 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 481 Workers Selected : [0, 1, 2, 22, 24, 50, 94, 35, 74, 37]
INFO:root:FL Epoch: 481 Fraction of points on each worker in this round: [0.30120482 0.30120482 0.30120482 0.00150602 0.00451807 0.00150602
 0.06024096 0.00150602 0.02560241 0.00150602]
INFO:root:FL Epoch: 481 Num points on workers: [200 200 200   1   3   1  40   1  17   1]
INFO:root:--------------------------
INFO:root:FL Epoch: 481 Training on worker :0
INFO:root:FL Epoch: 481 Using Learning rate : 0.003825249948172384 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693197
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695490
INFO:root:FL Epoch: 481 Worker: 0 Backdoor Test Loss: 0.7204917967319489 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 481 Worker: 0 Backdoor Train Loss: 0.6897600889205933 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 481 Norm Difference for worker 0 is 0.050763
INFO:root:FL Epoch: 481 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :1
INFO:root:FL Epoch: 481 Using Learning rate : 0.003825249948172384 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698382
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691019
INFO:root:FL Epoch: 481 Worker: 1 Backdoor Test Loss: 0.7223391433556875 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 481 Worker: 1 Backdoor Train Loss: 0.6896436274051666 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 481 Norm Difference for worker 1 is 0.052284
INFO:root:FL Epoch: 481 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :2
INFO:root:FL Epoch: 481 Using Learning rate : 0.003825249948172384 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697439
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695958
INFO:root:FL Epoch: 481 Worker: 2 Backdoor Test Loss: 0.7195793588956197 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 481 Worker: 2 Backdoor Train Loss: 0.6899188935756684 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 481 Norm Difference for worker 2 is 0.049635
INFO:root:FL Epoch: 481 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :22
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 481 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :24
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 481 Norm Difference for worker 24 is 0.0
INFO:root:FL Epoch: 481 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :50
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 481 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :94
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/40 (0%)]	Loss: 0.690831
INFO:root:Worker: 94 Train Epoch: 1 [0/40 (0%)]	Loss: 0.668561
INFO:root:FL Epoch: 481 Norm Difference for worker 94 is 0.119754
INFO:root:FL Epoch: 481 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :35
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 481 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :74
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 481 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 481 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :37
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 481 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 22
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 481 Ends   ===================
INFO:root:Epoch:481 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:481 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 482 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 482 Workers Selected : [6, 80, 98, 96, 87, 78, 44, 69, 22, 23]
INFO:root:FL Epoch: 482 Fraction of points on each worker in this round: [0.02702703 0.02702703 0.02702703 0.02702703 0.13513514 0.02702703
 0.05405405 0.45945946 0.02702703 0.18918919]
INFO:root:FL Epoch: 482 Num points on workers: [ 1  1  1  1  5  1  2 17  1  7]
INFO:root:--------------------------
INFO:root:FL Epoch: 482 Training on worker :6
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 482 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :80
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 482 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :98
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 482 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :96
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 482 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :87
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 482 Norm Difference for worker 87 is 0.0
INFO:root:FL Epoch: 482 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :78
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 482 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :44
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 482 Norm Difference for worker 44 is 0.0
INFO:root:FL Epoch: 482 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :69
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 482 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 482 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :22
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 482 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :23
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 482 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 482 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 6
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 482 Ends   ===================
INFO:root:Epoch:482 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:482 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 483 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 483 Workers Selected : [32, 45, 23, 47, 80, 25, 75, 33, 57, 17]
INFO:root:FL Epoch: 483 Fraction of points on each worker in this round: [0.04545455 0.02272727 0.07954545 0.03409091 0.01136364 0.27272727
 0.02272727 0.34090909 0.14772727 0.02272727]
INFO:root:FL Epoch: 483 Num points on workers: [ 4  2  7  3  1 24  2 30 13  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 483 Training on worker :32
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 483 Norm Difference for worker 32 is 0.0
INFO:root:FL Epoch: 483 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :45
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 483 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 483 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :23
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:ignore batch due to small size = 7
INFO:root:ignore batch due to small size = 7
INFO:root:FL Epoch: 483 Norm Difference for worker 23 is 0.0
INFO:root:FL Epoch: 483 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :47
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 483 Norm Difference for worker 47 is 0.0
INFO:root:FL Epoch: 483 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :80
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 483 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 483 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :25
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.689148
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.673460
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 483 Norm Difference for worker 25 is 0.039768
INFO:root:FL Epoch: 483 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :75
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 483 Norm Difference for worker 75 is 0.0
INFO:root:FL Epoch: 483 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :33
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/30 (0%)]	Loss: 0.691181
INFO:root:ignore batch due to small size = 10
INFO:root:Worker: 33 Train Epoch: 1 [0/30 (0%)]	Loss: 0.675616
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 483 Norm Difference for worker 33 is 0.039014
INFO:root:FL Epoch: 483 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :57
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 483 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 483 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :17
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 483 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 483 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 32
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 483 Ends   ===================
INFO:root:Epoch:483 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:483 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 484 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 484 Workers Selected : [67, 31, 11, 86, 18, 50, 85, 96, 62, 9]
INFO:root:FL Epoch: 484 Fraction of points on each worker in this round: [0.22641509 0.01886792 0.05660377 0.09433962 0.0754717  0.01886792
 0.03773585 0.01886792 0.05660377 0.39622642]
INFO:root:FL Epoch: 484 Num points on workers: [12  1  3  5  4  1  2  1  3 21]
INFO:root:--------------------------
INFO:root:FL Epoch: 484 Training on worker :67
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 484 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 484 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :31
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 484 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 484 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :11
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 484 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 484 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :86
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 484 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 484 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :18
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 484 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 484 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :50
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 484 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 484 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :85
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 484 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 484 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :96
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 484 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 484 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :62
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 484 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 484 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :9
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.684542
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.675096
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 484 Norm Difference for worker 9 is 0.037378
INFO:root:FL Epoch: 484 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 67
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 484 Ends   ===================
INFO:root:Epoch:484 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:484 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 485 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 485 Workers Selected : [50, 69, 25, 68, 76, 83, 60, 55, 4, 71]
INFO:root:FL Epoch: 485 Fraction of points on each worker in this round: [0.01785714 0.30357143 0.42857143 0.03571429 0.07142857 0.03571429
 0.05357143 0.01785714 0.01785714 0.01785714]
INFO:root:FL Epoch: 485 Num points on workers: [ 1 17 24  2  4  2  3  1  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 485 Training on worker :50
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 50 is 0.0
INFO:root:FL Epoch: 485 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :69
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 485 Norm Difference for worker 69 is 0.0
INFO:root:FL Epoch: 485 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :25
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.687152
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.682394
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 485 Norm Difference for worker 25 is 0.040065
INFO:root:FL Epoch: 485 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :68
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 485 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 485 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :76
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 485 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 485 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :83
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 485 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 485 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :60
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 485 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 485 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :55
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 55 is 0.0
INFO:root:FL Epoch: 485 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :4
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 485 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :71
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 485 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 50
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 485 Ends   ===================
INFO:root:Epoch:485 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:485 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 486 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 486 Workers Selected : [26, 36, 31, 96, 30, 57, 59, 52, 51, 46]
INFO:root:FL Epoch: 486 Fraction of points on each worker in this round: [0.03703704 0.07407407 0.03703704 0.03703704 0.07407407 0.48148148
 0.03703704 0.03703704 0.14814815 0.03703704]
INFO:root:FL Epoch: 486 Num points on workers: [ 1  2  1  1  2 13  1  1  4  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 486 Training on worker :26
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 486 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 486 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :36
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 486 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 486 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :31
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 486 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 486 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :96
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 486 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 486 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :30
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 486 Norm Difference for worker 30 is 0.0
INFO:root:FL Epoch: 486 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :57
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 486 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 486 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :59
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 486 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 486 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :52
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 486 Norm Difference for worker 52 is 0.0
INFO:root:FL Epoch: 486 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :51
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 486 Norm Difference for worker 51 is 0.0
INFO:root:FL Epoch: 486 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :46
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 486 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 486 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 26
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 486 Ends   ===================
INFO:root:Epoch:486 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:486 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 487 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 487 Workers Selected : [13, 62, 99, 67, 70, 90, 58, 80, 54, 17]
INFO:root:FL Epoch: 487 Fraction of points on each worker in this round: [0.08333333 0.0625     0.0625     0.25       0.04166667 0.04166667
 0.375      0.02083333 0.02083333 0.04166667]
INFO:root:FL Epoch: 487 Num points on workers: [ 4  3  3 12  2  2 18  1  1  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 487 Training on worker :13
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 487 Norm Difference for worker 13 is 0.0
INFO:root:FL Epoch: 487 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :62
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 487 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 487 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :99
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 487 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 487 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :67
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 487 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 487 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :70
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 487 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 487 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :90
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 487 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 487 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :58
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 487 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 487 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :80
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 80 is 0.0
INFO:root:FL Epoch: 487 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :54
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 54 is 0.0
INFO:root:FL Epoch: 487 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :17
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 487 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 487 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 13
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 487 Ends   ===================
INFO:root:Epoch:487 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:487 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 488 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 488 Workers Selected : [29, 3, 35, 20, 26, 90, 45, 70, 61, 91]
INFO:root:FL Epoch: 488 Fraction of points on each worker in this round: [0.0625 0.0625 0.0625 0.0625 0.0625 0.125  0.125  0.125  0.0625 0.25  ]
INFO:root:FL Epoch: 488 Num points on workers: [1 1 1 1 1 2 2 2 1 4]
INFO:root:--------------------------
INFO:root:FL Epoch: 488 Training on worker :29
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 488 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :3
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 488 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :35
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 488 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :20
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 488 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :26
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 488 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :90
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 488 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 488 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :45
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 488 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 488 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :70
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 488 Norm Difference for worker 70 is 0.0
INFO:root:FL Epoch: 488 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :61
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 61 is 0.0
INFO:root:FL Epoch: 488 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :91
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 488 Norm Difference for worker 91 is 0.0
INFO:root:FL Epoch: 488 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 29
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 488 Ends   ===================
INFO:root:Epoch:488 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:488 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 489 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 489 Workers Selected : [3, 39, 68, 36, 96, 89, 4, 34, 64, 37]
INFO:root:FL Epoch: 489 Fraction of points on each worker in this round: [0.03571429 0.46428571 0.07142857 0.07142857 0.03571429 0.03571429
 0.03571429 0.10714286 0.10714286 0.03571429]
INFO:root:FL Epoch: 489 Num points on workers: [ 1 13  2  2  1  1  1  3  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 489 Training on worker :3
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 489 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 489 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :39
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 489 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 489 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :68
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 489 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 489 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :36
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 489 Norm Difference for worker 36 is 0.0
INFO:root:FL Epoch: 489 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :96
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 489 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 489 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :89
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 489 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 489 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :4
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 489 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 489 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :34
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 489 Norm Difference for worker 34 is 0.0
INFO:root:FL Epoch: 489 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :64
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 489 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 489 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :37
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 489 Norm Difference for worker 37 is 0.0
INFO:root:FL Epoch: 489 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 3
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 489 Ends   ===================
INFO:root:Epoch:489 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:489 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 490 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 490 Workers Selected : [83, 35, 42, 71, 25, 20, 48, 17, 92, 57]
INFO:root:FL Epoch: 490 Fraction of points on each worker in this round: [0.03846154 0.01923077 0.05769231 0.01923077 0.46153846 0.01923077
 0.01923077 0.03846154 0.07692308 0.25      ]
INFO:root:FL Epoch: 490 Num points on workers: [ 2  1  3  1 24  1  1  2  4 13]
INFO:root:--------------------------
INFO:root:FL Epoch: 490 Training on worker :83
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 490 Norm Difference for worker 83 is 0.0
INFO:root:FL Epoch: 490 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :35
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 35 is 0.0
INFO:root:FL Epoch: 490 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :42
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 490 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 490 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :71
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 490 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :25
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.687720
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.681345
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 490 Norm Difference for worker 25 is 0.03962
INFO:root:FL Epoch: 490 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :20
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 490 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :48
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 48 is 0.0
INFO:root:FL Epoch: 490 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :17
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 490 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 490 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :92
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 490 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 490 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :57
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 490 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 490 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 83
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 490 Ends   ===================
INFO:root:Epoch:490 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:490 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 491 Begins ===================
INFO:root:FL Epoch: 491 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 491 Workers Selected : [0, 1, 2, 41, 97, 12, 3, 90, 26, 67]
INFO:root:FL Epoch: 491 Fraction of points on each worker in this round: [0.31695721 0.31695721 0.31695721 0.00633914 0.01584786 0.00158479
 0.00158479 0.00316957 0.00158479 0.01901743]
INFO:root:FL Epoch: 491 Num points on workers: [200 200 200   4  10   1   1   2   1  12]
INFO:root:--------------------------
INFO:root:FL Epoch: 491 Training on worker :0
INFO:root:FL Epoch: 491 Using Learning rate : 0.003749429834781701 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697622
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682204
INFO:root:FL Epoch: 491 Worker: 0 Backdoor Test Loss: 0.71882497270902 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 491 Worker: 0 Backdoor Train Loss: 0.6899494528770447 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 491 Norm Difference for worker 0 is 0.049008
INFO:root:FL Epoch: 491 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1
INFO:root:FL Epoch: 491 Using Learning rate : 0.003749429834781701 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697363
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691247
INFO:root:FL Epoch: 491 Worker: 1 Backdoor Test Loss: 0.7209531962871552 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 491 Worker: 1 Backdoor Train Loss: 0.6898240387439728 Backdoor Train Accuracy: 56.5
INFO:root:FL Epoch: 491 Norm Difference for worker 1 is 0.050247
INFO:root:FL Epoch: 491 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :2
INFO:root:FL Epoch: 491 Using Learning rate : 0.003749429834781701 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696044
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684809
INFO:root:FL Epoch: 491 Worker: 2 Backdoor Test Loss: 0.7173872888088226 Backdoor Test Accuracy: 0.0
INFO:root:FL Epoch: 491 Worker: 2 Backdoor Train Loss: 0.6901967644691467 Backdoor Train Accuracy: 57.0
INFO:root:FL Epoch: 491 Norm Difference for worker 2 is 0.046485
INFO:root:FL Epoch: 491 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :41
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 491 Norm Difference for worker 41 is 0.0
INFO:root:FL Epoch: 491 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :97
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 491 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 491 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :12
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 12 is 0.0
INFO:root:FL Epoch: 491 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :3
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 3 is 0.0
INFO:root:FL Epoch: 491 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :90
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 491 Norm Difference for worker 90 is 0.0
INFO:root:FL Epoch: 491 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :26
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 491 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :67
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:ignore batch due to small size = 12
INFO:root:ignore batch due to small size = 12
INFO:root:FL Epoch: 491 Norm Difference for worker 67 is 0.0
INFO:root:FL Epoch: 491 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 41
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 491 Ends   ===================
INFO:root:Epoch:491 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:491 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 492 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 492 Workers Selected : [77, 81, 65, 15, 11, 68, 97, 86, 96, 7]
INFO:root:FL Epoch: 492 Fraction of points on each worker in this round: [0.03571429 0.10714286 0.03571429 0.03571429 0.10714286 0.07142857
 0.35714286 0.17857143 0.03571429 0.03571429]
INFO:root:FL Epoch: 492 Num points on workers: [ 1  3  1  1  3  2 10  5  1  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 492 Training on worker :77
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 77 is 0.0
INFO:root:FL Epoch: 492 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :81
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 492 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 492 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :65
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 65 is 0.0
INFO:root:FL Epoch: 492 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :15
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 492 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :11
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 492 Norm Difference for worker 11 is 0.0
INFO:root:FL Epoch: 492 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :68
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 492 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 492 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :97
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 492 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 492 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :86
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 492 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 492 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :96
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 492 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :7
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 492 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 77
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 492 Ends   ===================
INFO:root:Epoch:492 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:492 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 493 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 493 Workers Selected : [4, 9, 29, 59, 5, 76, 14, 42, 56, 7]
INFO:root:FL Epoch: 493 Fraction of points on each worker in this round: [0.02 0.42 0.02 0.02 0.18 0.08 0.12 0.06 0.06 0.02]
INFO:root:FL Epoch: 493 Num points on workers: [ 1 21  1  1  9  4  6  3  3  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 493 Training on worker :4
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 493 Norm Difference for worker 4 is 0.0
INFO:root:FL Epoch: 493 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :9
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/21 (0%)]	Loss: 0.683156
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/21 (0%)]	Loss: 0.675644
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 493 Norm Difference for worker 9 is 0.037313
INFO:root:FL Epoch: 493 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :29
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 493 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 493 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :59
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 493 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 493 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :5
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 493 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 493 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :76
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 493 Norm Difference for worker 76 is 0.0
INFO:root:FL Epoch: 493 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :14
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:ignore batch due to small size = 6
INFO:root:ignore batch due to small size = 6
INFO:root:FL Epoch: 493 Norm Difference for worker 14 is 0.0
INFO:root:FL Epoch: 493 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :42
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 493 Norm Difference for worker 42 is 0.0
INFO:root:FL Epoch: 493 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :56
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 493 Norm Difference for worker 56 is 0.0
INFO:root:FL Epoch: 493 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :7
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 493 Norm Difference for worker 7 is 0.0
INFO:root:FL Epoch: 493 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 4
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 493 Ends   ===================
INFO:root:Epoch:493 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:493 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 494 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 494 Workers Selected : [45, 38, 78, 57, 10, 8, 96, 17, 39, 20]
INFO:root:FL Epoch: 494 Fraction of points on each worker in this round: [0.05555556 0.02777778 0.02777778 0.36111111 0.02777778 0.02777778
 0.02777778 0.05555556 0.36111111 0.02777778]
INFO:root:FL Epoch: 494 Num points on workers: [ 2  1  1 13  1  1  1  2 13  1]
INFO:root:--------------------------
INFO:root:FL Epoch: 494 Training on worker :45
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 494 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 494 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :38
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 38 is 0.0
INFO:root:FL Epoch: 494 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :78
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 78 is 0.0
INFO:root:FL Epoch: 494 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :57
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 494 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 494 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :10
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 494 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :8
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 494 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :96
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 96 is 0.0
INFO:root:FL Epoch: 494 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :17
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 494 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 494 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :39
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 494 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 494 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :20
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 494 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 45
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 494 Ends   ===================
INFO:root:Epoch:494 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:494 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 495 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 495 Workers Selected : [18, 74, 59, 5, 15, 71, 64, 85, 6, 92]
INFO:root:FL Epoch: 495 Fraction of points on each worker in this round: [0.09302326 0.39534884 0.02325581 0.20930233 0.02325581 0.02325581
 0.06976744 0.04651163 0.02325581 0.09302326]
INFO:root:FL Epoch: 495 Num points on workers: [ 4 17  1  9  1  1  3  2  1  4]
INFO:root:--------------------------
INFO:root:FL Epoch: 495 Training on worker :18
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 495 Norm Difference for worker 18 is 0.0
INFO:root:FL Epoch: 495 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :74
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:ignore batch due to small size = 17
INFO:root:ignore batch due to small size = 17
INFO:root:FL Epoch: 495 Norm Difference for worker 74 is 0.0
INFO:root:FL Epoch: 495 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :59
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 495 Norm Difference for worker 59 is 0.0
INFO:root:FL Epoch: 495 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :5
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 495 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 495 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :15
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 495 Norm Difference for worker 15 is 0.0
INFO:root:FL Epoch: 495 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :71
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 495 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 495 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :64
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 495 Norm Difference for worker 64 is 0.0
INFO:root:FL Epoch: 495 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :85
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 495 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 495 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :6
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 495 Norm Difference for worker 6 is 0.0
INFO:root:FL Epoch: 495 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :92
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 495 Norm Difference for worker 92 is 0.0
INFO:root:FL Epoch: 495 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 18
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 495 Ends   ===================
INFO:root:Epoch:495 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:495 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 496 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 496 Workers Selected : [25, 49, 71, 22, 31, 20, 17, 82, 40, 68]
INFO:root:FL Epoch: 496 Fraction of points on each worker in this round: [0.68571429 0.02857143 0.02857143 0.02857143 0.02857143 0.02857143
 0.05714286 0.02857143 0.02857143 0.05714286]
INFO:root:FL Epoch: 496 Num points on workers: [24  1  1  1  1  1  2  1  1  2]
INFO:root:--------------------------
INFO:root:FL Epoch: 496 Training on worker :25
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/24 (0%)]	Loss: 0.689854
INFO:root:ignore batch due to small size = 4
INFO:root:Worker: 25 Train Epoch: 1 [0/24 (0%)]	Loss: 0.679561
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 496 Norm Difference for worker 25 is 0.039344
INFO:root:FL Epoch: 496 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :49
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 49 is 0.0
INFO:root:FL Epoch: 496 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :71
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 496 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :22
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 496 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :31
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 496 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :20
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 496 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :17
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 496 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 496 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :82
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 82 is 0.0
INFO:root:FL Epoch: 496 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :40
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 496 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :68
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 496 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 496 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 49
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 496 Ends   ===================
INFO:root:Epoch:496 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:496 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 497 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 497 Workers Selected : [62, 26, 22, 45, 93, 10, 20, 29, 17, 86]
INFO:root:FL Epoch: 497 Fraction of points on each worker in this round: [0.15789474 0.05263158 0.05263158 0.10526316 0.10526316 0.05263158
 0.05263158 0.05263158 0.10526316 0.26315789]
INFO:root:FL Epoch: 497 Num points on workers: [3 1 1 2 2 1 1 1 2 5]
INFO:root:--------------------------
INFO:root:FL Epoch: 497 Training on worker :62
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 497 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 497 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :26
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 497 Norm Difference for worker 26 is 0.0
INFO:root:FL Epoch: 497 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :22
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 497 Norm Difference for worker 22 is 0.0
INFO:root:FL Epoch: 497 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :45
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 497 Norm Difference for worker 45 is 0.0
INFO:root:FL Epoch: 497 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :93
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 497 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 497 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :10
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 497 Norm Difference for worker 10 is 0.0
INFO:root:FL Epoch: 497 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :20
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 497 Norm Difference for worker 20 is 0.0
INFO:root:FL Epoch: 497 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :29
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 497 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 497 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :17
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 497 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 497 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :86
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 497 Norm Difference for worker 86 is 0.0
INFO:root:FL Epoch: 497 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 62
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 497 Ends   ===================
INFO:root:Epoch:497 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:497 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 498 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 498 Workers Selected : [85, 17, 93, 99, 58, 40, 98, 62, 16, 39]
INFO:root:FL Epoch: 498 Fraction of points on each worker in this round: [0.04255319 0.04255319 0.04255319 0.06382979 0.38297872 0.0212766
 0.0212766  0.06382979 0.04255319 0.27659574]
INFO:root:FL Epoch: 498 Num points on workers: [ 2  2  2  3 18  1  1  3  2 13]
INFO:root:--------------------------
INFO:root:FL Epoch: 498 Training on worker :85
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 498 Norm Difference for worker 85 is 0.0
INFO:root:FL Epoch: 498 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :17
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 498 Norm Difference for worker 17 is 0.0
INFO:root:FL Epoch: 498 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :93
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 498 Norm Difference for worker 93 is 0.0
INFO:root:FL Epoch: 498 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :99
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 498 Norm Difference for worker 99 is 0.0
INFO:root:FL Epoch: 498 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :58
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:ignore batch due to small size = 18
INFO:root:ignore batch due to small size = 18
INFO:root:FL Epoch: 498 Norm Difference for worker 58 is 0.0
INFO:root:FL Epoch: 498 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :40
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 498 Norm Difference for worker 40 is 0.0
INFO:root:FL Epoch: 498 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :98
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 498 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 498 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :62
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 498 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 498 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :16
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 498 Norm Difference for worker 16 is 0.0
INFO:root:FL Epoch: 498 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :39
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 498 Norm Difference for worker 39 is 0.0
INFO:root:FL Epoch: 498 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 85
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 498 Ends   ===================
INFO:root:Epoch:498 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:498 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 499 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 499 Workers Selected : [57, 68, 31, 53, 60, 71, 62, 29, 89, 97]
INFO:root:FL Epoch: 499 Fraction of points on each worker in this round: [0.33333333 0.05128205 0.02564103 0.1025641  0.07692308 0.02564103
 0.07692308 0.02564103 0.02564103 0.25641026]
INFO:root:FL Epoch: 499 Num points on workers: [13  2  1  4  3  1  3  1  1 10]
INFO:root:--------------------------
INFO:root:FL Epoch: 499 Training on worker :57
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:ignore batch due to small size = 13
INFO:root:ignore batch due to small size = 13
INFO:root:FL Epoch: 499 Norm Difference for worker 57 is 0.0
INFO:root:FL Epoch: 499 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :68
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 499 Norm Difference for worker 68 is 0.0
INFO:root:FL Epoch: 499 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :31
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 499 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 499 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :53
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:ignore batch due to small size = 4
INFO:root:ignore batch due to small size = 4
INFO:root:FL Epoch: 499 Norm Difference for worker 53 is 0.0
INFO:root:FL Epoch: 499 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :60
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 499 Norm Difference for worker 60 is 0.0
INFO:root:FL Epoch: 499 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :71
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 499 Norm Difference for worker 71 is 0.0
INFO:root:FL Epoch: 499 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :62
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 499 Norm Difference for worker 62 is 0.0
INFO:root:FL Epoch: 499 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :29
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 499 Norm Difference for worker 29 is 0.0
INFO:root:FL Epoch: 499 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :89
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 499 Norm Difference for worker 89 is 0.0
INFO:root:FL Epoch: 499 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :97
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:ignore batch due to small size = 10
INFO:root:ignore batch due to small size = 10
INFO:root:FL Epoch: 499 Norm Difference for worker 97 is 0.0
INFO:root:FL Epoch: 499 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 57
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 499 Ends   ===================
INFO:root:Epoch:499 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:499 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 500 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 500 Workers Selected : [5, 73, 79, 81, 8, 98, 27, 46, 66, 31]
INFO:root:FL Epoch: 500 Fraction of points on each worker in this round: [0.36 0.04 0.08 0.12 0.04 0.04 0.2  0.04 0.04 0.04]
INFO:root:FL Epoch: 500 Num points on workers: [9 1 2 3 1 1 5 1 1 1]
INFO:root:--------------------------
INFO:root:FL Epoch: 500 Training on worker :5
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:ignore batch due to small size = 9
INFO:root:ignore batch due to small size = 9
INFO:root:FL Epoch: 500 Norm Difference for worker 5 is 0.0
INFO:root:FL Epoch: 500 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :73
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 500 Norm Difference for worker 73 is 0.0
INFO:root:FL Epoch: 500 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :79
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:ignore batch due to small size = 2
INFO:root:ignore batch due to small size = 2
INFO:root:FL Epoch: 500 Norm Difference for worker 79 is 0.0
INFO:root:FL Epoch: 500 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :81
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:ignore batch due to small size = 3
INFO:root:ignore batch due to small size = 3
INFO:root:FL Epoch: 500 Norm Difference for worker 81 is 0.0
INFO:root:FL Epoch: 500 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :8
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 500 Norm Difference for worker 8 is 0.0
INFO:root:FL Epoch: 500 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :98
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 500 Norm Difference for worker 98 is 0.0
INFO:root:FL Epoch: 500 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :27
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:ignore batch due to small size = 5
INFO:root:ignore batch due to small size = 5
INFO:root:FL Epoch: 500 Norm Difference for worker 27 is 0.0
INFO:root:FL Epoch: 500 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :46
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 500 Norm Difference for worker 46 is 0.0
INFO:root:FL Epoch: 500 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :66
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 500 Norm Difference for worker 66 is 0.0
INFO:root:FL Epoch: 500 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :31
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:ignore batch due to small size = 1
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 500 Norm Difference for worker 31 is 0.0
INFO:root:FL Epoch: 500 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 5
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 500 Saving Checkpoint at this epoch.
INFO:root:FL Epoch: 500 Saved Checkpoint at this epoch.
INFO:root:================FL round 500 Ends   ===================
INFO:root:Epoch:500 Global Model Test Loss:0.6919716281049392 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:500 Global Model Backdoor Test Loss:0.7028335531552633                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:***** Done with FL Training, Saved the stats to file ./out/single-character-krum-natural//stats.csv ******
